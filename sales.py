import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from pptx import Presentation
from pptx.util import Inches, Pt
from pptx.enum.text import PP_ALIGN
from pptx.dml.color import RGBColor
import io
from sklearn.linear_model import LinearRegression
from statsmodels.tsa.holtwinters import ExponentialSmoothing
import os
from datetime import datetime
from prophet import Prophet
import io
import base64
import streamlit_authenticator as stauth
import hashlib
from difflib import SequenceMatcher
from fuzzywuzzy import fuzz
from io import BytesIO

# --- Language Selector ---
st.sidebar.header("Language / Ø§Ù„Ù„ØºØ©")
language = st.sidebar.selectbox("Choose / Ø§Ø®ØªØ±", ["English", "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"])
lang = "en" if language == "English" else "ar"

if lang == "ar":
    st.markdown("""
    <style>
    .stApp {
        direction: rtl;
        text-align: right;
    }
    .stButton > button {
        float: right;
    }
    .dataframe th, .dataframe td {
        text-align: right !important;
    }
    </style>
    """, unsafe_allow_html=True)

texts = {
    "en": {
        "page_title": "ğŸ“Š Haneef Data Dashboard",
        "layout": "wide",
        "page_icon": "ğŸ“ˆ",
        "welcome": "Welcome {0} ğŸ‘‹",
        "logout": "Logout",
        "incorrect_login": "âŒ Username/password is incorrect",
        "no_login": "âš ï¸ Please enter your username and password",
        "dark_mode": "ğŸŒ™ Dark Mode",
        "upload_header": "ğŸ“‚ Upload Excel (one-time)",
        "upload_tooltip": "Upload an Excel file with sheets: sales data, Target, sales channels, and optionally YTD.",
        "clear_data": "ğŸ” Clear data",
        "file_loaded": "âœ… File loaded â€” now use the menu to go to any page.",
        "menu_title": "ğŸ§­ Menu",
        "navigate": "Navigate",
        "home": "Home",
        "sales_tracking": "Sales Tracking",
        "ytd_comparison": "Year to Date Comparison",
        "custom_analysis": "Custom Analysis",
        "target_allocation": "SP/PY Target Allocation",
        "ai_insights": "AI Insights",
        "customer_insights": "Customer Insights",
        "customer_insights_title": "Customer Insights Dashboard",
        "material_forecast": "Material Forecast",
        "material_forecast_title": "ğŸ“ˆ Material Forecast",
        "rfm_analysis_sub": "RFM Analysis",
        "rfm_table_sub": "RFM Table",
        "rfm_chart_sub": "RFM Visualization",
        "rfm_no_data": "No data available for RFM analysis.",
        "rfm_download": "Download RFM Report",
        "rfm_cohort_sub": "RFM Cohort Analysis",
        "rfm_cohort_info": "Analyzes how RFM scores evolve over time for customer acquisition cohorts (grouped by first purchase month).",
        "rfm_cohort_table_sub": "Cohort Summary Table",
        "rfm_cohort_insights_sub": "Key Insights",
        "rfm_cohort_download": "Download Cohort Report (Excel)",
        "rfm_cohort_no_data": "Insufficient data for cohort analysis.",
        "product_availability_checker": "Product Availability Checker",
        "home_title": "ğŸ  Haneef Data Dashboard",
        "home_welcome": "**Welcome to your Sales Analytics Hub!**\n- ğŸ“ˆ Track sales & targets by salesman, By Customer Name, By Branch Name\n- ğŸ“Š Visualize trends with interactive charts (now with advanced forecasting)\n- ğŸ’¾ Download reports in PPTX & Excel\n- ğŸ“… Compare sales across custom periods\n- ğŸ¯ Allocate SP/PY targets based on recent performance\nUse the sidebar to navigate and upload data once.",
        "data_loaded_msg": "Data is loaded â€” choose a page from the menu.",
        "upload_prompt": "Please upload your Excel file in the sidebar to start.",
        "sales_tracking_title": "ğŸ“Š MTD Tracking",
        "no_data_warning": "âš ï¸ Please upload the Excel file in the sidebar (one-time).",
        "filters_header": "ğŸ” Filters (Sales Tracking)",
        "filters_tooltip": "Filter data by salesmen, billing types, PY, SP, and date range.",
        "select_salesmen": "ğŸ‘¥ Select Salesmen",
        "select_billing_types": "ğŸ“‹ Select Billing Types",
        "select_py": "ğŸ¬ Select PY Name",
        "select_sp": "ğŸ·ï¸ Select SP Name1",
        "date_presets": "ğŸ“… Quick Date Presets",
        "date_presets_options": ["Custom Range", "Last 7 Days", "This Month", "YTD"],
        "select_date_range": "ğŸ“† Select Date Range",
        "date_error": "âŒ Start date must be before end date.",
        "top_n_salesmen": "ğŸ† Show Top N Salesmen",
        "no_match_warning": "âš ï¸ No data matches the selected filters.",
        "kpis_tab": "ğŸ“ˆ KPIs",
        "tables_tab": "ğŸ“‹ Tables",
        "charts_tab": "ğŸ“Š Charts",
        "downloads_tab": "ğŸ’¾ Downloads",
        "key_metrics_sub": "ğŸ† Key Metrics",
        "total_ka_sales": "Total KA Sales",
        "of_ka_target": "{0:.0f}% of KA Target Achieved",
        "ka_other_ecom": "KA & Other E-com",
        "of_ka_target_pct": "{0:.0f}% of KA Target",
        "talabat_sales": "Talabat Sales",
        "of_talabat_target": "{0:.0f}% of Talabat Target Achieved",
        "target_overview_sub": "ğŸ¯ Target Overview",
        "ka_target": "KA Target",
        "talabat_target": "Talabat Target",
        "ka_gap": "KA Gap",
        "talabat_gap": "Talabat Gap",
        "channel_sales_sub": "ğŸ“Š Channel Sales",
        "retail_sales": "Retail Sales",
        "of_total_ka": "{0:.0f}% of Total KA Sales",
        "ecom_sales": "E-com Sales",
        "performance_metrics_sub": "ğŸ“ˆ Performance Metrics",
        "days_finished": "Days Finished (working)",
        "current_sales_per_day": "Current Sales Per Day",
        "forecast_month_end": "Forecasted Month-End KA Sales",
        "sales_targets_summary_sub": "ğŸ“‹ Sales & Targets Summary",
        "download_sales_targets": "â¬‡ï¸ Download Sales & Targets Summary (Excel)",
        "sales_by_billing_sub": "ğŸ“Š Sales by Billing Type per Salesman",
        "download_billing": "â¬‡ï¸ Download Billing Type Table (Excel)",
        "sales_by_py_sub": "ğŸ¬ Sales by PY Name 1",
        "download_py": "â¬‡ï¸ Download PY Name Table (Excel)",
        "daily_sales_trend_sub": "ğŸ“Š Daily Sales Trend with Prophet Forecast",
        "daily_sales_title": "Daily Sales Trend, Prophet Forecast & Anomalies",
        "not_enough_data": "Not enough data to perform a time-series forecast.",
        "market_vs_ecom_sub": "ğŸ“Š Market vs E-com Sales",
        "market_vs_ecom_title": "Market vs E-com Sales Distribution",
        "daily_ka_target_sub": "ğŸ“Š Daily KA Target vs Actual Sales",
        "daily_ka_title": "Daily KA Target vs Actual Sales",
        "salesman_ka_sub": "ğŸ“Š Salesman KA Target vs Actual",
        "salesman_ka_title": "KA Target vs Actual Sales by Salesman",
        "top10_py_sub": "ğŸ“Š Top 10 PY Name 1 by Sales",
        "top10_py_title": "Top 10 PY Name 1 by Sales",
        "download_reports_sub": "ğŸ’¾ Download Reports",
        "generate_pptx": "ğŸ“‘ Generate PPTX Report",
        "download_pptx": "â¬‡ï¸ Download PPTX Report",
        "ytd_title": "ğŸ“Š Year to Date Comparison",
        "ytd_filters_header": "ğŸ” Filters (YTD)",
        "ytd_filters_tooltip": "Filter data by salesmen, billing types, PY, SP, and date range.",
        "ytd_select_group": "Group By",
        "ytd_select_value": "Value Column",
        "ytd_period1": "Select Period 1",
        "ytd_period2": "Select Period 2",
        "ytd_no_data": "âš ï¸ No data matches the filters.",
        "ytd_comparison_sub": "ğŸ“‹ YTD Comparison Table",
        "ytd_download": "â¬‡ï¸ Download YTD Comparison (Excel)",
        "ytd_chart_title": "YTD Comparison Chart",
        "custom_title": "ğŸ“Š Custom Analysis",
        "custom_upload": "Upload Additional Sheet (optional)",
        "custom_extra_loaded": "âœ… Extra sheet loaded.",
        "custom_select_sheet": "ğŸ“‘ Select Sheet for Analysis",
        "custom_sheet_empty": "âš ï¸ The sheet '{0}' is empty or not available in your file.",
        "custom_explore": "ğŸ’¡ Explore your data by multiple columns & compare two periods.",
        "custom_group_cols": "Group by columns",
        "custom_value_col": "Value to analyze",
        "custom_periods_sub": "ğŸ“† Select Two Periods",
        "custom_period1": "Period 1",
        "custom_period2": "Period 2",
        "custom_select_p1": "Select Period 1",
        "custom_select_p2": "Select Period 2",
        "custom_select_prompt": "ğŸ‘‰ Please select at least one group column, one value column, and valid date ranges.",
        "custom_comparison_sub": "ğŸ“‹ Comparison of {0} by {1}",
        "custom_download": "â¬‡ï¸ Download Comparison (Excel)",
        "target_alloc_title": "ğŸ¯ SP/PY Target Allocation",
        "target_config_sub": "Configuration",
        "target_alloc_tooltip": "Allocate targets by branch or customer based on historical sales.",
        "target_alloc_type": "Select Target Allocation Type",
        "target_alloc_options": ["By Branch (SP Name1)", "Customer (PY Name 1)"],
        "target_input_option": "Select Target Input Option",
        "target_input_options": ["Manual", "Auto (from 'Target' sheet)"],
        "target_enter_total": "Enter the Total Target to be Allocated for this Month (KD)",
        "target_auto_info": "Using Total Target from 'Target' sheet: KD {0:,.0f}",
        "target_zero_warning": "Please ensure the total target is greater than 0.",
        "target_hist_sub": "Historical Data Period",
        "target_hist_option": "Select Historical Data Period",
        "target_hist_options": ["Last 6 Months", "Manual Days"],
        "target_select_range": "Select date range",
        "target_date_warning": "Please select both a start and an end date.",
        "target_no_hist": "âš ï¸ No sales data available in 'YTD' for {0}.",
        "target_analysis_sub": "ğŸ¯ Target Analysis",
        "hist_sales_total": "Historical Sales Total",
        "alloc_target_total": "Allocated Target Total",
        "increase_needed": "Increase Needed vs Avg Sales",
        "current_month_sales": "Current Month Sales",
        "target_balance": "Target Balance",
        "alloc_targets_sub": "ğŸ“Š Auto-Allocated Targets Based on {0}",
        "download_alloc": "ğŸ’¾ Download Target Allocation Table",
        "ai_title": "ğŸ¤– AI Insights",
        "ai_scope_sub": "Scope and filters",
        "ai_select_period": "Select period for insights",
        "ai_top_n": "Top-N salesmen spotlight",
        "ai_no_data": "No data in the selected period. Try expanding the date range.",
        "ai_exec_sub": "ğŸ“œ Executive summary",
        "ai_prescript_sub": "ğŸ› ï¸ Prescriptive Recommendations",
        "ai_visual_sub": "ğŸ“Š AI-Generated Visuals",
        "ai_section_sub": "ğŸ§­ Section insights",
        "ai_download_sub": "ğŸ“¥ Download executive summary",
        "ai_download_button": "ğŸ’¾ Download AI executive summary (TXT)",
        "ai_ask_sub": "ğŸ’¬ Ask a question about your data",
        "ai_ask_prompt": "Type a question (e.g., 'Which salesman is growing fastest?', 'Where are returns highest?', 'Correlation between targets and sales?')",
        "admin_tools": "Admin Tools",
        "view_logs": "View Audit Logs",
        "audit_title": "ğŸ“‹ Audit Logs",
        "download_logs": "â¬‡ï¸ Download Audit Logs (Excel)",
        "sheet_missing": "âŒ Excel file must contain sheets: {0}. Missing: {1}",
        "cols_missing": "âŒ Missing required columns: {0}",
        "load_error": "âŒ Error loading Excel file: {0}",
        "pptx_title": "Sales & Targets Report",
        "pptx_generated": "Generated on {0}",
        "pptx_kpi_title": "ğŸ“ˆ Key Performance Indicators",
        "pptx_summary_title": "ğŸ“‹ Sales & Targets Summary",
        "pptx_billing_title": "ğŸ“Š Sales by Billing Type per Salesman",
        "pptx_py_title": "ğŸ¬ Sales by PY Name 1",
        "pptx_embed_error": "Chart cannot be embedded: {0}. Install kaleido if missing.",
        "generating_pptx": "â³ Generating PPTX report...",
        "loading_data": "â³ Loading Excel data...",
    },
    "ar": {
        "page_title": "ğŸ“Š Ù„ÙˆØ­Ø© ØªØ­ÙƒÙ… Ø¨ÙŠØ§Ù†Ø§Øª Ø­Ù†ÙŠÙ",
        "layout": "wide",
        "page_icon": "ğŸ“ˆ",
        "welcome": "Ù…Ø±Ø­Ø¨Ø§ {0} ğŸ‘‹",
        "logout": "ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø®Ø±ÙˆØ¬",
        "incorrect_login": "âŒ Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…/ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ± ØºÙŠØ± ØµØ­ÙŠØ­Ø©",
        "no_login": "âš ï¸ ÙŠØ±Ø¬Ù‰ Ø¥Ø¯Ø®Ø§Ù„ Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙˆÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±",
        "dark_mode": "ğŸŒ™ Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„Ø¯Ø§ÙƒÙ†",
        "upload_header": "ğŸ“‚ ØªØ­Ù…ÙŠÙ„ Ø¥ÙƒØ³Ù„ (Ù…Ø±Ø© ÙˆØ§Ø­Ø¯Ø©)",
        "upload_tooltip": "ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù Ø¥ÙƒØ³Ù„ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø£ÙˆØ±Ø§Ù‚: Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§ØªØŒ Ø§Ù„Ù‡Ø¯ÙØŒ Ù‚Ù†ÙˆØ§Øª Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§ØªØŒ ÙˆØ§Ø®ØªÙŠØ§Ø±ÙŠØ§Ù‹ YTD.",
        "clear_data": "ğŸ” Ù…Ø³Ø­ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª",
        "file_loaded": "âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù â€” Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¢Ù† Ù„Ù„Ø°Ù‡Ø§Ø¨ Ø¥Ù„Ù‰ Ø£ÙŠ ØµÙØ­Ø©.",
        "menu_title": "ğŸ§­ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©",
        "navigate": "Ø§Ù„ØªÙ†Ù‚Ù„",
        "home": "Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©",
        "sales_tracking": "ØªØªØ¨Ø¹ Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª",
        "ytd_comparison": "Ù…Ù‚Ø§Ø±Ù†Ø© Ù…Ù† Ø¨Ø¯Ø§ÙŠØ© Ø§Ù„Ø³Ù†Ø©",
        "custom_analysis": "ØªØ­Ù„ÙŠÙ„ Ù…Ø®ØµØµ",
        "target_allocation": "ØªØ®ØµÙŠØµ Ø£Ù‡Ø¯Ø§Ù SP/PY",
        "ai_insights": "Ø±Ø¤Ù‰ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ",
        "customer_insights": "Ø±Ø¤Ù‰ Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡",
        "customer_insights_title": "Ù„ÙˆØ­Ø© Ø±Ø¤Ù‰ Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡",
        "material_forecast": "ØªÙˆÙ‚Ø¹Ø§Øª Ø§Ù„Ù…ÙˆØ§Ø¯",
        "material_forecast_title": "ğŸ“ˆ ØªÙˆÙ‚Ø¹Ø§Øª Ø§Ù„Ù…ÙˆØ§Ø¯",
        "rfm_analysis_sub": "ØªØ­Ù„ÙŠÙ„ RFM",
        "rfm_table_sub": "Ø¬Ø¯ÙˆÙ„ RFM",
        "rfm_chart_sub": "ØªØµÙˆØ± RFM",
        "rfm_no_data": "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù…ØªØ§Ø­Ø© Ù„ØªØ­Ù„ÙŠÙ„ RFM.",
        "rfm_download": "ØªÙ†Ø²ÙŠÙ„ ØªÙ‚Ø±ÙŠØ± RFM",
        "rfm_cohort_sub": "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£ØªØ±Ø§Ø¨ RFM",
        "rfm_cohort_info": "ÙŠØ­Ù„Ù„ ÙƒÙŠÙÙŠØ© ØªØ·ÙˆØ± Ø¯Ø±Ø¬Ø§Øª RFM Ø¨Ù…Ø±ÙˆØ± Ø§Ù„ÙˆÙ‚Øª Ù„Ø£ØªØ±Ø§Ø¨ Ø§ÙƒØªØ³Ø§Ø¨ Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡ (Ù…Ø¬Ù…Ø¹Ø© Ø­Ø³Ø¨ Ø´Ù‡Ø± Ø§Ù„Ø´Ø±Ø§Ø¡ Ø§Ù„Ø£ÙˆÙ„).",
        "rfm_cohort_table_sub": "Ø¬Ø¯ÙˆÙ„ Ù…Ù„Ø®Øµ Ø§Ù„Ø£ØªØ±Ø§Ø¨",
        "rfm_cohort_insights_sub": "Ø§Ù„Ø±Ø¤Ù‰ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©",
        "rfm_cohort_download": "ØªÙ†Ø²ÙŠÙ„ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£ØªØ±Ø§Ø¨ (Ø¥ÙƒØ³Ù„)",
        "rfm_cohort_no_data": "Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± ÙƒØ§ÙÙŠØ© Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£ØªØ±Ø§Ø¨.",
        "product_availability_checker": "Ù…Ø¯Ù‚Ù‚ ØªÙˆÙØ± Ø§Ù„Ù…Ù†ØªØ¬",
        "home_title": "ğŸ  Ù„ÙˆØ­Ø© ØªØ­ÙƒÙ… Ø¨ÙŠØ§Ù†Ø§Øª Ø­Ù†ÙŠÙ",
        "home_welcome": "**Ù…Ø±Ø­Ø¨Ø§ Ø¨Ùƒ ÙÙŠ Ù…Ø±ÙƒØ² ØªØ­Ù„ÙŠÙ„Ø§Øª Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª!**\n- ğŸ“ˆ ØªØªØ¨Ø¹ Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª ÙˆØ§Ù„Ø£Ù‡Ø¯Ø§Ù Ø­Ø³Ø¨ Ø§Ù„Ø¨Ø§Ø¦Ø¹ØŒ Ø§Ø³Ù… Ø§Ù„Ø¹Ù…ÙŠÙ„ØŒ Ø§Ø³Ù… Ø§Ù„ÙØ±Ø¹\n- ğŸ“Š ØªØµÙˆØ± Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª Ù…Ø¹ Ø±Ø³ÙˆÙ… Ø¨ÙŠØ§Ù†ÙŠØ© ØªÙØ§Ø¹Ù„ÙŠØ© (Ø§Ù„Ø¢Ù† Ù…Ø¹ ØªÙ†Ø¨Ø¤ Ù…ØªÙ‚Ø¯Ù…)\n- ğŸ’¾ ØªÙ†Ø²ÙŠÙ„ Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ± ÙÙŠ PPTX Ùˆ Excel\n- ğŸ“… Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª Ø¹Ø¨Ø± ÙØªØ±Ø§Øª Ù…Ø®ØµØµØ©\n- ğŸ¯ ØªØ®ØµÙŠØµ Ø£Ù‡Ø¯Ø§Ù SP/PY Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø£Ø®ÙŠØ±\nØ§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ Ù„Ù„ØªÙ†Ù‚Ù„ ÙˆØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø±Ø© ÙˆØ§Ø­Ø¯Ø©.",
        "data_loaded_msg": "ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª â€” Ø§Ø®ØªØ± ØµÙØ­Ø© Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©.",
        "upload_prompt": "ÙŠØ±Ø¬Ù‰ ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù Ø§Ù„Ø¥ÙƒØ³Ù„ ÙÙŠ Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ Ù„Ù„Ø¨Ø¯Ø¡.",
        "sales_tracking_title": "ğŸ“Š ØªØªØ¨Ø¹ MTD",
        "no_data_warning": "âš ï¸ ÙŠØ±Ø¬Ù‰ ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù Ø§Ù„Ø¥ÙƒØ³Ù„ ÙÙŠ Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ (Ù…Ø±Ø© ÙˆØ§Ø­Ø¯Ø©).",
        "filters_header": "ğŸ” ÙÙ„Ø§ØªØ± (ØªØªØ¨Ø¹ Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª)",
        "filters_tooltip": "ØªØµÙÙŠØ© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø­Ø³Ø¨ Ø§Ù„Ø¨Ø§Ø¦Ø¹ÙŠÙ†ØŒ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„ÙÙˆØ§ØªÙŠØ±ØŒ PYØŒ SPØŒ ÙˆÙ†Ø·Ø§Ù‚ Ø§Ù„ØªØ§Ø±ÙŠØ®.",
        "select_salesmen": "ğŸ‘¥ Ø§Ø®ØªØ± Ø§Ù„Ø¨Ø§Ø¦Ø¹ÙŠÙ†",
        "select_billing_types": "ğŸ“‹ Ø§Ø®ØªØ± Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„ÙÙˆØ§ØªÙŠØ±",
        "select_py": "ğŸ¬ Ø§Ø®ØªØ± Ø§Ø³Ù… PY",
        "select_sp": "ğŸ·ï¸ Ø§Ø®ØªØ± Ø§Ø³Ù… SP1",
        "date_presets": "ğŸ“… Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ØªØ§Ø±ÙŠØ® Ø³Ø±ÙŠØ¹Ø©",
        "date_presets_options": ["Ù†Ø·Ø§Ù‚ Ù…Ø®ØµØµ", "Ø¢Ø®Ø± 7 Ø£ÙŠØ§Ù…", "Ù‡Ø°Ø§ Ø§Ù„Ø´Ù‡Ø±", "Ù…Ù† Ø¨Ø¯Ø§ÙŠØ© Ø§Ù„Ø³Ù†Ø©"],
        "select_date_range": "ğŸ“† Ø§Ø®ØªØ± Ù†Ø·Ø§Ù‚ Ø§Ù„ØªØ§Ø±ÙŠØ®",
        "date_error": "âŒ ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¨Ø¯Ø§ÙŠØ© ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ù‚Ø¨Ù„ ØªØ§Ø±ÙŠØ® Ø§Ù„Ù†Ù‡Ø§ÙŠØ©.",
        "top_n_salesmen": "ğŸ† Ø¹Ø±Ø¶ Ø£ÙØ¶Ù„ N Ø¨Ø§Ø¦Ø¹ÙŠÙ†",
        "no_match_warning": "âš ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ØªØ·Ø§Ø¨Ù‚ Ø§Ù„ÙÙ„Ø§ØªØ± Ø§Ù„Ù…Ø®ØªØ§Ø±Ø©.",
        "kpis_tab": "ğŸ“ˆ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©",
        "tables_tab": "ğŸ“‹ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„",
        "charts_tab": "ğŸ“Š Ø§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠØ©",
        "downloads_tab": "ğŸ’¾ Ø§Ù„ØªÙ†Ø²ÙŠÙ„Ø§Øª",
        "key_metrics_sub": "ğŸ† Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©",
        "total_ka_sales": "Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ù…Ø¨ÙŠØ¹Ø§Øª KA",
        "of_ka_target": "{0:.0f}% Ù…Ù† Ù‡Ø¯Ù KA Ø§Ù„Ù…Ø­Ù‚Ù‚",
        "ka_other_ecom": "KA Ùˆ E-com Ø£Ø®Ø±Ù‰",
        "of_ka_target_pct": "{0:.0f}% Ù…Ù† Ù‡Ø¯Ù KA",
        "talabat_sales": "Ù…Ø¨ÙŠØ¹Ø§Øª Ø·Ù„Ø¨Ø§Øª",
        "of_talabat_target": "{0:.0f}% Ù…Ù† Ù‡Ø¯Ù Ø·Ù„Ø¨Ø§Øª Ø§Ù„Ù…Ø­Ù‚Ù‚",
        "target_overview_sub": "ğŸ¯ Ù†Ø¸Ø±Ø© Ø¹Ø§Ù…Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‡Ø¯Ø§Ù",
        "ka_target": "Ù‡Ø¯Ù KA",
        "talabat_target": "Ù‡Ø¯Ù Ø·Ù„Ø¨Ø§Øª",
        "ka_gap": "ÙØ¬ÙˆØ© KA",
        "talabat_gap": "ÙØ¬ÙˆØ© Ø·Ù„Ø¨Ø§Øª",
        "channel_sales_sub": "ğŸ“Š Ù…Ø¨ÙŠØ¹Ø§Øª Ø§Ù„Ù‚Ù†ÙˆØ§Øª",
        "retail_sales": "Ù…Ø¨ÙŠØ¹Ø§Øª Ø§Ù„ØªØ¬Ø²Ø¦Ø©",
        "of_total_ka": "{0:.0f}% Ù…Ù† Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ù…Ø¨ÙŠØ¹Ø§Øª KA",
        "ecom_sales": "Ù…Ø¨ÙŠØ¹Ø§Øª E-com",
        "performance_metrics_sub": "ğŸ“ˆ Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø£Ø¯Ø§Ø¡",
        "days_finished": "Ø§Ù„Ø£ÙŠØ§Ù… Ø§Ù„Ù…ÙƒØªÙ…Ù„Ø© (Ø§Ù„Ø¹Ù…Ù„ÙŠØ©)",
        "current_sales_per_day": "Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª Ø§Ù„Ø­Ø§Ù„ÙŠØ© Ù„ÙƒÙ„ ÙŠÙˆÙ…",
        "forecast_month_end": "Ù…Ø¨ÙŠØ¹Ø§Øª KA Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø© ÙÙŠ Ù†Ù‡Ø§ÙŠØ© Ø§Ù„Ø´Ù‡Ø±",
        "sales_targets_summary_sub": "ğŸ“‹ Ù…Ù„Ø®Øµ Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª ÙˆØ§Ù„Ø£Ù‡Ø¯Ø§Ù",
        "download_sales_targets": "â¬‡ï¸ ØªÙ†Ø²ÙŠÙ„ Ù…Ù„Ø®Øµ Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª ÙˆØ§Ù„Ø£Ù‡Ø¯Ø§Ù (Ø¥ÙƒØ³Ù„)",
        "sales_by_billing_sub": "ğŸ“Š Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„ÙØ§ØªÙˆØ±Ø© Ù„ÙƒÙ„ Ø¨Ø§Ø¦Ø¹",
        "download_billing": "â¬‡ï¸ ØªÙ†Ø²ÙŠÙ„ Ø¬Ø¯ÙˆÙ„ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„ÙÙˆØ§ØªÙŠØ± (Ø¥ÙƒØ³Ù„)",
        "sales_by_py_sub": "ğŸ¬ Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª Ø­Ø³Ø¨ Ø§Ø³Ù… PY 1",
        "download_py": "â¬‡ï¸ ØªÙ†Ø²ÙŠÙ„ Ø¬Ø¯ÙˆÙ„ Ø§Ø³Ù… PY (Ø¥ÙƒØ³Ù„)",
        "daily_sales_trend_sub": "ğŸ“Š Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª Ø§Ù„ÙŠÙˆÙ…ÙŠ Ù…Ø¹ ØªÙ†Ø¨Ø¤ Prophet",
        "daily_sales_title": "Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª Ø§Ù„ÙŠÙˆÙ…ÙŠØŒ ØªÙ†Ø¨Ø¤ Prophet ÙˆØ§Ù„Ø´Ø°ÙˆØ°Ø§Øª",
        "not_enough_data": "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ§ÙÙŠØ© Ù„Ø¥Ø¬Ø±Ø§Ø¡ ØªÙ†Ø¨Ø¤ Ø²Ù…Ù†ÙŠ.",
        "market_vs_ecom_sub": "ğŸ“Š Ø§Ù„Ø³ÙˆÙ‚ Ù…Ù‚Ø§Ø¨Ù„ Ù…Ø¨ÙŠØ¹Ø§Øª E-com",
        "market_vs_ecom_title": "ØªÙˆØ²ÙŠØ¹ Ù…Ø¨ÙŠØ¹Ø§Øª Ø§Ù„Ø³ÙˆÙ‚ Ù…Ù‚Ø§Ø¨Ù„ E-com",
        "daily_ka_target_sub": "ğŸ“Š Ù‡Ø¯Ù KA Ø§Ù„ÙŠÙˆÙ…ÙŠ Ù…Ù‚Ø§Ø¨Ù„ Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª Ø§Ù„ÙØ¹Ù„ÙŠØ©",
        "daily_ka_title": "Ù‡Ø¯Ù KA Ø§Ù„ÙŠÙˆÙ…ÙŠ Ù…Ù‚Ø§Ø¨Ù„ Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª Ø§Ù„ÙØ¹Ù„ÙŠØ©",
        "salesman_ka_sub": "ğŸ“Š Ù‡Ø¯Ù KA Ù„Ù„Ø¨Ø§Ø¦Ø¹ Ù…Ù‚Ø§Ø¨Ù„ Ø§Ù„ÙØ¹Ù„ÙŠ",
        "salesman_ka_title": "Ù‡Ø¯Ù KA Ù…Ù‚Ø§Ø¨Ù„ Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª Ø§Ù„ÙØ¹Ù„ÙŠØ© Ø­Ø³Ø¨ Ø§Ù„Ø¨Ø§Ø¦Ø¹",
        "top10_py_sub": "ğŸ“Š Ø£ÙØ¶Ù„ 10 Ø£Ø³Ù…Ø§Ø¡ PY 1 Ø­Ø³Ø¨ Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª",
        "top10_py_title": "Ø£ÙØ¶Ù„ 10 Ø£Ø³Ù…Ø§Ø¡ PY 1 Ø­Ø³Ø¨ Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª",
        "download_reports_sub": "ğŸ’¾ ØªÙ†Ø²ÙŠÙ„ Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ±",
        "generate_pptx": "ğŸ“‘ ØªÙˆÙ„ÙŠØ¯ ØªÙ‚Ø±ÙŠØ± PPTX",
        "download_pptx": "â¬‡ï¸ ØªÙ†Ø²ÙŠÙ„ ØªÙ‚Ø±ÙŠØ± PPTX",
        "ytd_title": "ğŸ“Š Ù…Ù‚Ø§Ø±Ù†Ø© Ù…Ù† Ø¨Ø¯Ø§ÙŠØ© Ø§Ù„Ø³Ù†Ø©",
        "ytd_filters_header": "ğŸ” ÙÙ„Ø§ØªØ± (YTD)",
        "ytd_filters_tooltip": "ØªØµÙÙŠØ© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø­Ø³Ø¨ Ø§Ù„Ø¨Ø§Ø¦Ø¹ÙŠÙ†ØŒ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„ÙÙˆØ§ØªÙŠØ±ØŒ PYØŒ SPØŒ ÙˆÙ†Ø·Ø§Ù‚ Ø§Ù„ØªØ§Ø±ÙŠØ®.",
        "ytd_select_group": "Ø§Ù„ØªØ¬Ù…ÙŠØ¹ Ø­Ø³Ø¨",
        "ytd_select_value": "Ø¹Ù…ÙˆØ¯ Ø§Ù„Ù‚ÙŠÙ…Ø©",
        "ytd_period1": "Ø§Ø®ØªØ± Ø§Ù„ÙØªØ±Ø© 1",
        "ytd_period2": "Ø§Ø®ØªØ± Ø§Ù„ÙØªØ±Ø© 2",
        "ytd_no_data": "âš ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ØªØ·Ø§Ø¨Ù‚ Ø§Ù„ÙÙ„Ø§ØªØ±.",
        "ytd_comparison_sub": "ğŸ“‹ Ø¬Ø¯ÙˆÙ„ Ù…Ù‚Ø§Ø±Ù†Ø© YTD",
        "ytd_download": "â¬‡ï¸ ØªÙ†Ø²ÙŠÙ„ Ù…Ù‚Ø§Ø±Ù†Ø© YTD (Ø¥ÙƒØ³Ù„)",
        "ytd_chart_title": "Ø±Ø³Ù… Ø¨ÙŠØ§Ù†ÙŠ Ù„Ù…Ù‚Ø§Ø±Ù†Ø© YTD",
        "custom_title": "ğŸ“Š ØªØ­Ù„ÙŠÙ„ Ù…Ø®ØµØµ",
        "custom_upload": "ØªØ­Ù…ÙŠÙ„ ÙˆØ±Ù‚Ø© Ø¥Ø¶Ø§ÙÙŠØ© (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)",
        "custom_extra_loaded": "âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙˆØ±Ù‚Ø© Ø§Ù„Ø¥Ø¶Ø§ÙÙŠØ©.",
        "custom_select_sheet": "ğŸ“‘ Ø§Ø®ØªØ± Ø§Ù„ÙˆØ±Ù‚Ø© Ù„Ù„ØªØ­Ù„ÙŠÙ„",
        "custom_sheet_empty": "âš ï¸ Ø§Ù„ÙˆØ±Ù‚Ø© '{0}' ÙØ§Ø±ØºØ© Ø£Ùˆ ØºÙŠØ± Ù…ØªÙˆÙØ±Ø© ÙÙŠ Ù…Ù„ÙÙƒ.",
        "custom_explore": "ğŸ’¡ Ø§Ø³ØªÙƒØ´Ù Ø¨ÙŠØ§Ù†Ø§ØªÙƒ Ø­Ø³Ø¨ Ø£Ø¹Ù…Ø¯Ø© Ù…ØªØ¹Ø¯Ø¯Ø© ÙˆÙ‚Ø§Ø±Ù† ÙØªØ±ØªÙŠÙ†.",
        "custom_group_cols": "Ø§Ù„ØªØ¬Ù…ÙŠØ¹ Ø­Ø³Ø¨ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©",
        "custom_value_col": "Ø§Ù„Ù‚ÙŠÙ…Ø© Ù„Ù„ØªØ­Ù„ÙŠÙ„",
        "custom_periods_sub": "ğŸ“† Ø§Ø®ØªØ± ÙØªØ±ØªÙŠÙ†",
        "custom_period1": "Ø§Ù„ÙØªØ±Ø© 1",
        "custom_period2": "Ø§Ù„ÙØªØ±Ø© 2",
        "custom_select_p1": "Ø§Ø®ØªØ± Ø§Ù„ÙØªØ±Ø© 1",
        "custom_select_p2": "Ø§Ø®ØªØ± Ø§Ù„ÙØªØ±Ø© 2",
        "custom_select_prompt": "ğŸ‘‰ ÙŠØ±Ø¬Ù‰ Ø§Ø®ØªÙŠØ§Ø± Ø¹Ù…ÙˆØ¯ ØªØ¬Ù…ÙŠØ¹ ÙˆØ§Ø­Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„ØŒ Ø¹Ù…ÙˆØ¯ Ù‚ÙŠÙ…Ø© ÙˆØ§Ø­Ø¯ØŒ ÙˆÙ†Ø·Ø§Ù‚Ø§Øª ØªØ§Ø±ÙŠØ® ØµØ§Ù„Ø­Ø©.",
        "custom_comparison_sub": "ğŸ“‹ Ù…Ù‚Ø§Ø±Ù†Ø© {0} Ø­Ø³Ø¨ {1}",
        "custom_download": "â¬‡ï¸ ØªÙ†Ø²ÙŠÙ„ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© (Ø¥ÙƒØ³Ù„)",
        "target_alloc_title": "ğŸ¯ ØªØ®ØµÙŠØµ Ø£Ù‡Ø¯Ø§Ù SP/PY",
        "target_config_sub": "Ø§Ù„ØªÙƒÙˆÙŠÙ†",
        "target_alloc_tooltip": "ØªØ®ØµÙŠØµ Ø§Ù„Ø£Ù‡Ø¯Ø§Ù Ø­Ø³Ø¨ Ø§Ù„ÙØ±Ø¹ Ø£Ùˆ Ø§Ù„Ø¹Ù…ÙŠÙ„ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ©.",
        "target_alloc_type": "Ø§Ø®ØªØ± Ù†ÙˆØ¹ ØªØ®ØµÙŠØµ Ø§Ù„Ù‡Ø¯Ù",
        "target_alloc_options": ["Ø­Ø³Ø¨ Ø§Ù„ÙØ±Ø¹ (SP Name1)", "Ø§Ù„Ø¹Ù…ÙŠÙ„ (PY Name 1)"],
        "target_input_option": "Ø§Ø®ØªØ± Ø®ÙŠØ§Ø± Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ù‡Ø¯Ù",
        "target_input_options": ["ÙŠØ¯ÙˆÙŠ", "ØªÙ„Ù‚Ø§Ø¦ÙŠ (Ù…Ù† ÙˆØ±Ù‚Ø© 'Target')"],
        "target_enter_total": "Ø£Ø¯Ø®Ù„ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù‡Ø¯Ù Ù„Ù„ØªØ®ØµÙŠØµ Ù„Ù‡Ø°Ø§ Ø§Ù„Ø´Ù‡Ø± (Ø¯.Ùƒ)",
        "target_auto_info": "Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù‡Ø¯Ù Ù…Ù† ÙˆØ±Ù‚Ø© 'Target': Ø¯.Ùƒ {0:,.0f}",
        "target_zero_warning": "ÙŠØ±Ø¬Ù‰ Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù‡Ø¯Ù Ø£ÙƒØ¨Ø± Ù…Ù† 0.",
        "target_hist_sub": "ÙØªØ±Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ©",
        "target_hist_option": "Ø§Ø®ØªØ± ÙØªØ±Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ©",
        "target_hist_options": ["Ø¢Ø®Ø± 6 Ø£Ø´Ù‡Ø±", "Ø£ÙŠØ§Ù… ÙŠØ¯ÙˆÙŠØ©"],
        "target_select_range": "Ø§Ø®ØªØ± Ù†Ø·Ø§Ù‚ Ø§Ù„ØªØ§Ø±ÙŠØ®",
        "target_date_warning": "ÙŠØ±Ø¬Ù‰ Ø§Ø®ØªÙŠØ§Ø± ØªØ§Ø±ÙŠØ® Ø¨Ø¯Ø§ÙŠØ© ÙˆÙ†Ù‡Ø§ÙŠØ©.",
        "target_no_hist": "âš ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø¨ÙŠØ¹Ø§Øª Ù…ØªÙˆÙØ±Ø© ÙÙŠ 'YTD' Ù„Ù€ {0}.",
        "target_analysis_sub": "ğŸ¯ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‡Ø¯Ù",
        "hist_sales_total": "Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ©",
        "alloc_target_total": "Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù‡Ø¯Ù Ø§Ù„Ù…Ø®ØµØµ",
        "increase_needed": "Ø§Ù„Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ù…Ù‚Ø§Ø¨Ù„ Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª",
        "current_month_sales": "Ù…Ø¨ÙŠØ¹Ø§Øª Ø§Ù„Ø´Ù‡Ø± Ø§Ù„Ø­Ø§Ù„ÙŠ",
        "target_balance": "Ø±ØµÙŠØ¯ Ø§Ù„Ù‡Ø¯Ù",
        "alloc_targets_sub": "ğŸ“Š Ø§Ù„Ø£Ù‡Ø¯Ø§Ù Ø§Ù„Ù…Ø®ØµØµØ© ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ {0}",
        "download_alloc": "ğŸ’¾ ØªÙ†Ø²ÙŠÙ„ Ø¬Ø¯ÙˆÙ„ ØªØ®ØµÙŠØµ Ø§Ù„Ù‡Ø¯Ù",
        "ai_title": "ğŸ¤– Ø±Ø¤Ù‰ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ",
        "ai_scope_sub": "Ø§Ù„Ù†Ø·Ø§Ù‚ ÙˆØ§Ù„ÙÙ„Ø§ØªØ±",
        "ai_select_period": "Ø§Ø®ØªØ± Ø§Ù„ÙØªØ±Ø© Ù„Ù„Ø±Ø¤Ù‰",
        "ai_top_n": "Ø£Ø¨Ø±Ø² Ø£ÙØ¶Ù„ N Ø¨Ø§Ø¦Ø¹ÙŠÙ†",
        "ai_no_data": "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ Ø§Ù„ÙØªØ±Ø© Ø§Ù„Ù…Ø®ØªØ§Ø±Ø©. Ø¬Ø±Ø¨ ØªÙˆØ³ÙŠØ¹ Ù†Ø·Ø§Ù‚ Ø§Ù„ØªØ§Ø±ÙŠØ®.",
        "ai_exec_sub": "ğŸ“œ Ù…Ù„Ø®Øµ ØªÙ†ÙÙŠØ°ÙŠ",
        "ai_prescript_sub": "ğŸ› ï¸ ØªÙˆØµÙŠØ§Øª Ø¥Ø±Ø´Ø§Ø¯ÙŠØ©",
        "ai_visual_sub": "ğŸ“Š Ø±Ø³ÙˆÙ… Ø¨ÙŠØ§Ù†ÙŠØ© Ù…ÙˆÙ„Ø¯Ø© Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ",
        "ai_section_sub": "ğŸ§­ Ø±Ø¤Ù‰ Ø­Ø³Ø¨ Ø§Ù„Ù‚Ø³Ù…",
        "ai_download_sub": "ğŸ“¥ ØªÙ†Ø²ÙŠÙ„ Ø§Ù„Ù…Ù„Ø®Øµ Ø§Ù„ØªÙ†ÙÙŠØ°ÙŠ",
        "ai_download_button": "ğŸ’¾ ØªÙ†Ø²ÙŠÙ„ Ù…Ù„Ø®Øµ ØªÙ†ÙÙŠØ°ÙŠ AI (TXT)",
        "ai_ask_sub": "ğŸ’¬ Ø§Ø³Ø£Ù„ Ø³Ø¤Ø§Ù„Ø§Ù‹ Ø¹Ù† Ø¨ÙŠØ§Ù†Ø§ØªÙƒ",
        "ai_ask_prompt": "Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ø§Ù‹ (Ù…Ø«Ù„ 'Ø£ÙŠ Ø¨Ø§Ø¦Ø¹ ÙŠÙ†Ù…Ùˆ Ø£Ø³Ø±Ø¹ØŸ'ØŒ 'Ø£ÙŠÙ† Ø§Ù„Ù…Ø±ØªØ¬Ø¹Ø§Øª Ø£Ø¹Ù„Ù‰ØŸ'ØŒ 'Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø· Ø¨ÙŠÙ† Ø§Ù„Ø£Ù‡Ø¯Ø§Ù ÙˆØ§Ù„Ù…Ø¨ÙŠØ¹Ø§ØªØŸ')",
        "admin_tools": "Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ø¥Ø¯Ø§Ø±Ø©",
        "view_logs": "Ø¹Ø±Ø¶ Ø³Ø¬Ù„Ø§Øª Ø§Ù„ØªØ¯Ù‚ÙŠÙ‚",
        "audit_title": "ğŸ“‹ Ø³Ø¬Ù„Ø§Øª Ø§Ù„ØªØ¯Ù‚ÙŠÙ‚",
        "download_logs": "â¬‡ï¸ ØªÙ†Ø²ÙŠÙ„ Ø³Ø¬Ù„Ø§Øª Ø§Ù„ØªØ¯Ù‚ÙŠÙ‚ (Ø¥ÙƒØ³Ù„)",
        "sheet_missing": "âŒ Ù…Ù„Ù Ø§Ù„Ø¥ÙƒØ³Ù„ ÙŠØ¬Ø¨ Ø£Ù† ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø£ÙˆØ±Ø§Ù‚: {0}. Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©: {1}",
        "cols_missing": "âŒ Ø£Ø¹Ù…Ø¯Ø© Ù…Ø·Ù„ÙˆØ¨Ø© Ù…ÙÙ‚ÙˆØ¯Ø©: {0}",
        "load_error": "âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù Ø§Ù„Ø¥ÙƒØ³Ù„: {0}",
        "pptx_title": "ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª ÙˆØ§Ù„Ø£Ù‡Ø¯Ø§Ù",
        "pptx_generated": "ØªÙ… ØªÙˆÙ„ÙŠØ¯Ù‡ ÙÙŠ {0}",
        "pptx_kpi_title": "ğŸ“ˆ Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©",
        "pptx_summary_title": "ğŸ“‹ Ù…Ù„Ø®Øµ Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª ÙˆØ§Ù„Ø£Ù‡Ø¯Ø§Ù",
        "pptx_billing_title": "ğŸ“Š Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„ÙØ§ØªÙˆØ±Ø© Ù„ÙƒÙ„ Ø¨Ø§Ø¦Ø¹",
        "pptx_py_title": "ğŸ¬ Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª Ø­Ø³Ø¨ Ø§Ø³Ù… PY 1",
        "pptx_embed_error": "Ù„Ø§ ÙŠÙ…ÙƒÙ† ØªØ¶Ù…ÙŠÙ† Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ: {0}. Ù‚Ù… Ø¨ØªØ«Ø¨ÙŠØª kaleido Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ÙÙ‚ÙˆØ¯Ø§Ù‹.",
        "generating_pptx": "â³ Ø¬Ø§Ø±ÙŠ ØªÙˆÙ„ÙŠØ¯ ØªÙ‚Ø±ÙŠØ± PPTX...",
        "loading_data": "â³ Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¥ÙƒØ³Ù„...",
    }
}

# --- Page Config ---
st.set_page_config(page_title=texts[lang]["page_title"], layout=texts[lang]["layout"], page_icon=texts[lang]["page_icon"])

# --- Streamlit Authenticator (v0.4.2) ---
# Hash the plain-text passwords
hashed_passwords = [
    stauth.Hasher.hash("admin123"),
    stauth.Hasher.hash("salesman1"),
    stauth.Hasher.hash("salesman2")
]

# Define credentials
credentials = {
    "usernames": {
        "admin": {
            "email": "admin@example.com",
            "name": "Admin User",
            "password": hashed_passwords[0],
            "role": "admin"
        },
        "salesman1": {
            "email": "sales1@example.com",
            "name": "Salesman One",
            "password": hashed_passwords[1],
            "role": "salesman",
            "salesman_name": "Salesman One"
        },
        "salesman2": {
            "email": "sales2@example.com",
            "name": "Salesman Two",
            "password": hashed_passwords[2],
            "role": "salesman",
            "salesman_name": "Salesman Two"
        }
    }
}

# Initialize authenticator
authenticator = stauth.Authenticate(
    credentials,
    cookie_name="sales_app",
    key="auth_key",
    cookie_expiry_days=30
)

# Initialize variables
user_role = None
salesman_name = None
username = None

# --- Login ---
authenticator.login(location="main")

if st.session_state.get("authentication_status"):
    st.success(texts[lang]["welcome"].format(st.session_state["name"]))
    authenticator.logout(texts[lang]["logout"], location="sidebar")
    username = st.session_state["username"]
    user_role = credentials["usernames"][username]["role"]
    salesman_name = credentials["usernames"][username].get("salesman_name", None)

elif st.session_state.get("authentication_status") is False:
    st.error(texts[lang]["incorrect_login"])
    st.stop()

elif st.session_state.get("authentication_status") is None:
    st.warning(texts[lang]["no_login"])
    st.stop()

# --- Custom CSS for Visual Enhancements ---
st.markdown(
    """
    <style>
    /* General layout and typography */
    .main {
        background-color: #F8FAFC;
        padding: 30px;
        border-radius: 12px;
        box-shadow: 0 10px 25px rgba(0, 0, 0, 0.05);
        transition: background-color 0.3s;
    }
    h1, h2, h3 {
        font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
        color: #0F172A;
        margin-bottom: 15px;
        font-weight: 700;
    }

    /* Buttons */
    .stButton>button {
        background: linear-gradient(135deg, #1565C0, #1E88E5);
        color: white;
        border: 2px solid #0EA5E9;
        border-radius: 12px;
        padding: 12px 24px;
        font-weight: 700;
        letter-spacing: 0.3px;
        transition: all 0.2s ease;
        box-shadow: 0 6px 18px rgba(2,132,199,0.25);
    }
    .stButton>button:hover {
        transform: translateY(-1px);
        box-shadow: 0 10px 20px rgba(2,132,199,0.35);
    }

    /* Dataframe (tables) */
    .dataframe {
        border-radius: 12px !important;
        overflow: hidden !important;
        box-shadow: 0 4px 16px rgba(0, 0, 0, 0.08);
        border: 1px solid #E2E8F0;
    }
    .dataframe th {
        background: #1E3A8A !important; /* Dark blue for headers */
        color: #FFFFFF !important;
        font-weight: 800 !important;
        padding: 12px !important;
        text-transform: uppercase;
        letter-spacing: 0.4px;
        height: 40px !important; /* Fixed header height */
        line-height: 40px !important;
        border: 1px solid #E5E7EB !important;
    }
    .dataframe td {
        background-color: #FFFFFF;
        border: 1px solid #E5E7EB !important;
        padding: 10px !important;
        font-weight: 600;
        color: #0F172A;
        height: 40px !important; /* Fixed row height */
        line-height: 40px !important;
        vertical-align: middle !important;
    }

    /* Sidebar */
    .css-1d391kg {
        background-color: #E2E8F0;
        border-radius: 12px;
        padding: 20px;
        box-shadow: 0 4px 10px rgba(0, 0, 0, 0.05);
    }

    /* Metric card styling with pretty border */
    div[data-testid="stMetric"] {
        border: 2px solid #38BDF8;
        border-radius: 14px;
        padding: 16px 14px;
        background: linear-gradient(180deg, #FFFFFF, #F0F9FF);
        box-shadow: 0 10px 20px rgba(56,189,248,0.25);
        white-space: nowrap;
        overflow: visible;
    }
    div[data-testid="stMetric"] > div {
        color: #0F172A !important;
        font-size: 16px;
    }

    /* Dark mode */
    .dark-mode .main { background-color: #1F2937; }
    .dark-mode h1, .dark-mode h2, .dark-mode h3 { color: #F3F4F6; }
    .dark-mode .dataframe td { background-color: #111827; color: #F3F4F6; }
    .dark-mode .dataframe th { background: #1E3A8A !important; } /* Dark blue headers in dark mode */
    .dark-mode div[data-testid="stMetric"] { background: linear-gradient(180deg,#111827,#0B1220); border-color:#60A5FA; box-shadow: 0 10px 20px rgba(59,130,246,0.25); }

    /* Tooltip */
    .tooltip { position: relative; display: inline-block; cursor: pointer; }
    .tooltip .tooltiptext {
        visibility: hidden; width: 220px; background-color: #0F172A; color: #fff; text-align: center;
        border-radius: 8px; padding: 8px; position: absolute; z-index: 1; bottom: 125%; left: 50%; margin-left: -110px;
        opacity: 0; transition: opacity 0.3s;
    }
    .tooltip:hover .tooltiptext { visibility: visible; opacity: 1; }

    .progress-bar {
        background-color: #e0e0e0;
        border-radius: 10px;
        margin-top: 5px;
    }
    .progress-bar-fill {
        background-color: #4CAF50;
        height: 15px;
        border-radius: 10px;
        text-align: right;
        padding-right: 5px;
        color: white;
        font-weight: bold;
        transition: width 0.5s ease-in-out;
    }

    /* Green caption styling for specific percentage captions */
    .green-caption {
        color: #15803D !important;
        font-weight: 600;
        font-size: 14px;
    }
    .dark-mode .green-caption {
        color: #6EE7B7 !important; /* Lighter green for dark mode */
    }
    </style>
    """,
    unsafe_allow_html=True
)

# --- Dark Mode Toggle ---
if "dark_mode" not in st.session_state:
    st.session_state.dark_mode = False

st.sidebar.checkbox(
    texts[lang]["dark_mode"],
    value=st.session_state.dark_mode,
    key="dark_mode_toggle",
    on_change=lambda: setattr(st.session_state, "dark_mode", not st.session_state.dark_mode)
)

if st.session_state.dark_mode:
    st.markdown('<script>document.body.classList.add("dark-mode");</script>', unsafe_allow_html=True)
else:
    st.markdown('<script>document.body.classList.remove("dark-mode");</script>', unsafe_allow_html=True)

# --- Cache Data Loading ---
@st.cache_data
def load_data(file):
    with st.spinner(texts[lang]["loading_data"]):
        try:
            xls = pd.ExcelFile(file)
            required_sheets = ["sales data", "Target", "sales channels"]
            missing = [s for s in required_sheets if s not in xls.sheet_names]
            if missing:
                st.error(texts[lang]["sheet_missing"].format(', '.join(required_sheets), ', '.join(missing)))
                return pd.DataFrame(), pd.DataFrame(), pd.DataFrame(), pd.DataFrame()

            sales_df = pd.read_excel(xls, sheet_name="sales data")
            target_df = pd.read_excel(xls, sheet_name="Target")
            channels_df = pd.read_excel(xls, sheet_name="sales channels")
            ytd_df = pd.read_excel(xls, sheet_name="YTD") if "YTD" in xls.sheet_names else pd.DataFrame()

            required_cols = ["Billing Date", "Driver Name EN", "Net Value", "Billing Type", "PY Name 1", "SP Name1"]
            if not all(col in sales_df.columns for col in required_cols):
                st.error(texts[lang]["cols_missing"].format(set(required_cols) - set(sales_df.columns)))
                return pd.DataFrame(), pd.DataFrame(), pd.DataFrame(), pd.DataFrame()

            def normalize_series(s):
                try:
                    return s.astype(str).str.strip().str.lower().replace({'nan': ''})
                except Exception:
                    return s

            sales_df["Billing Date"] = pd.to_datetime(sales_df["Billing Date"], errors='coerce')
            if "PY Name 1" in sales_df.columns:
                sales_df["_py_name_norm"] = normalize_series(sales_df["PY Name 1"])
            else:
                sales_df["_py_name_norm"] = ""

            if "PY Name 1" in channels_df.columns:
                channels_df["_py_name_norm"] = normalize_series(channels_df["PY Name 1"])
            else:
                channels_df["_py_name_norm"] = ""
            if "Channels" in channels_df.columns:
                channels_df["_channels_norm"] = normalize_series(channels_df["Channels"])
            else:
                channels_df["_channels_norm"] = ""

            if not ytd_df.empty and "Billing Date" in ytd_df.columns:
                ytd_df["Billing Date"] = pd.to_datetime(ytd_df["Billing Date"], errors='coerce')
            if not ytd_df.empty and "PY Name 1" in ytd_df.columns:
                ytd_df["_py_name_norm"] = normalize_series(ytd_df["PY Name 1"])

            # Hash sensitive columns for privacy (e.g., Driver Name EN)
            def hash_column(col):
                return col.apply(lambda x: hashlib.sha256(str(x).encode()).hexdigest() if pd.notnull(x) else x)

            sales_df["Driver Name EN Hashed"] = hash_column(sales_df["Driver Name EN"])
            if "Driver Name EN" in ytd_df.columns:
                ytd_df["Driver Name EN Hashed"] = hash_column(ytd_df["Driver Name EN"])
            if "Driver Name EN" in target_df.columns:
                target_df["Driver Name EN Hashed"] = hash_column(target_df["Driver Name EN"])

            return sales_df, target_df, ytd_df, channels_df
        except Exception as e:
            st.error(texts[lang]["load_error"].format(e))
            return pd.DataFrame(), pd.DataFrame(), pd.DataFrame(), pd.DataFrame()

# --- Helpers: Downloads ---
@st.cache_data
def to_excel_bytes(df: pd.DataFrame, sheet_name: str = "Sheet1", index: bool = False) -> bytes:
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
        df.to_excel(writer, sheet_name=sheet_name, index=index)
    return output.getvalue()

@st.cache_data
def to_multi_sheet_excel_bytes(dfs, sheet_names) -> bytes:
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
        for df, sn in zip(dfs, sheet_names):
            df.to_excel(writer, sheet_name=sn, index=True)
    return output.getvalue()

# --- PPTX Export ---
def create_pptx(report_df, billing_df, py_table, figs_dict, kpi_data):
    with st.spinner(texts[lang]["generating_pptx"]):
        prs = Presentation()
        slide_layout = prs.slide_layouts[0]
        slide = prs.slides.add_slide(slide_layout)
        title = slide.shapes.title
        title.text = texts[lang]["pptx_title"]
        title.text_frame.paragraphs[0].font.size = Pt(32)
        title.text_frame.paragraphs[0].font.name = 'Roboto'
        title.text_frame.paragraphs[0].font.color.rgb = RGBColor(30, 58, 138)
        try:
            subtitle = slide.placeholders[1]
            subtitle.text = texts[lang]["pptx_generated"].format(datetime.now().strftime('%Y-%m-%d'))
            subtitle.text_frame.paragraphs[0].font.size = Pt(18)
            subtitle.text_frame.paragraphs[0].font.name = 'Roboto'
            subtitle.text_frame.paragraphs[0].font.color.rgb = RGBColor(55, 65, 81)
        except Exception:
            pass

        slide_layout = prs.slide_layouts[5]
        slide = prs.slides.add_slide(slide_layout)
        slide.shapes.title.text = texts[lang]["pptx_kpi_title"]
        slide.shapes.title.text_frame.paragraphs[0].font.size = Pt(24)
        slide.shapes.title.text_frame.paragraphs[0].font.name = 'Roboto'
        slide.shapes.title.text_frame.paragraphs[0].font.color.rgb = RGBColor(30, 58, 138)

        rows = 4
        cols = 3
        left = Inches(1)
        top = Inches(1.5)
        width = Inches(8)
        height = Inches(4)
        table = slide.shapes.add_table(rows, cols, left, top, width, height).table
        kpi_list = list(kpi_data.items())
        for i in range(rows):
            for j in range(cols):
                index = i * cols + j
                if index < len(kpi_list):
                    label, value = kpi_list[index]
                    cell = table.cell(i, j)
                    cell.text = f"{label}\n{value}"
                    cell.text_frame.paragraphs[0].font.size = Pt(12)
                    cell.text_frame.paragraphs[0].font.name = 'Roboto'
                    cell.text_frame.paragraphs[0].font.bold = True
                    cell.fill.solid()
                    cell.fill.fore_color.rgb = RGBColor(243, 244, 246)

        def add_table_slide(df, title):
            slide_layout = prs.slide_layouts[5]
            slide = prs.slides.add_slide(slide_layout)
            slide.shapes.title.text = title
            slide.shapes.title.text_frame.paragraphs[0].font.size = Pt(24)
            slide.shapes.title.text_frame.paragraphs[0].font.name = 'Roboto'
            slide.shapes.title.text_frame.paragraphs[0].font.color.rgb = RGBColor(30, 58, 138)
            rows, cols = df.shape
            table = slide.shapes.add_table(rows + 1, cols, Inches(0.5), Inches(1.5), Inches(9), Inches(4)).table
            for j, col in enumerate(df.columns):
                cell = table.cell(0, j)
                cell.text = str(col)
                cell.text_frame.paragraphs[0].font.size = Pt(14)
                cell.text_frame.paragraphs[0].font.name = 'Roboto'
                cell.text_frame.paragraphs[0].font.bold = True
                cell.text_frame.paragraphs[0].font.color.rgb = RGBColor(255, 255, 255)
                cell.fill.solid()
                cell.fill.fore_color.rgb = RGBColor(30, 58, 138)
            for i, row in enumerate(df.itertuples(index=False), start=1):
                for j, val in enumerate(row):
                    cell = table.cell(i, j)
                    if isinstance(val, (int, float, np.integer, np.floating)):
                        cell.text = f"{val:,.0f}"
                    else:
                        cell.text = str(val)
                    cell.text_frame.paragraphs[0].font.size = Pt(12)
                    cell.text_frame.paragraphs[0].font.name = 'Roboto'
                    cell.fill.solid()
                    cell.fill.fore_color.rgb = RGBColor(243, 244, 246) if i % 2 == 0 else RGBColor(255, 255, 255)

        def add_chart_slide(fig, title):
            slide_layout = prs.slide_layouts[5]
            slide = prs.slides.add_slide(slide_layout)
            slide.shapes.title.text = title
            slide.shapes.title.text_frame.paragraphs[0].font.size = Pt(24)
            slide.shapes.title.text_frame.paragraphs[0].font.name = 'Roboto'
            slide.shapes.title.text_frame.paragraphs[0].font.color.rgb = RGBColor(30, 58, 138)
            img_stream = io.BytesIO()
            try:
                fig.write_image(img_stream, format="png", width=800, height=600)
                img_stream.seek(0)
                slide.shapes.add_picture(img_stream, Inches(0.5), Inches(1.5), width=Inches(9))
            except Exception as e:
                slide.shapes.add_textbox(Inches(0.5), Inches(1.5), Inches(9), Inches(4)).text_frame.text = (
                    texts[lang]["pptx_embed_error"].format(e)
                )

        add_table_slide(report_df.reset_index(), texts[lang]["pptx_summary_title"])
        add_table_slide(billing_df.reset_index(), texts[lang]["pptx_billing_title"])
        add_table_slide(py_table.reset_index(), texts[lang]["pptx_py_title"])
        for key, fig in figs_dict.items():
            add_chart_slide(fig, key)
        pptx_stream = io.BytesIO()
        prs.save(pptx_stream)
        pptx_stream.seek(0)
        return pptx_stream

# --- Positive/Negative Coloring ---
def color_positive_negative(val):
    try:
        v = float(val)
        color = "#15803D" if v > 0 else "#B91C1C" if v < 0 else ""
        return f"color: {color}; font-weight: bold"
    except:
        return ""

def create_progress_bar_html(percentage):
    safe_pct = max(0, min(100, percentage))
    fill_color = "#4CAF50" if safe_pct >= 100 else "#2196F3"
    html = f"""
    <div style="background-color: #f0f0f0; border-radius: 5px; height: 10px; margin-top: 5px;">
        <div style="background-color: {fill_color}; height: 100%; width: {safe_pct}%; border-radius: 5px; text-align: right; font-size: 8px; color: white;">
        </div>
    </div>
    """
    return html

# --- SINGLE SIDEBAR UPLOADER ---
st.sidebar.header(texts[lang]["upload_header"])
st.sidebar.markdown(f'<div class="tooltip">â„¹ï¸<span class="tooltiptext">{texts[lang]["upload_tooltip"]}</span></div>', unsafe_allow_html=True)
uploaded = st.sidebar.file_uploader("", type=["xlsx"], key="single_upload")
if st.sidebar.button(texts[lang]["clear_data"]):
    for k in ["sales_df", "target_df", "ytd_df", "channels_df", "data_loaded"]:
        if k in st.session_state:
            del st.session_state[k]
    st.experimental_rerun()

if uploaded is not None and "data_loaded" not in st.session_state:
    sales_df, target_df, ytd_df, channels_df = load_data(uploaded)
    st.session_state["sales_df"] = sales_df
    st.session_state["target_df"] = target_df
    st.session_state["ytd_df"] = ytd_df
    st.session_state["channels_df"] = channels_df
    st.session_state["data_loaded"] = True
    st.session_state["audit_log"] = []  # Initialize audit log
    st.success(texts[lang]["file_loaded"])

    # Log upload action
    st.session_state["audit_log"].append({
        "user": username,
        "action": "upload_file",
        "details": uploaded.name,
        "timestamp": datetime.now().isoformat()
    })

# --- Sidebar Menu with multilingual support ---
st.sidebar.title(texts[lang]["menu_title"])

menu = [
    texts[lang]["home"],
    texts[lang]["sales_tracking"],
    texts[lang]["ytd_comparison"],
    texts[lang]["custom_analysis"],
    texts[lang]["target_allocation"],
    texts[lang]["ai_insights"],
    texts[lang]["customer_insights"],
    texts[lang]["material_forecast"],  # Add this line
    texts[lang]["product_availability_checker"]
]
choice = st.sidebar.selectbox(texts[lang]["navigate"], menu)
# Role-based filtering for data
if "data_loaded" in st.session_state:
    sales_df = st.session_state["sales_df"].copy()
    target_df = st.session_state["target_df"].copy()
    ytd_df = st.session_state["ytd_df"].copy()
    channels_df = st.session_state["channels_df"].copy()

    if user_role == "salesman" and salesman_name:
        sales_df = sales_df[sales_df["Driver Name EN"] == salesman_name]
        ytd_df = ytd_df[ytd_df.get("Driver Name EN", pd.Series()) == salesman_name]
        target_df = target_df[target_df.get("Driver Name EN", pd.Series()) == salesman_name]

# --- Home Page ---
if choice == texts[lang]["home"]:
    st.title(texts[lang]["home_title"])
    with st.container():
        st.markdown(
            texts[lang]["home_welcome"],
            unsafe_allow_html=True
        )
    if "data_loaded" in st.session_state: st.success(texts[lang]["data_loaded_msg"])
    else: st.info(texts[lang]["upload_prompt"])


# --- Sales Tracking Page ---
elif choice == texts[lang]["sales_tracking"]:
    st.title(texts[lang]["sales_tracking_title"])
    if "data_loaded" not in st.session_state:
        st.warning(texts[lang]["no_data_warning"])
    else:
        # Filters
        st.sidebar.subheader(texts[lang]["filters_header"])
        st.sidebar.markdown(f'<div class="tooltip">â„¹ï¸<span class="tooltiptext">{texts[lang]["filters_tooltip"]}</span></div>', unsafe_allow_html=True)
        salesmen = st.sidebar.multiselect(
            texts[lang]["select_salesmen"],
            options=sorted(sales_df["Driver Name EN"].dropna().unique()),
            default=sorted(sales_df["Driver Name EN"].dropna().unique()),
            key="st_salesmen"
        )
        billing_types = st.sidebar.multiselect(
            texts[lang]["select_billing_types"],
            options=sorted(sales_df["Billing Type"].dropna().unique()),
            default=sorted(sales_df["Billing Type"].dropna().unique()),
            key="st_billing_types"
        )
        py_filter = st.sidebar.multiselect(
            texts[lang]["select_py"],
            options=sorted(sales_df["PY Name 1"].dropna().unique()),
            default=sorted(sales_df["PY Name 1"].dropna().unique()),
            key="st_py_filter"
        )
        sp_filter = st.sidebar.multiselect(
            texts[lang]["select_sp"],
            options=sorted(sales_df["SP Name1"].dropna().unique()),
            default=sorted(sales_df["SP Name1"].dropna().unique()),
            key="st_sp_filter"
        )

        preset = st.sidebar.radio(texts[lang]["date_presets"], texts[lang]["date_presets_options"], key="st_preset")
        today = pd.Timestamp.today().normalize()
        if preset == texts[lang]["date_presets_options"][1]:  # Last 7 Days
            date_range = [today - pd.Timedelta(days=7), today]
        elif preset == texts[lang]["date_presets_options"][2]:  # This Month
            month_start = today.replace(day=1)
            month_end = month_start + pd.offsets.MonthEnd(0)
            date_range = [month_start, month_end]
        elif preset == texts[lang]["date_presets_options"][3]:  # YTD
            date_range = [today.replace(month=1, day=1), today]
        else:
            date_range = st.sidebar.date_input(
                texts[lang]["select_date_range"],
                [sales_df["Billing Date"].min(), sales_df["Billing Date"].max()],
                key="st_date_range"
            )
            if isinstance(date_range, tuple) and len(date_range) == 2:
                date_range = [pd.to_datetime(date_range[0]), pd.to_datetime(date_range[1])]
            else:
                date_range = [sales_df["Billing Date"].min(), sales_df["Billing Date"].max()]

        if date_range[0] > date_range[1]:
            st.error(texts[lang]["date_error"])
        else:
            top_n = st.sidebar.slider(
                texts[lang]["top_n_salesmen"],
                min_value=1,
                max_value=max(1, len(sales_df["Driver Name EN"].dropna().unique())),
                value=min(5, max(1, len(sales_df["Driver Name EN"].dropna().unique()))),
                key="st_topn"
            )

            df_filtered = sales_df[
                (sales_df["Driver Name EN"].isin(salesmen))
                & (sales_df["Billing Type"].isin(billing_types))
                & (sales_df["Billing Date"] >= date_range[0])
                & (sales_df["Billing Date"] <= date_range[1])
                & (sales_df["PY Name 1"].isin(py_filter))
                & (sales_df["SP Name1"].isin(sp_filter))
            ].copy()

            if df_filtered.empty:
                st.warning(texts[lang]["no_match_warning"])
            else:
                billing_start = df_filtered["Billing Date"].min().normalize()
                billing_end = df_filtered["Billing Date"].max().normalize()
                all_days = pd.date_range(billing_start, billing_end, freq="D")
                days_finish = int(sum(1 for d in all_days if d.weekday() != 4))

                current_month_start = today.replace(day=1)
                current_month_end = current_month_start + pd.offsets.MonthEnd(0)
                month_days = pd.date_range(current_month_start, current_month_end, freq="D")
                working_days_current_month = int(sum(1 for d in month_days if d.weekday() != 4))

                # --- Base aggregates ---
                total_sales = df_filtered.groupby("Driver Name EN")["Net Value"].sum()
                talabat_df = df_filtered[df_filtered["PY Name 1"] == "STORES SERVICES KUWAIT CO."]
                talabat_sales = talabat_df.groupby("Driver Name EN")["Net Value"].sum()

                ka_targets = target_df.set_index("Driver Name EN")["KA Target"] if "KA Target" in target_df.columns else pd.Series(dtype=float)
                talabat_targets = target_df.set_index("Driver Name EN")["Talabat Target"] if "Talabat Target" in target_df.columns else pd.Series(dtype=float)

                all_salesmen_idx = total_sales.index.union(talabat_sales.index).union(ka_targets.index).union(talabat_targets.index)
                total_sales = total_sales.reindex(all_salesmen_idx, fill_value=0).astype(float)
                talabat_sales = talabat_sales.reindex(all_salesmen_idx, fill_value=0).astype(float)
                ka_targets = ka_targets.reindex(all_salesmen_idx, fill_value=0).astype(float)
                talabat_targets = talabat_targets.reindex(all_salesmen_idx, fill_value=0).astype(float)

                ka_gap = (ka_targets - total_sales).clip(lower=0)
                talabat_gap = (talabat_targets - talabat_sales).clip(lower=0)

                top_salesmen = total_sales.sort_values(ascending=False).head(top_n).index
                total_sales_top = total_sales.loc[top_salesmen]
                talabat_sales_top = talabat_sales.loc[top_salesmen]
                ka_gap_top = ka_gap.loc[top_salesmen]
                talabat_gap_top = talabat_gap.loc[top_salesmen]

                total_ka_target_all = float(ka_targets.sum())
                total_tal_target_all = float(talabat_targets.sum())
                per_day_ka_target = (total_ka_target_all / working_days_current_month) if working_days_current_month > 0 else 0
                current_sales_per_day = (total_sales.sum() / days_finish) if days_finish > 0 else 0
                forecast_month_end_ka = current_sales_per_day * working_days_current_month

                # --- Channels mapping: Market (Retail) vs E-com ---
                df_py_sales = df_filtered.groupby("_py_name_norm")["Net Value"].sum().reset_index()
                df_channels_merged = df_py_sales.merge(
                    channels_df[["_py_name_norm", "Channels"]],
                    on="_py_name_norm",
                    how="left"
                )
                df_channels_merged["Channels"] = df_channels_merged["Channels"].str.strip().str.lower().fillna("uncategorized")
                channel_sales = df_channels_merged.groupby("Channels")["Net Value"].sum()
                total_retail_sales = float(channel_sales.get("market", 0.0) + channel_sales.get("uncategorized", 0.0))
                total_ecom_sales = float(channel_sales.get("e-com", 0.0))
                total_channel_sales = total_retail_sales + total_ecom_sales
                retail_sales_pct = (total_retail_sales / total_channel_sales * 100) if total_channel_sales > 0 else 0
                ecom_sales_pct = (total_ecom_sales / total_channel_sales * 100) if total_channel_sales > 0 else 0

                # --- KA & Other E-com Calculation ---
                ka_other_ecom_sales = total_sales.sum() - talabat_sales.sum()
                ka_other_ecom_pct = (ka_other_ecom_sales / total_ka_target_all * 100) if total_ka_target_all > 0 else 0

                # --- KPI Data for PPTX ---
                kpi_data = {
                    texts[lang]["ka_target"]: f"KD {total_ka_target_all:,.0f}",
                    texts[lang]["talabat_target"]: f"KD {total_tal_target_all:,.0f}",
                    texts[lang]["ka_gap"]: f"KD {(total_ka_target_all - total_sales.sum()):,.0f}",
                    "Total Talabat Gap": f"KD {talabat_gap.sum():,.0f}",
                    texts[lang]["total_ka_sales"]: f"KD {total_sales.sum():,.0f} ({((total_sales.sum() / total_ka_target_all) * 100):.0f}%)" if total_ka_target_all else f"KD {total_sales.sum():,.0f} (0%)",
                    "Total Talabat Sales": f"KD {talabat_sales.sum():,.0f} ({((talabat_sales.sum() / total_tal_target_all) * 100):.0f}%)" if total_tal_target_all else f"KD {talabat_sales.sum():,.0f} (0%)",
                    texts[lang]["ka_other_ecom"]: f"KD {ka_other_ecom_sales:,.0f} ({ka_other_ecom_pct:.0f}%)",
                    texts[lang]["retail_sales"]: f"KD {total_retail_sales:,.0f} ({retail_sales_pct:.0f}%)",
                    texts[lang]["ecom_sales"]: f"KD {total_ecom_sales:,.0f} ({ecom_sales_pct:.0f}%)",
                    texts[lang]["days_finished"]: f"{days_finish}",
                    "Per Day KA Target": f"KD {per_day_ka_target:,.0f}",
                    texts[lang]["current_sales_per_day"]: f"KD {current_sales_per_day:,.0f}",
                    texts[lang]["forecast_month_end"]: f"KD {forecast_month_end_ka:,.0f}"
                }

                tabs = st.tabs([texts[lang]["kpis_tab"], texts[lang]["tables_tab"], texts[lang]["charts_tab"], texts[lang]["downloads_tab"]])

                # --- KPIs with progress bars ---
                with tabs[0]:
                    st.subheader(texts[lang]["key_metrics_sub"])
                    r1c1 = st.columns(1)[0]
                    with r1c1:
                        st.metric(texts[lang]["total_ka_sales"], f"KD {total_sales.sum():,.0f}")
                        progress_pct_ka = (total_sales.sum() / total_ka_target_all * 100) if total_ka_target_all > 0 else 0
                        st.markdown(create_progress_bar_html(progress_pct_ka), unsafe_allow_html=True)
                        st.markdown(f'<div class="green-caption">{texts[lang]["of_ka_target"].format(progress_pct_ka)}</div>', unsafe_allow_html=True)

                    r2c1, r2c2 = st.columns(2)
                    with r2c1:
                        st.metric(texts[lang]["ka_other_ecom"], f"KD {ka_other_ecom_sales:,.0f}")
                        st.markdown(create_progress_bar_html(ka_other_ecom_pct), unsafe_allow_html=True)
                        st.markdown(f'<div class="green-caption">{texts[lang]["of_ka_target_pct"].format(ka_other_ecom_pct)}</div>', unsafe_allow_html=True)
                    with r2c2:
                        st.metric(texts[lang]["talabat_sales"], f"KD {talabat_sales.sum():,.0f}")
                        progress_pct_talabat = (talabat_sales.sum() / total_tal_target_all * 100) if total_tal_target_all > 0 else 0
                        st.markdown(create_progress_bar_html(progress_pct_talabat), unsafe_allow_html=True)
                        st.markdown(f'<div class="green-caption">{texts[lang]["of_talabat_target"].format(progress_pct_talabat)}</div>', unsafe_allow_html=True)

                    st.subheader(texts[lang]["target_overview_sub"])
                    r3c1, r3c2, r3c3, r3c4 = st.columns(4)
                    r3c1.metric(texts[lang]["ka_target"], f"KD {total_ka_target_all:,.0f}")
                    r3c2.metric(texts[lang]["talabat_target"], f"KD {total_tal_target_all:,.0f}")
                    r3c3.metric(texts[lang]["ka_gap"], f"KD {(total_ka_target_all - total_sales.sum()):,.0f}")
                    r3c4.metric(texts[lang]["talabat_gap"], f"KD {talabat_gap.sum():,.0f}")

                    st.subheader(texts[lang]["channel_sales_sub"])
                    r4c1, r4c2 = st.columns(2)
                    with r4c1:
                        st.metric(texts[lang]["retail_sales"], f"KD {total_retail_sales:,.0f}")
                        retail_contribution_pct = (total_retail_sales / total_sales.sum() * 100) if total_sales.sum() > 0 else 0
                        st.caption(texts[lang]["of_total_ka"].format(retail_contribution_pct))
                    with r4c2:
                        st.metric(texts[lang]["ecom_sales"], f"KD {total_ecom_sales:,.0f}")
                        ecom_contribution_pct = (total_ecom_sales / total_sales.sum() * 100) if total_sales.sum() > 0 else 0
                        st.caption(texts[lang]["of_total_ka"].format(ecom_contribution_pct))

                    st.subheader(texts[lang]["performance_metrics_sub"])
                    r5c1, r5c2, r5c3 = st.columns(3)
                    r5c1.metric(texts[lang]["days_finished"], days_finish)
                    r5c2.metric(texts[lang]["current_sales_per_day"], f"KD {current_sales_per_day:,.0f}")
                    r5c3.metric(texts[lang]["forecast_month_end"], f"KD {forecast_month_end_ka:,.0f}")

                    # --- TABLES ---
                    with tabs[1]:
                        # --- Sales & Targets Summary ---
                        st.subheader(texts[lang]["sales_targets_summary_sub"])
                        report_df = pd.DataFrame({
                            "Salesman": ka_targets.index,
                            "KA Target": ka_targets.values,
                            "KA Sales": total_sales.values,
                            "KA Remaining": ka_gap.values,
                            "KA % Achieved": np.where(ka_targets.values != 0, (total_sales.values / ka_targets.values * 100).round(0), 0),
                            "Talabat Target": talabat_targets.values,
                            "Talabat Sales": talabat_sales.values,
                            "Talabat Remaining": talabat_gap.values,
                            "Talabat % Achieved": np.where(talabat_targets.values != 0, (talabat_sales.values / talabat_targets.values * 100).round(0), 0)
                        })

                        total_row = report_df.sum(numeric_only=True).to_frame().T
                        total_row.index = ["Total"]
                        total_row["KA % Achieved"] = round(total_row["KA Sales"]/total_row["KA Target"]*100,0) if total_row["KA Target"].iloc[0]!=0 else 0
                        total_row["Talabat % Achieved"] = round(total_row["Talabat Sales"]/total_row["Talabat Target"]*100,0) if total_row["Talabat Target"].iloc[0]!=0 else 0

                        total_row = total_row.reset_index(drop=True)
                        total_row["Salesman"] = "Total"
                        total_row = total_row[report_df.columns]
                        report_df_with_total = pd.concat([report_df, total_row], ignore_index=True)

                        def highlight_total_row(row):
                            return ['background-color: #BFDBFE; color: #1E3A8A; font-weight: 900' if row['Salesman'] == "Total" else '' for _ in row]

                        styled_report = (
                            report_df_with_total.style
                            .set_table_styles([
                                {'selector': 'th', 'props': [('background', '#1E3A8A'), ('color', 'white'),
                                                            ('font-weight', '800'), ('height', '40px'),
                                                            ('line-height', '40px'), ('border', '1px solid #E5E7EB')] }
                            ])
                            .apply(highlight_total_row, axis=1)
                            .format("{:,.0f}", subset=["KA Target","KA Sales","KA Remaining",
                                                    "Talabat Target","Talabat Sales","Talabat Remaining"])
                            .format("{:.0f}%", subset=["KA % Achieved","Talabat % Achieved"])
                        )
                        st.dataframe(styled_report, use_container_width=True, hide_index=True)

                        if st.download_button(
                            texts[lang]["download_sales_targets"],
                            data=to_excel_bytes(report_df_with_total, sheet_name="Sales_Targets_Summary", index=False),
                            file_name=f"Sales_Targets_Summary_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                        ):
                            st.session_state["audit_log"].append({
                                "user": username,
                                "action": "download",
                                "details": "Sales & Targets Summary Excel",
                                "timestamp": datetime.now()
                            })


                        # --- Sales by Billing Type per Salesman ---
                        st.subheader(texts[lang]["sales_by_billing_sub"])
                        billing_wide = df_filtered.pivot_table(
                            index="Driver Name EN",
                            columns="Billing Type",
                            values="Net Value",
                            aggfunc="sum",
                            fill_value=0
                        )

                        required_cols_raw = ["ZFR", "YKF2", "YKRE", "YKS1", "YKS2", "ZCAN", "ZRE"]
                        billing_wide = billing_wide.reindex(columns=required_cols_raw, fill_value=0)
                        display_df = billing_wide.rename(columns={"ZFR": "Presales", "YKF2": "HHT"})
                        display_df["Sales Total"] = billing_wide.sum(axis=1)
                        display_df["Return"] = billing_wide["YKRE"] + billing_wide["ZRE"]
                        display_df["Return %"] = np.where(display_df["Sales Total"] != 0,
                                                        (display_df["Return"] / display_df["Sales Total"] * 100).round(0), 0)
                        display_df["Cancel Total"] = billing_wide[["YKS1", "YKS2", "ZCAN"]].sum(axis=1)

                        ordered_cols = ["Presales", "HHT", "Sales Total", "YKS1", "YKS2", "ZCAN",
                                        "Cancel Total", "YKRE", "ZRE", "Return", "Return %"]
                        display_df = display_df.reindex(columns=ordered_cols, fill_value=0)

                        total_row = pd.DataFrame(display_df.sum(numeric_only=True)).T
                        total_row.index = ["Total"]
                        total_row["Return %"] = round((total_row["Return"] / total_row["Sales Total"] * 100), 0) if total_row["Sales Total"].iloc[0] != 0 else 0
                        billing_df = pd.concat([display_df, total_row])
                        billing_df.index.name = "Salesman"

                        def highlight_total_row_billing(row):
                            return ['background-color: #BFDBFE; color: #1E3A8A; font-weight: 900' if row.name == "Total" else '' for _ in row]

                        styled_billing = (
                            billing_df.style
                            .set_table_styles([
                                {'selector': 'th', 'props': [('background', '#1E3A8A'), ('color', 'white'),
                                                            ('font-weight', '800'), ('height', '40px'),
                                                            ('line-height', '40px'), ('border', '1px solid #E5E7EB')] }
                            ])
                            .apply(highlight_total_row_billing, axis=1)
                            .format({
                                "Presales": "{:,.0f}", "HHT": "{:,.0f}", "Sales Total": "{:,.0f}",
                                "YKS1": "{:,.0f}", "YKS2": "{:,.0f}", "ZCAN": "{:,.0f}", "Cancel Total": "{:,.0f}",
                                "YKRE": "{:,.0f}", "ZRE": "{:,.0f}", "Return": "{:,.0f}", "Return %": "{:.0f}%"
                            })
                        )
                        st.dataframe(styled_billing, use_container_width=True, hide_index=False)

                        if st.download_button(
                            texts[lang]["download_billing"],
                            data=to_excel_bytes(billing_df.reset_index(), sheet_name="Billing_Types", index=False),
                            file_name=f"Billing_Types_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                        ):
                            st.session_state["audit_log"].append({
                                "user": username,
                                "action": "download",
                                "details": "Billing Type Table Excel",
                                "timestamp": datetime.now()
                            })


                        # --- Sales by PY Name 1 ---
                        st.subheader(texts[lang]["sales_by_py_sub"])
                        py_table = df_filtered.groupby("PY Name 1")["Net Value"].sum().sort_values(ascending=False).to_frame(name="Sales")
                        py_table["Contribution %"] = np.where(py_table["Sales"] != 0,
                                                            (py_table["Sales"]/py_table["Sales"].sum()*100).round(0), 0)

                        total_row = py_table.sum(numeric_only=True).to_frame().T
                        total_row.index = ["Total"]
                        py_table_with_total = pd.concat([py_table, total_row])
                        py_table_with_total.index.name = "PY Name 1"

                        def highlight_total_row_py(row):
                            return ['background-color: #BFDBFE; color: #1E3A8A; font-weight: 900' if row.name == "Total" else '' for _ in row]

                        styled_py = (
                            py_table_with_total.style
                            .set_table_styles([
                                {'selector': 'th', 'props': [('background', '#1E3A8A'), ('color', 'white'),
                                                            ('font-weight', '800'), ('height', '40px'),
                                                            ('line-height', '40px'), ('border', '1px solid #E5E7EB')] }
                            ])
                            .apply(highlight_total_row_py, axis=1)
                            .format("{:,.0f}", subset=["Sales"])
                            .format("{:.0f}%", subset=["Contribution %"])
                        )
                        st.dataframe(styled_py, use_container_width=True, hide_index=False)

                        if st.download_button(
                            texts[lang]["download_py"],
                            data=to_excel_bytes(py_table_with_total.reset_index(), sheet_name="Sales_by_PY_Name", index=False),
                            file_name=f"Sales_by_PY_Name_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                        ):
                            st.session_state["audit_log"].append({
                                "user": username,
                                "action": "download",
                                "details": "PY Name Table Excel",
                                "timestamp": datetime.now()
                            })


                        # --- Return by SP Name1 ---
                        st.subheader("ğŸ”„ Return by SP Name1")
                        sp_billing = df_filtered.pivot_table(
                            index="SP Name1",
                            columns="Billing Type",
                            values="Net Value",
                            aggfunc="sum",
                            fill_value=0
                        )
                        sp_billing = sp_billing.reindex(columns=required_cols_raw, fill_value=0)
                        sp_billing["Sales Total"] = sp_billing.sum(axis=1)
                        sp_billing["Return"] = sp_billing["YKRE"] + sp_billing["ZRE"]
                        sp_billing["Cancel Total"] = sp_billing[["YKS1", "YKS2", "ZCAN"]].sum(axis=1)
                        sp_billing = sp_billing.rename(columns={"ZFR": "Presales", "YKF2": "HHT"})
                        sp_billing["Return %"] = np.where(sp_billing["Sales Total"] != 0,
                                                        (sp_billing["Return"] / sp_billing["Sales Total"] * 100).round(0), 0)
                        sp_billing = sp_billing.reindex(columns=ordered_cols, fill_value=0).astype(int)

                        total_row = pd.DataFrame(sp_billing.sum(numeric_only=True)).T
                        total_row.index = ["Total"]
                        total_row["Return %"] = round((total_row["Return"]/total_row["Sales Total"]*100), 0) if total_row["Sales Total"].iloc[0]!=0 else 0
                        sp_billing = pd.concat([sp_billing, total_row])

                        def highlight_total_row_sp_return(row):
                            return ['background-color: #BFDBFE; color: #1E3A8A; font-weight: 900' if row.name == "Total" else '' for _ in row]

                        styled_sp_return = (
                            sp_billing.style
                            .set_table_styles([
                                {'selector': 'th', 'props': [('background', '#1E3A8A'), ('color', 'white'),
                                                            ('font-weight', '800'), ('height', '40px'),
                                                            ('line-height', '40px'), ('border', '1px solid #E5E7EB')] }
                            ])
                            .apply(highlight_total_row_sp_return, axis=1)
                            .format({
                                "Presales": "{:,.0f}", "HHT": "{:,.0f}", "Sales Total": "{:,.0f}",
                                "YKS1": "{:,.0f}", "YKS2": "{:,.0f}", "ZCAN": "{:,.0f}", "Cancel Total": "{:,.0f}",
                                "YKRE": "{:,.0f}", "ZRE": "{:,.0f}", "Return": "{:,.0f}", "Return %": "{:.0f}%"
                            })
                        )
                        st.dataframe(styled_sp_return, use_container_width=True, hide_index=False)


                        # --- Return by Material Description ---
                        st.subheader("ğŸ”„ Return by Material Description")
                        if "Material Description" in df_filtered.columns:
                            material_billing = df_filtered.pivot_table(
                                index="Material Description",
                                columns="Billing Type",
                                values="Net Value",
                                aggfunc="sum",
                                fill_value=0
                            )

                            material_cols_raw = ["ZFR", "YKF2", "YKRE", "YKS1", "YKS2", "ZCAN", "ZRE"]
                            material_billing = material_billing.reindex(columns=material_cols_raw, fill_value=0)
                            material_billing["Sales Total"] = material_billing.sum(axis=1)
                            material_billing["Return"] = material_billing["YKRE"] + material_billing["ZRE"]
                            material_billing["Cancel Total"] = material_billing[["YKS1", "YKS2", "ZCAN"]].sum(axis=1)
                            material_billing = material_billing.rename(columns={"ZFR": "Presales", "YKF2": "HHT"})
                            material_billing["Return %"] = np.where(material_billing["Sales Total"] != 0,
                                                                    (material_billing["Return"] / material_billing["Sales Total"] * 100).round(0), 0)

                            ordered_cols_material = ["Presales", "HHT", "Sales Total", "YKS1", "YKS2", "ZCAN",
                                                    "Cancel Total", "YKRE", "ZRE", "Return", "Return %"]
                            material_billing = material_billing.reindex(columns=ordered_cols_material, fill_value=0)

                            total_row = pd.DataFrame(material_billing.sum(numeric_only=True)).T
                            total_row.index = ["Total"]
                            total_row["Return %"] = round((total_row["Return"]/total_row["Sales Total"]*100), 0) if total_row["Sales Total"].iloc[0] != 0 else 0
                            material_billing = pd.concat([material_billing, total_row])

                            def highlight_total_row_material(row):
                                return ['background-color: #BFDBFE; color: #1E3A8A; font-weight: 900' if row.name == "Total" else '' for _ in row]

                            styled_material = (
                                material_billing.style
                                .set_table_styles([
                                    {'selector': 'th', 'props': [('background', '#1E3A8A'), ('color', 'white'),
                                                                ('font-weight', '800'), ('height', '40px'),
                                                                ('line-height', '40px'), ('border', '1px solid #E5E7EB')] }
                                ])
                                .apply(highlight_total_row_material, axis=1)
                                .format({
                                    "Presales": "{:,.0f}", "HHT": "{:,.0f}", "Sales Total": "{:,.0f}",
                                    "YKS1": "{:,.0f}", "YKS2": "{:,.0f}", "ZCAN": "{:,.0f}", "Cancel Total": "{:,.0f}",
                                    "YKRE": "{:,.0f}", "ZRE": "{:,.0f}", "Return": "{:,.0f}", "Return %": "{:.0f}%"
                                })
                            )
                            st.dataframe(styled_material, use_container_width=True, hide_index=False)

                            if st.download_button(
                                texts[lang].get("download_material", "Download Return by Material Description"),
                                data=to_excel_bytes(material_billing.reset_index(), sheet_name="Return_by_Material", index=False),
                                file_name=f"Return_by_Material_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}.xlsx",
                                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                            ):
                                st.session_state["audit_log"].append({
                                    "user": username,
                                    "action": "download",
                                    "details": "Return by Material Description Excel",
                                    "timestamp": datetime.now()
                                })
                        else:
                            st.info("No 'Material Description' column found in data â€” skipping Material Description table.")


                        # --- Return by SP Name1 + Material Description ---
                        st.subheader("ğŸ”„ Return by SP Name1 + Material Description")
                        required_cols = {"SP Name1", "Material Description", "Billing Type", "Net Value"}
                        if required_cols.issubset(df_filtered.columns):
                            # Pivot table
                            sp_mat_table = pd.pivot_table(
                                df_filtered,
                                index=["SP Name1", "Material Description"],
                                columns="Billing Type",
                                values="Net Value",
                                aggfunc="sum",
                                fill_value=0
                            )

                            # Ensure all billing columns exist
                            billing_cols = ["ZFR", "YKF2", "YKRE", "YKS1", "YKS2", "ZCAN", "ZRE"]
                            for col in billing_cols:
                                if col not in sp_mat_table.columns:
                                    sp_mat_table[col] = 0

                            # Rename for display
                            sp_mat_table = sp_mat_table.rename(columns={"ZFR": "Presales", "YKF2": "HHT"})
                            
                            # Calculate totals
                            sp_mat_table["Sales Total"] = sp_mat_table.sum(axis=1, numeric_only=True)
                            sp_mat_table["Return"] = sp_mat_table["YKRE"] + sp_mat_table["ZRE"]
                            sp_mat_table["Cancel Total"] = sp_mat_table[["YKS1", "YKS2", "ZCAN"]].sum(axis=1)
                            sp_mat_table["Return %"] = np.where(sp_mat_table["Sales Total"] != 0,
                                                                (sp_mat_table["Return"] / sp_mat_table["Sales Total"] * 100).round(0), 0)

                            # Reorder columns
                            ordered_cols = ["Presales", "HHT", "Sales Total", "YKS1", "YKS2", "ZCAN",
                                            "Cancel Total", "YKRE", "ZRE", "Return", "Return %"]
                            sp_mat_table = sp_mat_table.reindex(columns=ordered_cols, fill_value=0)

                            # Add total row
                            total_row = pd.DataFrame(sp_mat_table.sum(numeric_only=True)).T
                            total_row.index = [("Total", "")]
                            total_row["Return %"] = round((total_row["Return"] / total_row["Sales Total"] * 100), 0) if total_row["Sales Total"].iloc[0]!=0 else 0
                            sp_mat_table = pd.concat([sp_mat_table, total_row])

                            # Highlighting function
                            def highlight_sp_mat(row):
                                styles = []
                                for col in row.index:
                                    if row.name == ("Total", ""):
                                        styles.append('background-color: #BFDBFE; color: #1E3A8A; font-weight: 900')
                                    elif col == "Return" and row[col] > 0:
                                        styles.append('background-color: #FECACA; color: #991B1B; font-weight: 700')  # highlight returns
                                    elif col == "Cancel Total" and row[col] > 0:
                                        styles.append('background-color: #FDE68A; color: #92400E; font-weight: 700')  # highlight cancels
                                    elif col == "Sales Total" and row[col] > 0:
                                        styles.append('background-color: #D1FAE5; color: #065F46; font-weight: 700')  # highlight sales
                                    else:
                                        styles.append('')
                                return styles

                            # Style the table
                            styled_sp_mat = (
                                sp_mat_table.style
                                .set_table_styles([
                                    {'selector': 'th', 'props': [('background', '#1E3A8A'), ('color', 'white'),
                                                                ('font-weight', '800'), ('height', '40px'),
                                                                ('line-height', '40px'), ('border', '1px solid #E5E7EB')] }
                                ])
                                .apply(highlight_sp_mat, axis=1)
                                .format({
                                    "Presales": "{:,.0f}", "HHT": "{:,.0f}", "Sales Total": "{:,.0f}",
                                    "YKS1": "{:,.0f}", "YKS2": "{:,.0f}", "ZCAN": "{:,.0f}", "Cancel Total": "{:,.0f}",
                                    "YKRE": "{:,.0f}", "ZRE": "{:,.0f}", "Return": "{:,.0f}", "Return %": "{:.0f}%"
                                })
                            )

                            st.dataframe(styled_sp_mat, use_container_width=True)

                            # Download button
                            if st.download_button(
                                texts[lang].get("download_sp_material", "Download Return by SP+Material"),
                                data=to_excel_bytes(sp_mat_table.reset_index(), sheet_name="Return_by_SP_Material", index=False),
                                file_name=f"Return_by_SP_Material_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}.xlsx",
                                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                            ):
                                st.session_state["audit_log"].append({
                                    "user": username,
                                    "action": "download",
                                    "details": "Return by SP+Material Excel",
                                    "timestamp": datetime.now()
                                })
                        else:
                            st.info("Required columns are missing in your data for SP+Material table.")

                # --- CHARTS ---
                with tabs[2]:
                    st.subheader(texts[lang]["daily_sales_trend_sub"])
                    df_time = df_filtered.groupby(pd.Grouper(key="Billing Date", freq="D"))["Net Value"].sum().reset_index()
                    df_time.rename(columns={"Billing Date": "ds", "Net Value": "y"}, inplace=True)

                    if len(df_time) > 1:
                        try:
                            m = Prophet()
                            m.fit(df_time)
                            future = m.make_future_dataframe(periods=30)
                            forecast = m.predict(future)

                            fig_trend = go.Figure()
                            fig_trend.add_trace(go.Scatter(x=df_time["ds"], y=df_time["y"], mode='lines+markers', name='Actual Sales', line=dict(color='#1E3A8A', width=3)))
                            fig_trend.add_trace(go.Scatter(x=forecast["ds"], y=forecast["yhat"], mode='lines', name='Prophet Forecast', line=dict(color='#3B82F6', width=2, dash='dash')))
                        except Exception:
                            fig_trend = go.Figure()
                            fig_trend.add_trace(go.Scatter(x=df_time["ds"], y=df_time["y"], mode='lines+markers', name='Actual Sales'))

                        df_time['y_mean'] = df_time['y'].rolling(window=7).mean()
                        df_time['y_std'] = df_time['y'].rolling(window=7).std()
                        df_time['upper_bound'] = df_time['y_mean'] + 2 * df_time['y_std']
                        df_time['lower_bound'] = df_time['y_mean'] - 2 * df_time['y_std']
                        df_time['anomaly'] = np.where((df_time['y'] > df_time['upper_bound']) | (df_time['y'] < df_time['lower_bound']), df_time['y'], np.nan)

                        fig_trend.add_trace(go.Scatter(
                            x=df_time['ds'], y=df_time['anomaly'],
                            mode='markers', name='Anomaly',
                            marker=dict(color='red', size=10, symbol='x')
                        ))

                        fig_trend.update_layout(
                            title=texts[lang]["daily_sales_title"],
                            xaxis_title="Date",
                            yaxis_title="Net Value (KD)",
                            font=dict(family="Roboto", size=12),
                            plot_bgcolor="#F3F4F6",
                            paper_bgcolor="#F3F4F6",
                            hovermode="x unified"
                        )
                        st.plotly_chart(fig_trend, use_container_width=True)
                    else:
                        st.info(texts[lang]["not_enough_data"])

                    st.subheader(texts[lang]["market_vs_ecom_sub"])
                    market_ecom_df = pd.DataFrame({
                        "Channel": ["Market (In-Store & Other)", "E-com (Talabat)"],
                        "Sales": [total_retail_sales, total_ecom_sales]
                    })
                    fig_channel = px.pie(
                        market_ecom_df,
                        values="Sales",
                        names="Channel",
                        title=texts[lang]["market_vs_ecom_title"],
                        hole=0.4,
                        color_discrete_sequence=px.colors.sequential.Bluered_r
                    )
                    fig_channel.update_traces(textposition='inside', textinfo='percent+label')
                    fig_channel.update_layout(font=dict(family="Roboto", size=12), showlegend=True)
                    st.plotly_chart(fig_channel, use_container_width=True)

                    st.subheader(texts[lang]["daily_ka_target_sub"])
                    df_time_target = df_filtered.groupby(pd.Grouper(key="Billing Date", freq="D"))["Net Value"].sum().reset_index()
                    df_time_target.rename(columns={"Billing Date": "Date", "Net Value": "Sales"}, inplace=True)
                    df_time_target = df_time_target.sort_values("Date").reset_index(drop=True)
                    df_time_target["Daily KA Target"] = per_day_ka_target

                    fig_target_trend = go.Figure()
                    fig_target_trend.add_trace(go.Scatter(
                        x=df_time_target["Date"], y=df_time_target["Sales"],
                        mode='lines+markers', name="Actual Sales", line=dict(color='#16A34A', width=3)
                    ))
                    fig_target_trend.add_trace(go.Scatter(
                        x=df_time_target["Date"], y=df_time_target["Daily KA Target"],
                        mode='lines', name="Daily KA Target", line=dict(color='#F59E0B', width=2, dash='dot')
                    ))
                    fig_target_trend.update_layout(
                        title=texts[lang]["daily_ka_title"],
                        xaxis_title="Date",
                        yaxis_title="Net Value (KD)",
                        font=dict(family="Roboto", size=12),
                        plot_bgcolor="#F3F4F6",
                        paper_bgcolor="#F3F4F6",
                        hovermode="x unified"
                    )
                    st.plotly_chart(fig_target_trend, use_container_width=True)

                    st.subheader(texts[lang]["salesman_ka_sub"])
                    salesman_target_df = pd.DataFrame({
                        "Salesman": ka_targets.index,
                        "KA Target": ka_targets.values,
                        "KA Sales": total_sales.values
                    }).reset_index(drop=True)

                    fig_salesman_target = go.Figure()
                    fig_salesman_target.add_trace(go.Bar(
                        x=salesman_target_df["Salesman"],
                        y=salesman_target_df["KA Target"],
                        name="KA Target",
                        marker_color="gray",
                        text=salesman_target_df["KA Target"].apply(lambda x: f"{x:,.0f}"),
                        textposition="inside",
                        insidetextanchor="middle",
                        textfont=dict(color="white", size=12)
                    ))
                    fig_salesman_target.add_trace(go.Bar(
                        x=salesman_target_df["Salesman"],
                        y=salesman_target_df["KA Sales"],
                        name="KA Sales",
                        marker_color=[
                            "green" if val >= tgt else "red"
                            for val, tgt in zip(salesman_target_df["KA Sales"], salesman_target_df["KA Target"])
                        ],
                        text=salesman_target_df["KA Sales"].apply(lambda x: f"{x:,.0f}"),
                        textposition="inside",
                        insidetextanchor="middle",
                        textfont=dict(color="white", size=12)
                    ))
                    fig_salesman_target.update_layout(
                        title=texts[lang]["salesman_ka_title"],
                        xaxis_title="Salesman",
                        yaxis_title="Net Value (KD)",
                        font=dict(family="Roboto", size=12),
                        plot_bgcolor="#F3F4F6",
                        paper_bgcolor="#F3F4F6",
                        barmode="group",
                        hovermode="x unified"
                    )
                    st.plotly_chart(fig_salesman_target, use_container_width=True)

                    st.subheader(texts[lang]["top10_py_sub"])
                    py_sales_top10 = py_table.sort_values("Sales", ascending=False).head(10)
                    fig_top10 = px.bar(
                        py_sales_top10.reset_index(),
                        x="PY Name 1",
                        y="Sales",
                        title=texts[lang]["top10_py_title"],
                        color_discrete_sequence=px.colors.sequential.Blues_r
                    )
                    fig_top10.update_layout(font=dict(family="Roboto", size=12))
                    st.plotly_chart(fig_top10, use_container_width=True)

                # --- DOWNLOADS ---
                with tabs[3]:
                    st.subheader(texts[lang]["download_reports_sub"])
                    col1, col2 = st.columns(2)
                    with col1:
                        if st.button(texts[lang]["generate_pptx"]):
                            figs_dict = {
                                "Daily Sales Trend": fig_trend,
                                "Market vs E-com Sales": fig_channel,
                                "Daily KA Target vs Actual": fig_target_trend,
                                "Salesman KA Target vs Actual": fig_salesman_target,
                                "Top 10 PY Name 1 by Sales": fig_top10
                            }
                            pptx_stream = create_pptx(report_df_with_total, billing_df, py_table_with_total, figs_dict, kpi_data)
                            st.download_button(
                                texts[lang]["download_pptx"],
                                pptx_stream,
                                file_name=f"sales_report_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}.pptx",
                                mime="application/vnd.openxmlformats-officedocument.presentationml.presentation"
                            )
                            st.session_state["audit_log"].append({
                                "user": username,
                                "action": "download",
                                "details": "PPTX Report",
                                "timestamp": datetime.now()
                            })

elif choice == texts[lang]["sales_tracking"]:
    st.title(texts[lang]["sales_tracking_title"])
    if "data_loaded" not in st.session_state:
        st.warning(texts[lang]["no_data_warning"])
    else:
        # Filters
        st.sidebar.subheader(texts[lang]["filters_header"])
        st.sidebar.markdown(f'<div class="tooltip">â„¹ï¸<span class="tooltiptext">{texts[lang]["filters_tooltip"]}</span></div>', unsafe_allow_html=True)
        salesmen = st.sidebar.multiselect(
            texts[lang]["select_salesmen"],
            options=sorted(sales_df["Driver Name EN"].dropna().unique()),
            default=sorted(sales_df["Driver Name EN"].dropna().unique()),
            key="st_salesmen"
        )
        billing_types = st.sidebar.multiselect(
            texts[lang]["select_billing_types"],
            options=sorted(sales_df["Billing Type"].dropna().unique()),
            default=sorted(sales_df["Billing Type"].dropna().unique()),
            key="st_billing_types"
        )
        py_filter = st.sidebar.multiselect(
            texts[lang]["select_py"],
            options=sorted(sales_df["PY Name 1"].dropna().unique()),
            default=sorted(sales_df["PY Name 1"].dropna().unique()),
            key="st_py_filter"
        )
        sp_filter = st.sidebar.multiselect(
            texts[lang]["select_sp"],
            options=sorted(sales_df["SP Name1"].dropna().unique()),
            default=sorted(sales_df["SP Name1"].dropna().unique()),
            key="st_sp_filter"
        )

        preset = st.sidebar.radio(texts[lang]["date_presets"], texts[lang]["date_presets_options"], key="st_preset")
        today = pd.Timestamp.today().normalize()
        if preset == texts[lang]["date_presets_options"][1]:  # Last 7 Days
            date_range = [today - pd.Timedelta(days=7), today]
        elif preset == texts[lang]["date_presets_options"][2]:  # This Month
            month_start = today.replace(day=1)
            month_end = month_start + pd.offsets.MonthEnd(0)
            date_range = [month_start, month_end]
        elif preset == texts[lang]["date_presets_options"][3]:  # YTD
            date_range = [today.replace(month=1, day=1), today]
        else:
            date_range = st.sidebar.date_input(
                texts[lang]["select_date_range"],
                [sales_df["Billing Date"].min(), sales_df["Billing Date"].max()],
                key="st_date_range"
            )
            if isinstance(date_range, tuple) and len(date_range) == 2:
                date_range = [pd.to_datetime(date_range[0]), pd.to_datetime(date_range[1])]
            else:
                date_range = [sales_df["Billing Date"].min(), sales_df["Billing Date"].max()]

        if date_range[0] > date_range[1]:
            st.error(texts[lang]["date_error"])
        else:
            top_n = st.sidebar.slider(
                texts[lang]["top_n_salesmen"],
                min_value=1,
                max_value=max(1, len(sales_df["Driver Name EN"].dropna().unique())),
                value=min(5, max(1, len(sales_df["Driver Name EN"].dropna().unique()))),
                key="st_topn"
            )

            df_filtered = sales_df[
                (sales_df["Driver Name EN"].isin(salesmen))
                & (sales_df["Billing Type"].isin(billing_types))
                & (sales_df["Billing Date"] >= date_range[0])
                & (sales_df["Billing Date"] <= date_range[1])
                & (sales_df["PY Name 1"].isin(py_filter))
                & (sales_df["SP Name1"].isin(sp_filter))
            ].copy()

            if df_filtered.empty:
                st.warning(texts[lang]["no_match_warning"])
            else:
                billing_start = df_filtered["Billing Date"].min().normalize()
                billing_end = df_filtered["Billing Date"].max().normalize()
                all_days = pd.date_range(billing_start, billing_end, freq="D")
                days_finish = int(sum(1 for d in all_days if d.weekday() != 4))

                current_month_start = today.replace(day=1)
                current_month_end = current_month_start + pd.offsets.MonthEnd(0)
                month_days = pd.date_range(current_month_start, current_month_end, freq="D")
                working_days_current_month = int(sum(1 for d in month_days if d.weekday() != 4))

                # --- Base aggregates ---
                total_sales = df_filtered.groupby("Driver Name EN")["Net Value"].sum()
                talabat_df = df_filtered[df_filtered["PY Name 1"] == "STORES SERVICES KUWAIT CO."]
                talabat_sales = talabat_df.groupby("Driver Name EN")["Net Value"].sum()

                ka_targets = target_df.set_index("Driver Name EN")["KA Target"] if "KA Target" in target_df.columns else pd.Series(dtype=float)
                talabat_targets = target_df.set_index("Driver Name EN")["Talabat Target"] if "Talabat Target" in target_df.columns else pd.Series(dtype=float)

                all_salesmen_idx = total_sales.index.union(talabat_sales.index).union(ka_targets.index).union(talabat_targets.index)
                total_sales = total_sales.reindex(all_salesmen_idx, fill_value=0).astype(float)
                talabat_sales = talabat_sales.reindex(all_salesmen_idx, fill_value=0).astype(float)
                ka_targets = ka_targets.reindex(all_salesmen_idx, fill_value=0).astype(float)
                talabat_targets = talabat_targets.reindex(all_salesmen_idx, fill_value=0).astype(float)

                ka_gap = (ka_targets - total_sales).clip(lower=0)
                talabat_gap = (talabat_targets - talabat_sales).clip(lower=0)

                top_salesmen = total_sales.sort_values(ascending=False).head(top_n).index
                total_sales_top = total_sales.loc[top_salesmen]
                talabat_sales_top = talabat_sales.loc[top_salesmen]
                ka_gap_top = ka_gap.loc[top_salesmen]
                talabat_gap_top = talabat_gap.loc[top_salesmen]

                total_ka_target_all = float(ka_targets.sum())
                total_tal_target_all = float(talabat_targets.sum())
                per_day_ka_target = (total_ka_target_all / working_days_current_month) if working_days_current_month > 0 else 0
                current_sales_per_day = (total_sales.sum() / days_finish) if days_finish > 0 else 0
                forecast_month_end_ka = current_sales_per_day * working_days_current_month

                # --- Channels mapping: Market (Retail) vs E-com ---
                df_py_sales = df_filtered.groupby("_py_name_norm")["Net Value"].sum().reset_index()
                df_channels_merged = df_py_sales.merge(
                    channels_df[["_py_name_norm", "Channels"]],
                    on="_py_name_norm",
                    how="left"
                )
                df_channels_merged["Channels"] = df_channels_merged["Channels"].str.strip().str.lower().fillna("uncategorized")
                channel_sales = df_channels_merged.groupby("Channels")["Net Value"].sum()
                total_retail_sales = float(channel_sales.get("market", 0.0) + channel_sales.get("uncategorized", 0.0))
                total_ecom_sales = float(channel_sales.get("e-com", 0.0))
                total_channel_sales = total_retail_sales + total_ecom_sales
                retail_sales_pct = (total_retail_sales / total_channel_sales * 100) if total_channel_sales > 0 else 0
                ecom_sales_pct = (total_ecom_sales / total_channel_sales * 100) if total_channel_sales > 0 else 0

                # --- KA & Other E-com Calculation ---
                ka_other_ecom_sales = total_sales.sum() - talabat_sales.sum()
                ka_other_ecom_pct = (ka_other_ecom_sales / total_ka_target_all * 100) if total_ka_target_all > 0 else 0

                # --- KPI Data for PPTX ---
                kpi_data = {
                    texts[lang]["ka_target"]: f"KD {total_ka_target_all:,.0f}",
                    texts[lang]["talabat_target"]: f"KD {total_tal_target_all:,.0f}",
                    texts[lang]["ka_gap"]: f"KD {(total_ka_target_all - total_sales.sum()):,.0f}",
                    "Total Talabat Gap": f"KD {talabat_gap.sum():,.0f}",
                    texts[lang]["total_ka_sales"]: f"KD {total_sales.sum():,.0f} ({((total_sales.sum() / total_ka_target_all) * 100):.0f}%)" if total_ka_target_all else f"KD {total_sales.sum():,.0f} (0%)",
                    "Total Talabat Sales": f"KD {talabat_sales.sum():,.0f} ({((talabat_sales.sum() / total_tal_target_all) * 100):.0f}%)" if total_tal_target_all else f"KD {talabat_sales.sum():,.0f} (0%)",
                    texts[lang]["ka_other_ecom"]: f"KD {ka_other_ecom_sales:,.0f} ({ka_other_ecom_pct:.0f}%)",
                    texts[lang]["retail_sales"]: f"KD {total_retail_sales:,.0f} ({retail_sales_pct:.0f}%)",
                    texts[lang]["ecom_sales"]: f"KD {total_ecom_sales:,.0f} ({ecom_sales_pct:.0f}%)",
                    texts[lang]["days_finished"]: f"{days_finish}",
                    "Per Day KA Target": f"KD {per_day_ka_target:,.0f}",
                    texts[lang]["current_sales_per_day"]: f"KD {current_sales_per_day:,.0f}",
                    texts[lang]["forecast_month_end"]: f"KD {forecast_month_end_ka:,.0f}"
                }

                tabs = st.tabs([texts[lang]["kpis_tab"], texts[lang]["tables_tab"], texts[lang]["charts_tab"], texts[lang]["downloads_tab"]])

                # --- KPIs with progress bars ---
                with tabs[0]:
                    st.subheader(texts[lang]["key_metrics_sub"])
                    r1c1 = st.columns(1)[0]
                    with r1c1:
                        st.metric(texts[lang]["total_ka_sales"], f"KD {total_sales.sum():,.0f}")
                        progress_pct_ka = (total_sales.sum() / total_ka_target_all * 100) if total_ka_target_all > 0 else 0
                        st.markdown(create_progress_bar_html(progress_pct_ka), unsafe_allow_html=True)
                        st.markdown(f'<div class="green-caption">{texts[lang]["of_ka_target"].format(progress_pct_ka)}</div>', unsafe_allow_html=True)

                    r2c1, r2c2 = st.columns(2)
                    with r2c1:
                        st.metric(texts[lang]["ka_other_ecom"], f"KD {ka_other_ecom_sales:,.0f}")
                        st.markdown(create_progress_bar_html(ka_other_ecom_pct), unsafe_allow_html=True)
                        st.markdown(f'<div class="green-caption">{texts[lang]["of_ka_target_pct"].format(ka_other_ecom_pct)}</div>', unsafe_allow_html=True)
                    with r2c2:
                        st.metric(texts[lang]["talabat_sales"], f"KD {talabat_sales.sum():,.0f}")
                        progress_pct_talabat = (talabat_sales.sum() / total_tal_target_all * 100) if total_tal_target_all > 0 else 0
                        st.markdown(create_progress_bar_html(progress_pct_talabat), unsafe_allow_html=True)
                        st.markdown(f'<div class="green-caption">{texts[lang]["of_talabat_target"].format(progress_pct_talabat)}</div>', unsafe_allow_html=True)

                    st.subheader(texts[lang]["target_overview_sub"])
                    r3c1, r3c2, r3c3, r3c4 = st.columns(4)
                    r3c1.metric(texts[lang]["ka_target"], f"KD {total_ka_target_all:,.0f}")
                    r3c2.metric(texts[lang]["talabat_target"], f"KD {total_tal_target_all:,.0f}")
                    r3c3.metric(texts[lang]["ka_gap"], f"KD {(total_ka_target_all - total_sales.sum()):,.0f}")
                    r3c4.metric(texts[lang]["talabat_gap"], f"KD {talabat_gap.sum():,.0f}")

                    st.subheader(texts[lang]["channel_sales_sub"])
                    r4c1, r4c2 = st.columns(2)
                    with r4c1:
                        st.metric(texts[lang]["retail_sales"], f"KD {total_retail_sales:,.0f}")
                        retail_contribution_pct = (total_retail_sales / total_sales.sum() * 100) if total_sales.sum() > 0 else 0
                        st.caption(texts[lang]["of_total_ka"].format(retail_contribution_pct))
                    with r4c2:
                        st.metric(texts[lang]["ecom_sales"], f"KD {total_ecom_sales:,.0f}")
                        ecom_contribution_pct = (total_ecom_sales / total_sales.sum() * 100) if total_sales.sum() > 0 else 0
                        st.caption(texts[lang]["of_total_ka"].format(ecom_contribution_pct))

                    st.subheader(texts[lang]["performance_metrics_sub"])
                    r5c1, r5c2, r5c3 = st.columns(3)
                    r5c1.metric(texts[lang]["days_finished"], days_finish)
                    r5c2.metric(texts[lang]["current_sales_per_day"], f"KD {current_sales_per_day:,.0f}")
                    r5c3.metric(texts[lang]["forecast_month_end"], f"KD {forecast_month_end_ka:,.0f}")

                    # --- TABLES ---
                    with tabs[1]:
                        # --- Sales & Targets Summary ---
                        st.subheader(texts[lang]["sales_targets_summary_sub"])
                        report_df = pd.DataFrame({
                            "Salesman": ka_targets.index,
                            "KA Target": ka_targets.values,
                            "KA Sales": total_sales.values,
                            "KA Remaining": ka_gap.values,
                            "KA % Achieved": np.where(ka_targets.values != 0, (total_sales.values / ka_targets.values * 100).round(0), 0),
                            "Talabat Target": talabat_targets.values,
                            "Talabat Sales": talabat_sales.values,
                            "Talabat Remaining": talabat_gap.values,
                            "Talabat % Achieved": np.where(talabat_targets.values != 0, (talabat_sales.values / talabat_targets.values * 100).round(0), 0)
                        })

                        total_row = report_df.sum(numeric_only=True).to_frame().T
                        total_row.index = ["Total"]
                        total_row["KA % Achieved"] = round(total_row["KA Sales"]/total_row["KA Target"]*100,0) if total_row["KA Target"].iloc[0]!=0 else 0
                        total_row["Talabat % Achieved"] = round(total_row["Talabat Sales"]/total_row["Talabat Target"]*100,0) if total_row["Talabat Target"].iloc[0]!=0 else 0

                        total_row = total_row.reset_index(drop=True)
                        total_row["Salesman"] = "Total"
                        total_row = total_row[report_df.columns]
                        report_df_with_total = pd.concat([report_df, total_row], ignore_index=True)

                        def highlight_total_row(row):
                            return ['background-color: #BFDBFE; color: #1E3A8A; font-weight: 900' if row['Salesman'] == "Total" else '' for _ in row]

                        styled_report = (
                            report_df_with_total.style
                            .set_table_styles([
                                {'selector': 'th', 'props': [('background', '#1E3A8A'), ('color', 'white'),
                                                            ('font-weight', '800'), ('height', '40px'),
                                                            ('line-height', '40px'), ('border', '1px solid #E5E7EB')]}
                            ])
                            .apply(highlight_total_row, axis=1)
                            .format("{:,.0f}", subset=["KA Target","KA Sales","KA Remaining",
                                                    "Talabat Target","Talabat Sales","Talabat Remaining"])
                            .format("{:.0f}%", subset=["KA % Achieved","Talabat % Achieved"])
                        )
                        st.dataframe(styled_report, use_container_width=True, hide_index=True)
                        if st.download_button(
                            texts[lang]["download_sales_targets"],
                            data=to_excel_bytes(report_df_with_total, sheet_name="Sales_Targets_Summary", index=False),
                            file_name=f"Sales_Targets_Summary_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                        ):
                            st.session_state["audit_log"].append({
                                "user": username,
                                "action": "download",
                                "details": "Sales & Targets Summary Excel",
                                "timestamp": datetime.now()
                            })

                        # --- Sales by Billing Type per Salesman ---
                        st.subheader(texts[lang]["sales_by_billing_sub"])
                        billing_wide = df_filtered.pivot_table(
                            index="Driver Name EN",
                            columns="Billing Type",
                            values="Net Value",
                            aggfunc="sum",
                            fill_value=0
                        )

                        required_cols_raw = ["ZFR", "YKF2", "YKRE", "YKS1", "YKS2", "ZCAN", "ZRE"]
                        billing_wide = billing_wide.reindex(columns=required_cols_raw, fill_value=0)
                        display_df = billing_wide.rename(columns={"ZFR": "Presales", "YKF2": "HHT"})
                        display_df["Sales Total"] = billing_wide.sum(axis=1)
                        display_df["Return"] = billing_wide["YKRE"] + billing_wide["ZRE"]
                        display_df["Return %"] = np.where(display_df["Sales Total"] != 0,
                                                        (display_df["Return"] / display_df["Sales Total"] * 100).round(0), 0)
                        display_df["Cancel Total"] = billing_wide[["YKS1", "YKS2", "ZCAN"]].sum(axis=1)
                        ordered_cols = ["Presales", "HHT", "Sales Total", "YKS1", "YKS2", "ZCAN",
                                        "Cancel Total", "YKRE", "ZRE", "Return", "Return %"]
                        display_df = display_df.reindex(columns=ordered_cols, fill_value=0)

                        total_row = pd.DataFrame(display_df.sum(numeric_only=True)).T
                        total_row.index = ["Total"]
                        total_row["Return %"] = round((total_row["Return"] / total_row["Sales Total"] * 100), 0) if total_row["Sales Total"].iloc[0] != 0 else 0
                        billing_df = pd.concat([display_df, total_row])
                        billing_df.index.name = "Salesman"

                        def highlight_total_row_billing(row):
                            return ['background-color: #BFDBFE; color: #1E3A8A; font-weight: 900' if row.name == "Total" else '' for _ in row]

                        styled_billing = (
                            billing_df.style
                            .set_table_styles([
                                {'selector': 'th', 'props': [('background', '#1E3A8A'), ('color', 'white'),
                                                            ('font-weight', '800'), ('height', '40px'),
                                                            ('line-height', '40px'), ('border', '1px solid #E5E7EB')]}
                            ])
                            .apply(highlight_total_row_billing, axis=1)
                            .format({
                                "Presales": "{:,.0f}", "HHT": "{:,.0f}", "Sales Total": "{:,.0f}",
                                "YKS1": "{:,.0f}", "YKS2": "{:,.0f}", "ZCAN": "{:,.0f}", "Cancel Total": "{:,.0f}",
                                "YKRE": "{:,.0f}", "ZRE": "{:,.0f}", "Return": "{:,.0f}", "Return %": "{:.0f}%"
                            })
                        )
                        st.dataframe(styled_billing, use_container_width=True, hide_index=False)
                        if st.download_button(
                            texts[lang]["download_billing"],
                            data=to_excel_bytes(billing_df.reset_index(), sheet_name="Billing_Types", index=False),
                            file_name=f"Billing_Types_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                        ):
                            st.session_state["audit_log"].append({
                                "user": username,
                                "action": "download",
                                "details": "Billing Type Table Excel",
                                "timestamp": datetime.now()
                            })

                        # --- Sales by PY Name 1 ---
                        st.subheader(texts[lang]["sales_by_py_sub"])
                        py_table = df_filtered.groupby("PY Name 1")["Net Value"].sum().sort_values(ascending=False).to_frame(name="Sales")
                        py_table["Contribution %"] = np.where(py_table["Sales"] != 0,
                                                            (py_table["Sales"]/py_table["Sales"].sum()*100).round(0), 0)

                        total_row = py_table.sum(numeric_only=True).to_frame().T
                        total_row.index = ["Total"]
                        py_table_with_total = pd.concat([py_table, total_row])
                        py_table_with_total.index.name = "PY Name 1"

                        def highlight_total_row_py(row):
                            return ['background-color: #BFDBFE; color: #1E3A8A; font-weight: 900' if row.name == "Total" else '' for _ in row]

                        styled_py = (
                            py_table_with_total.style
                            .set_table_styles([
                                {'selector': 'th', 'props': [('background', '#1E3A8A'), ('color', 'white'),
                                                            ('font-weight', '800'), ('height', '40px'),
                                                            ('line-height', '40px'), ('border', '1px solid #E5E7EB')]}
                            ])
                            .apply(highlight_total_row_py, axis=1)
                            .format("{:,.0f}", subset=["Sales"])
                            .format("{:.0f}%", subset=["Contribution %"])
                        )
                        st.dataframe(styled_py, use_container_width=True, hide_index=False)
                        if st.download_button(
                            texts[lang]["download_py"],
                            data=to_excel_bytes(py_table_with_total.reset_index(), sheet_name="Sales_by_PY_Name", index=False),
                            file_name=f"Sales_by_PY_Name_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                        ):
                            st.session_state["audit_log"].append({
                                "user": username,
                                "action": "download",
                                "details": "PY Name Table Excel",
                                "timestamp": datetime.now()
                            })

                        # --- Return by PY Name 1 ---
                        st.subheader("ğŸ”„ Return by PY Name 1")
                        py_billing = df_filtered.pivot_table(
                            index="PY Name 1",
                            columns="Billing Type",
                            values="Net Value",
                            aggfunc="sum",
                            fill_value=0
                        )

                        py_billing = py_billing.reindex(columns=required_cols_raw, fill_value=0)
                        py_billing["Sales Total"] = py_billing.sum(axis=1)
                        py_billing["Return"] = py_billing["YKRE"] + py_billing["ZRE"]
                        py_billing["Cancel Total"] = py_billing[["YKS1", "YKS2", "ZCAN"]].sum(axis=1)

                        # Reorder columns like Sales by Billing table
                        ordered_cols = ["Presales", "HHT", "Sales Total", "YKS1", "YKS2", "ZCAN",
                                        "Cancel Total", "YKRE", "ZRE", "Return", "Return %"]
                        # Map the original column names to the ordered display names
                        py_billing = py_billing.rename(columns={"ZFR": "Presales", "YKF2": "HHT"})
                        py_billing["Return %"] = np.where(py_billing["Sales Total"] != 0,
                                                        (py_billing["Return"] / py_billing["Sales Total"] * 100).round(0), 0)
                        py_billing = py_billing.reindex(columns=ordered_cols, fill_value=0).astype(int)

                        # Add total row
                        total_row = pd.DataFrame(py_billing.sum(numeric_only=True)).T
                        total_row.index = ["Total"]
                        total_row["Return %"] = round((total_row["Return"]/total_row["Sales Total"]*100), 0) if total_row["Sales Total"].iloc[0]!=0 else 0
                        py_billing = pd.concat([py_billing, total_row])

                        def highlight_total_row_py_return(row):
                            return ['background-color: #BFDBFE; color: #1E3A8A; font-weight: 900' if row.name == "Total" else '' for _ in row]

                        styled_py_return = (
                            py_billing.style
                            .set_table_styles([
                                {'selector': 'th', 'props': [('background', '#1E3A8A'), ('color', 'white'),
                                                            ('font-weight', '800'), ('height', '40px'),
                                                            ('line-height', '40px'), ('border', '1px solid #E5E7EB')]}
                            ])
                            .apply(highlight_total_row_py_return, axis=1)
                            .format({
                                "Presales": "{:,.0f}", "HHT": "{:,.0f}", "Sales Total": "{:,.0f}",
                                "YKS1": "{:,.0f}", "YKS2": "{:,.0f}", "ZCAN": "{:,.0f}", "Cancel Total": "{:,.0f}",
                                "YKRE": "{:,.0f}", "ZRE": "{:,.0f}", "Return": "{:,.0f}", "Return %": "{:.0f}%"
                            })
                        )
                        st.dataframe(styled_py_return, use_container_width=True, hide_index=False)

                        # --- Return by SP Name1 ---
                        st.subheader("ğŸ”„ Return by SP Name1")
                        sp_billing = df_filtered.pivot_table(
                            index="SP Name1",
                            columns="Billing Type",
                            values="Net Value",
                            aggfunc="sum",
                            fill_value=0
                        )

                        sp_billing = sp_billing.reindex(columns=required_cols_raw, fill_value=0)
                        sp_billing["Sales Total"] = sp_billing.sum(axis=1)
                        sp_billing["Return"] = sp_billing["YKRE"] + sp_billing["ZRE"]
                        sp_billing["Cancel Total"] = sp_billing[["YKS1", "YKS2", "ZCAN"]].sum(axis=1)

                        # Reorder and rename like Sales by Billing table
                        sp_billing = sp_billing.rename(columns={"ZFR": "Presales", "YKF2": "HHT"})
                        sp_billing["Return %"] = np.where(sp_billing["Sales Total"] != 0,
                                                        (sp_billing["Return"] / sp_billing["Sales Total"] * 100).round(0), 0)
                        sp_billing = sp_billing.reindex(columns=ordered_cols, fill_value=0).astype(int)

                        # Add total row
                        total_row = pd.DataFrame(sp_billing.sum(numeric_only=True)).T
                        total_row.index = ["Total"]
                        total_row["Return %"] = round((total_row["Return"]/total_row["Sales Total"]*100), 0) if total_row["Sales Total"].iloc[0]!=0 else 0
                        sp_billing = pd.concat([sp_billing, total_row])

                        def highlight_total_row_sp_return(row):
                            return ['background-color: #BFDBFE; color: #1E3A8A; font-weight: 900' if row.name == "Total" else '' for _ in row]

                        styled_sp_return = (
                            sp_billing.style
                            .set_table_styles([
                                {'selector': 'th', 'props': [('background', '#1E3A8A'), ('color', 'white'),
                                                            ('font-weight', '800'), ('height', '40px'),
                                                            ('line-height', '40px'), ('border', '1px solid #E5E7EB')]}
                            ])
                            .apply(highlight_total_row_sp_return, axis=1)
                            .format({
                                "Presales": "{:,.0f}", "HHT": "{:,.0f}", "Sales Total": "{:,.0f}",
                                "YKS1": "{:,.0f}", "YKS2": "{:,.0f}", "ZCAN": "{:,.0f}", "Cancel Total": "{:,.0f}",
                                "YKRE": "{:,.0f}", "ZRE": "{:,.0f}", "Return": "{:,.0f}", "Return %": "{:.0f}%"
                            })
                        )
                        st.dataframe(styled_sp_return, use_container_width=True, hide_index=False)

                # --- CHARTS ---
                with tabs[2]:
                    st.subheader(texts[lang]["daily_sales_trend_sub"])
                    df_time = df_filtered.groupby(pd.Grouper(key="Billing Date", freq="D"))["Net Value"].sum().reset_index()
                    df_time.rename(columns={"Billing Date": "ds", "Net Value": "y"}, inplace=True)
                    
                    if len(df_time) > 1:
                        m = Prophet()
                        m.fit(df_time)
                        future = m.make_future_dataframe(periods=30)
                        forecast = m.predict(future)
                        
                        fig_trend = go.Figure()
                        fig_trend.add_trace(go.Scatter(x=df_time["ds"], y=df_time["y"], mode='lines+markers', name='Actual Sales', line=dict(color='#1E3A8A', width=3)))
                        fig_trend.add_trace(go.Scatter(x=forecast["ds"], y=forecast["yhat"], mode='lines', name='Prophet Forecast', line=dict(color='#3B82F6', width=2, dash='dash')))
                        
                        df_time['y_mean'] = df_time['y'].rolling(window=7).mean()
                        df_time['y_std'] = df_time['y'].rolling(window=7).std()
                        df_time['upper_bound'] = df_time['y_mean'] + 2 * df_time['y_std']
                        df_time['lower_bound'] = df_time['y_mean'] - 2 * df_time['y_std']
                        df_time['anomaly'] = np.where((df_time['y'] > df_time['upper_bound']) | (df_time['y'] < df_time['lower_bound']), df_time['y'], np.nan)
                        
                        fig_trend.add_trace(go.Scatter(
                            x=df_time['ds'], y=df_time['anomaly'],
                            mode='markers', name='Anomaly',
                            marker=dict(color='red', size=10, symbol='x')
                        ))
                        
                        fig_trend.update_layout(
                            title=texts[lang]["daily_sales_title"],
                            xaxis_title="Date",
                            yaxis_title="Net Value (KD)",
                            font=dict(family="Roboto", size=12),
                            plot_bgcolor="#F3F4F6",
                            paper_bgcolor="#F3F4F6",
                            hovermode="x unified"
                        )
                        st.plotly_chart(fig_trend, use_container_width=True)
                    else:
                        st.info(texts[lang]["not_enough_data"])
                        
                    st.subheader(texts[lang]["market_vs_ecom_sub"])
                    market_ecom_df = pd.DataFrame({
                        "Channel": ["Market (In-Store & Other)", "E-com (Talabat)"],
                        "Sales": [total_retail_sales, total_ecom_sales]
                    })
                    fig_channel = px.pie(
                        market_ecom_df,
                        values="Sales",
                        names="Channel",
                        title=texts[lang]["market_vs_ecom_title"],
                        hole=0.4,
                        color_discrete_sequence=px.colors.sequential.Bluered_r
                    )
                    fig_channel.update_traces(textposition='inside', textinfo='percent+label')
                    fig_channel.update_layout(font=dict(family="Roboto", size=12), showlegend=True)
                    st.plotly_chart(fig_channel, use_container_width=True)

                    st.subheader(texts[lang]["daily_ka_target_sub"])
                    df_time_target = df_filtered.groupby(pd.Grouper(key="Billing Date", freq="D"))["Net Value"].sum().reset_index()
                    df_time_target.rename(columns={"Billing Date": "Date", "Net Value": "Sales"}, inplace=True)
                    df_time_target = df_time_target.sort_values("Date").reset_index(drop=True)
                    df_time_target["Daily KA Target"] = per_day_ka_target

                    fig_target_trend = go.Figure()
                    fig_target_trend.add_trace(go.Scatter(
                        x=df_time_target["Date"], y=df_time_target["Sales"],
                        mode='lines+markers', name="Actual Sales", line=dict(color='#16A34A', width=3)
                    ))
                    fig_target_trend.add_trace(go.Scatter(
                        x=df_time_target["Date"], y=df_time_target["Daily KA Target"],
                        mode='lines', name="Daily KA Target", line=dict(color='#F59E0B', width=2, dash='dot')
                    ))
                    fig_target_trend.update_layout(
                        title=texts[lang]["daily_ka_title"],
                        xaxis_title="Date",
                        yaxis_title="Net Value (KD)",
                        font=dict(family="Roboto", size=12),
                        plot_bgcolor="#F3F4F6",
                        paper_bgcolor="#F3F4F6",
                        hovermode="x unified"
                    )
                    st.plotly_chart(fig_target_trend, use_container_width=True)

                    st.subheader(texts[lang]["salesman_ka_sub"])
                    salesman_target_df = pd.DataFrame({
                        "Salesman": ka_targets.index,
                        "KA Target": ka_targets.values,
                        "KA Sales": total_sales.values
                    }).reset_index(drop=True)

                    fig_salesman_target = go.Figure()
                    fig_salesman_target.add_trace(go.Bar(
                        x=salesman_target_df["Salesman"],
                        y=salesman_target_df["KA Target"],
                        name="KA Target",
                        marker_color="gray",
                        text=salesman_target_df["KA Target"].apply(lambda x: f"{x:,.0f}"),
                        textposition="inside",
                        insidetextanchor="middle",
                        textfont=dict(color="white", size=12)
                    ))
                    fig_salesman_target.add_trace(go.Bar(
                        x=salesman_target_df["Salesman"],
                        y=salesman_target_df["KA Sales"],
                        name="KA Sales",
                        marker_color=[
                            "green" if val >= tgt else "red"
                            for val, tgt in zip(salesman_target_df["KA Sales"], salesman_target_df["KA Target"])
                        ],
                        text=salesman_target_df["KA Sales"].apply(lambda x: f"{x:,.0f}"),
                        textposition="inside",
                        insidetextanchor="middle",
                        textfont=dict(color="white", size=12)
                    ))
                    fig_salesman_target.update_layout(
                        title=texts[lang]["salesman_ka_title"],
                        xaxis_title="Salesman",
                        yaxis_title="Net Value (KD)",
                        font=dict(family="Roboto", size=12),
                        plot_bgcolor="#F3F4F6",
                        paper_bgcolor="#F3F4F6",
                        barmode="group",
                        hovermode="x unified"
                    )
                    st.plotly_chart(fig_salesman_target, use_container_width=True)

                    st.subheader(texts[lang]["top10_py_sub"])
                    py_sales_top10 = py_table.sort_values("Sales", ascending=False).head(10)
                    fig_top10 = px.bar(
                        py_sales_top10.reset_index(),
                        x="PY Name 1",
                        y="Sales",
                        title=texts[lang]["top10_py_title"],
                        color_discrete_sequence=px.colors.sequential.Blues_r
                    )
                    fig_top10.update_layout(font=dict(family="Roboto", size=12))
                    st.plotly_chart(fig_top10, use_container_width=True)

                # --- DOWNLOADS ---
                with tabs[3]:
                    st.subheader(texts[lang]["download_reports_sub"])
                    col1, col2 = st.columns(2)
                    with col1:
                        if st.button(texts[lang]["generate_pptx"]):
                            figs_dict = {
                                "Daily Sales Trend": fig_trend,
                                "Market vs E-com Sales": fig_channel,
                                "Daily KA Target vs Actual": fig_target_trend,
                                "Salesman KA Target vs Actual": fig_salesman_target,
                                "Top 10 PY Name 1 by Sales": fig_top10
                            }
                            pptx_stream = create_pptx(report_df_with_total, billing_df, py_table_with_total, figs_dict, kpi_data)
                            st.download_button(
                                texts[lang]["download_pptx"],
                                pptx_stream,
                                file_name=f"sales_report_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}.pptx",
                                mime="application/vnd.openxmlformats-officedocument.presentationml.presentation"
                            )
                            st.session_state["audit_log"].append({
                                "user": username,
                                "action": "download",
                                "details": "PPTX Report",
                                "timestamp": datetime.now()
                            })

# --- YTD Comparison Page ---
elif choice == "Year to Date Comparison":
    if "ytd_df" in st.session_state and not st.session_state["ytd_df"].empty:
        ytd_df = st.session_state["ytd_df"]
        ytd_df['Billing Date'] = pd.to_datetime(ytd_df['Billing Date'])

        st.title("ğŸ“… Year to Date Comparison")
        st.markdown('<div class="tooltip">â„¹ï¸<span class="tooltiptext">Compare sales across two periods by a selected dimension.</span></div>', unsafe_allow_html=True)

        # --- Select Dimension ---
        st.subheader("ğŸ“Š Choose Dimension")
        dimension = st.selectbox("Choose dimension", ["PY Name 1", "Driver Name EN", "SP Name1"], index=0)

        # --- Select Two Periods ---
        st.subheader("ğŸ“† Select Two Periods")
        col1, col2 = st.columns(2)
        with col1:
            st.write("Period 1")
            period1_range = st.date_input("Select Date Range", value=(ytd_df["Billing Date"].min(), ytd_df["Billing Date"].max()), key="ytd_p1_range")
        with col2:
            st.write("Period 2")
            period2_range = st.date_input("Select Date Range", value=(ytd_df["Billing Date"].min(), ytd_df["Billing Date"].max()), key="ytd_p2_range")

        if period1_range and period2_range and len(period1_range) == 2 and len(period2_range) == 2:
            period1_start, period1_end = period1_range
            period2_start, period2_end = period2_range
            df_p1 = ytd_df[(ytd_df["Billing Date"] >= pd.to_datetime(period1_start)) & (ytd_df["Billing Date"] <= pd.to_datetime(period1_end))]
            df_p2 = ytd_df[(ytd_df["Billing Date"] >= pd.to_datetime(period2_start)) & (ytd_df["Billing Date"] <= pd.to_datetime(period2_end))]

            # --- YTD Comparison Table ---
            summary_p1 = df_p1.groupby(dimension)["Net Value"].sum().reset_index().rename(
                columns={"Net Value": f"{period1_start.strftime('%Y-%m-%d')} to {period1_end.strftime('%Y-%m-%d')} Sales"}
            )
            summary_p2 = df_p2.groupby(dimension)["Net Value"].sum().reset_index().rename(
                columns={"Net Value": f"{period2_start.strftime('%Y-%m-%d')} to {period2_end.strftime('%Y-%m-%d')} Sales"}
            )
            ytd_comparison = pd.merge(summary_p1, summary_p2, on=dimension, how="outer").fillna(0)
            ytd_comparison["Difference"] = ytd_comparison.iloc[:, 2] - ytd_comparison.iloc[:, 1]
            ytd_comparison.rename(columns={dimension: "Name"}, inplace=True)
            ytd_comparison.loc['Total'] = ytd_comparison.sum(numeric_only=True)
            ytd_comparison.loc['Total', 'Name'] = 'Total'

            st.subheader(f"ğŸ“‹ Comparison by {dimension}")
            styled_ytd = (
                ytd_comparison.style
                .set_table_styles([
                    {'selector': 'th', 'props': [('background', '#1E3A8A'), ('color', 'white'), ('font-weight', '800'), ('height', '40px'), ('line-height', '40px'), ('border', '1px solid #E5E7EB')]}
                ])
                .apply(lambda x: ['background-color: #BFDBFE; color: #1E3A8A; font-weight: 900' if x.name == 'Total' else '' for _ in x], axis=1)
                .format("{:,.0f}", subset=[ytd_comparison.columns[1], ytd_comparison.columns[2], 'Difference'])
            )
            st.dataframe(styled_ytd, use_container_width=True, hide_index=False)

            st.download_button(
                "â¬‡ï¸ Download YTD Comparison (Excel)",
                data=to_excel_bytes(ytd_comparison, sheet_name="YTD_Comparison", index=False),
                file_name=f"YTD_Comparison_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )

            # --- Top 10 Customers: Last Year vs Current Year ---
            st.subheader("ğŸ† Top 10 Customers â€“ Last Year vs Current Year")
            ytd_df["Year"] = ytd_df["Billing Date"].dt.year
            current_year = pd.Timestamp.today().year
            last_year = current_year - 1
            cust_sales = (
                ytd_df[ytd_df["Year"].isin([last_year, current_year])]
                .groupby(["PY Name 1", "Year"])["Net Value"]
                .sum()
                .reset_index()
            )
            if cust_sales.empty:
                st.info("âš ï¸ No customer sales found for last year or current year.")
            else:
                cust_pivot = cust_sales.pivot(index="PY Name 1", columns="Year", values="Net Value").fillna(0)
                cust_pivot["Total"] = cust_pivot.sum(axis=1)
                top10_cust = cust_pivot.sort_values("Total", ascending=False).head(10).reset_index()
                top10_melt = top10_cust.melt(id_vars="PY Name 1", value_vars=[last_year, current_year], var_name="Year", value_name="Sales")
                top10_melt = top10_melt.merge(top10_cust[["PY Name 1", last_year, current_year]], on="PY Name 1", how="left")
                top10_melt["Status"] = np.where(top10_melt["Year"] == current_year,
                                                np.where(top10_melt[current_year] >= top10_melt[last_year], "Achieved", "Not Achieved"),
                                                "Previous")
                color_map = {"Achieved": "green", "Not Achieved": "red", "Previous": "gray"}
                fig_top10 = px.bar(
                    top10_melt,
                    x="PY Name 1",
                    y="Sales",
                    color="Status",
                    color_discrete_map=color_map,
                    barmode="group",
                    text=top10_melt["Sales"].apply(lambda x: f"{x:,.0f}")
                )
                fig_top10.update_traces(textposition="inside", insidetextanchor="middle", textfont=dict(color="white", size=12))
                fig_top10.update_layout(title=f"Top 10 Customers: {last_year} vs {current_year}",
                                        xaxis_title="Customer", yaxis_title="Sales (KD)",
                                        font=dict(family="Roboto", size=12),
                                        plot_bgcolor="#F3F4F6", paper_bgcolor="#F3F4F6")
                st.plotly_chart(fig_top10, use_container_width=True)

            # --- Return by SP Name1 + Material Description (YTD) ---
            st.subheader("ğŸ”„ Return by SP Name1 + Material Description (YTD)")
            required_cols = {"SP Name1", "Material Description", "Billing Type", "Net Value"}
            if required_cols.issubset(ytd_df.columns):
                sp_mat_ytd = pd.pivot_table(
                    ytd_df,
                    index=["SP Name1", "Material Description"],
                    columns="Billing Type",
                    values="Net Value",
                    aggfunc="sum",
                    fill_value=0
                )
                billing_cols = ["ZFR", "YKF2", "YKRE", "YKS1", "YKS2", "ZCAN", "ZRE"]
                for col in billing_cols:
                    if col not in sp_mat_ytd.columns:
                        sp_mat_ytd[col] = 0
                sp_mat_ytd = sp_mat_ytd.rename(columns={"ZFR": "Presales", "YKF2": "HHT"})
                sp_mat_ytd["Sales Total"] = sp_mat_ytd.sum(axis=1, numeric_only=True)
                sp_mat_ytd["Return"] = sp_mat_ytd["YKRE"] + sp_mat_ytd["ZRE"]
                sp_mat_ytd["Cancel Total"] = sp_mat_ytd[["YKS1", "YKS2", "ZCAN"]].sum(axis=1)
                sp_mat_ytd["Return %"] = np.where(sp_mat_ytd["Sales Total"] != 0,
                                                  (sp_mat_ytd["Return"] / sp_mat_ytd["Sales Total"] * 100).round(0), 0)
                ordered_cols = ["Presales", "HHT", "Sales Total", "YKS1", "YKS2", "ZCAN",
                                "Cancel Total", "YKRE", "ZRE", "Return", "Return %"]
                sp_mat_ytd = sp_mat_ytd.reindex(columns=ordered_cols, fill_value=0)
                total_row = pd.DataFrame(sp_mat_ytd.sum(numeric_only=True)).T
                total_row.index = [("Total", "")]
                total_row["Return %"] = round((total_row["Return"] / total_row["Sales Total"] * 100), 0) if total_row["Sales Total"].iloc[0] != 0 else 0
                sp_mat_ytd = pd.concat([sp_mat_ytd, total_row])

                # Conditional highlights for easy read
                def highlight_sp_mat(row):
                    styles = []
                    for col in row.index:
                        if row.name == ("Total", ""):
                            styles.append('background-color: #BFDBFE; color: #1E3A8A; font-weight: 900')
                        elif col == "Return" and row[col] > 0:
                            styles.append('background-color: #FECACA; color: #991B1B; font-weight: 700')
                        elif col == "Cancel Total" and row[col] > 0:
                            styles.append('background-color: #FDE68A; color: #92400E; font-weight: 700')
                        elif col == "Sales Total" and row[col] > 0:
                            styles.append('background-color: #D1FAE5; color: #065F46; font-weight: 700')
                        else:
                            styles.append('')
                    return styles

                styled_sp_mat = (
                    sp_mat_ytd.style
                    .set_table_styles([
                        {'selector': 'th', 'props': [('background', '#1E3A8A'), ('color', 'white'),
                                                    ('font-weight', '800'), ('height', '40px'),
                                                    ('line-height', '40px'), ('border', '1px solid #E5E7EB')]}
                    ])
                    .apply(highlight_sp_mat, axis=1)
                    .format({
                        "Presales": "{:,.0f}", "HHT": "{:,.0f}", "Sales Total": "{:,.0f}",
                        "YKS1": "{:,.0f}", "YKS2": "{:,.0f}", "ZCAN": "{:,.0f}", "Cancel Total": "{:,.0f}",
                        "YKRE": "{:,.0f}", "ZRE": "{:,.0f}", "Return": "{:,.0f}", "Return %": "{:.0f}%"
                    })
                )
                st.dataframe(styled_sp_mat, use_container_width=True)
                st.download_button(
                    "â¬‡ï¸ Download Return by SP+Material (YTD)",
                    data=to_excel_bytes(sp_mat_ytd.reset_index(), sheet_name="Return_by_SP_Material_YTD", index=False),
                    file_name=f"Return_by_SP_Material_YTD_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
            else:
                st.info("Required columns for SP+Material YTD table are missing.")

    else:
        st.warning("âš ï¸ Please ensure the 'YTD' sheet is present in your uploaded file.")




# --- Custom Analysis Page ---
elif choice == texts[lang]["custom_analysis"]:
    st.title(texts[lang]["custom_title"])
    if "data_loaded" not in st.session_state:
        st.warning(texts[lang]["no_data_warning"])
    else:
        # âœ… Ensure Extra sheet is loaded into session state
        if "Extra_sheet_df" not in st.session_state:
            try:
                extra_df = pd.read_excel(uploaded, sheet_name="Extra sheet")
            except Exception:
                extra_df = pd.DataFrame()
            st.session_state["Extra_sheet_df"] = extra_df

        # Available sheet options
        sheet_options = {
            "Sales Data": st.session_state.get("sales_df", pd.DataFrame()),
            "YTD": st.session_state.get("ytd_df", pd.DataFrame()),
            "Target": st.session_state.get("target_df", pd.DataFrame()),
            "Sales Channels": st.session_state.get("channels_df", pd.DataFrame()),
            "Extra sheet": st.session_state.get("Extra_sheet_df", pd.DataFrame())
        }

        selected_sheet_name = st.selectbox(texts[lang]["custom_select_sheet"], list(sheet_options.keys()))
        df = sheet_options[selected_sheet_name]

        if df.empty:
            st.warning(texts[lang]["custom_sheet_empty"].format(selected_sheet_name))
        else:
            st.subheader(texts[lang]["custom_explore"])

            available_cols = list(df.columns)
            group_cols = st.multiselect(texts[lang]["custom_group_cols"], available_cols)
            value_col = st.selectbox(texts[lang]["custom_value_col"], available_cols)

            if "Billing Date" in df.columns:
                st.subheader(texts[lang]["custom_periods_sub"])
                col1, col2 = st.columns(2)
                with col1:
                    st.write(texts[lang]["custom_period1"])
                    period1_range = st.date_input(
                        texts[lang]["custom_select_p1"],
                        [df["Billing Date"].min(), df["Billing Date"].max()],
                        key="ca_p1_range"
                    )
                with col2:
                    st.write(texts[lang]["custom_period2"])
                    period2_range = st.date_input(
                        texts[lang]["custom_select_p2"],
                        [df["Billing Date"].min(), df["Billing Date"].max()],
                        key="ca_p2_range"
                    )
            else:
                period1_range = period2_range = None
                st.info("âš ï¸ No 'Billing Date' column found. Period comparison disabled.")

            if group_cols and value_col and period1_range and period2_range and len(period1_range) == 2 and len(period2_range) == 2:
                # --- Period 1 ---
                p1_start, p1_end = pd.to_datetime(period1_range[0]), pd.to_datetime(period1_range[1])
                df_p1 = df[(df["Billing Date"] >= p1_start) & (df["Billing Date"] <= p1_end)]
                summary_p1 = df_p1.groupby(group_cols)[value_col].sum().reset_index()
                summary_p1.rename(columns={value_col: "Period 1"}, inplace=True)

                # --- Period 2 ---
                p2_start, p2_end = pd.to_datetime(period2_range[0]), pd.to_datetime(period2_range[1])
                df_p2 = df[(df["Billing Date"] >= p2_start) & (df["Billing Date"] <= p2_end)]
                summary_p2 = df_p2.groupby(group_cols)[value_col].sum().reset_index()
                summary_p2.rename(columns={value_col: "Period 2"}, inplace=True)

                # --- Merge & Compare ---
                comparison_df = pd.merge(summary_p1, summary_p2, on=group_cols, how="outer").fillna(0)
                comparison_df["Difference"] = comparison_df["Period 2"] - comparison_df["Period 1"]

                st.subheader(texts[lang]["custom_comparison_sub"].format(value_col, ", ".join(group_cols)))
                styled_custom = (
                    comparison_df.style
                    .set_table_styles([
                        {'selector': 'th', 'props': [('background', '#1E3A8A'), ('color', 'white'),
                                                    ('font-weight', '800'), ('height', '40px'),
                                                    ('line-height', '40px'), ('border', '1px solid #E5E7EB')]}
                    ])
                    .format({
                        "Period 1": "{:,.0f}",
                        "Period 2": "{:,.0f}",
                        "Difference": "{:,.0f}"
                    })
                )
                st.dataframe(styled_custom, use_container_width=True)

                # --- Plotly Chart Fix ---
                df_plot = comparison_df.sort_values(by="Period 2", ascending=False).copy()

                if len(group_cols) == 1:
                    df_plot["Group"] = df_plot[group_cols[0]].astype(str)
                elif len(group_cols) > 1:
                    df_plot["Group"] = df_plot[group_cols].astype(str).agg(" | ".join, axis=1)
                else:
                    df_plot["Group"] = "All Data"

                df_plot_melted = df_plot.melt(
                    id_vars=["Group"],
                    value_vars=["Period 1", "Period 2"],
                    var_name="Period",
                    value_name="Value"
                )

                fig = px.bar(
                    df_plot_melted,
                    x="Group",
                    y="Value",
                    color="Period",
                    barmode="group",
                    title=f"Comparison of {value_col} by {', '.join(group_cols) if group_cols else 'All'}",
                    color_discrete_sequence=px.colors.qualitative.Set2
                )
                st.plotly_chart(fig, use_container_width=True)

                # --- Download ---
                if st.download_button(
                    texts[lang]["custom_download"],
                    data=to_excel_bytes(comparison_df, sheet_name="Custom_Comparison", index=False),
                    file_name=f"Custom_Comparison_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                ):
                    st.session_state["audit_log"].append({
                        "user": username,
                        "action": "download",
                        "details": "Custom Comparison Excel",
                        "timestamp": datetime.now()
                    })
            else:
                st.info(texts[lang]["custom_select_prompt"])

# --- SP/PY Target Allocation Page ---
elif choice == "SP/PY Target Allocation":
    st.title("ğŸ¯ SP/PY Target Allocation")
    if "data_loaded" not in st.session_state:
        st.warning("âš ï¸ Please upload the Excel file from the sidebar first.")
        st.stop()

    sales_df = st.session_state["sales_df"]
    ytd_df = st.session_state["ytd_df"]
    target_df = st.session_state.get("target_df", pd.DataFrame())

    st.subheader("Configuration")
    st.markdown('<div class="tooltip">â„¹ï¸<span class="tooltiptext">Allocate targets by branch or customer based on historical sales.</span></div>', unsafe_allow_html=True)
    allocation_type = st.radio("Select Target Allocation Type", ["By Branch (SP Name1)", "Customer (PY Name 1)"])
    group_col = "SP Name1" if allocation_type == "By Branch (SP Name1)" else "PY Name 1"

    target_option = st.radio("Select Target Input Option", ["Manual", "Auto (from 'Target' sheet)"])

    total_target = 0
    if target_option == "Manual":
        total_target = st.number_input("Enter the Total Target to be Allocated for this Month (KD)", min_value=0, value=1000000, step=1000)
    else:
        if target_df.empty or "KA Target" not in target_df.columns:
            st.error("âŒ 'Target' sheet or 'KA Target' column not found. Please upload a file with this sheet for 'Auto' mode.")
            st.stop()
        total_target = target_df["KA Target"].sum()
        st.info(f"Using Total Target from 'Target' sheet: KD {total_target:,.0f}")

    if total_target <= 0:
        st.warning("Please ensure the total target is greater than 0.")
        st.stop()

    st.subheader("Historical Data Period")
    today = pd.Timestamp.today().normalize()
    data_period_option = st.radio("Select Historical Data Period", ["Last 6 Months", "Manual Days"], index=1)

    if data_period_option == "Last 6 Months":
        lookback_period = pd.DateOffset(months=6)
        days_label = "6 Months"; months_count = 6
        end_date_selected = today; start_date_selected = today - lookback_period
    else:
        start_date_manual = today - pd.DateOffset(days=180)
        selected_dates = st.date_input("Select date range", value=(start_date_manual, today))
        if len(selected_dates) == 2:
            start_date_selected, end_date_selected = selected_dates
            lookback_period = end_date_selected - start_date_selected
            days_label = f"From {start_date_selected.strftime('%Y-%m-%d')} to {end_date_selected.strftime('%Y-%m-%d')}"
            months_count = lookback_period.days / 30
        else:
            st.warning("Please select both a start and an end date.")
            st.stop()

    historical_df = ytd_df[(ytd_df["Billing Date"] >= pd.Timestamp(start_date_selected)) & (ytd_df["Billing Date"] <= pd.Timestamp(end_date_selected))].copy()
    if historical_df.empty:
        st.warning(f"âš ï¸ No sales data available in 'YTD' for {days_label}.")
        st.stop()

    historical_sales = historical_df.groupby(group_col)["Net Value"].sum()
    total_historical_sales_value = historical_sales.sum()
    current_month_sales_df = sales_df[(sales_df["Billing Date"].dt.month == today.month) & (sales_df["Billing Date"].dt.year == today.year)].copy()
    current_month_sales = current_month_sales_df.groupby(group_col)["Net Value"].sum()
    total_current_month_sales = current_month_sales.sum()

    target_balance = total_target - total_current_month_sales

    if total_target > 0:
        average_historical_sales = total_historical_sales_value / months_count
        st.subheader("ğŸ¯ Target Analysis")
        col1, col2, col3 = st.columns(3)
        col4, col5 = st.columns(2)
        with col1: st.metric("Historical Sales Total", f"KD {total_historical_sales_value:,.0f}")
        with col2: st.metric("Allocated Target Total", f"KD {total_target:,.0f}")
        with col3:
            if average_historical_sales > 0:
                percentage_increase_needed = ((total_target - average_historical_sales) / average_historical_sales) * 100
                delta_value = total_target - average_historical_sales
                st.metric("Increase Needed vs Avg Sales", f"{percentage_increase_needed:.0f}%", delta=f"KD {delta_value:,.0f}")
            else:
                st.metric("Increase Needed vs Avg Sales", "N/A", delta="Historical = 0")
        st.markdown("---")
        with col4: st.metric("Current Month Sales", f"KD {total_current_month_sales:,.0f}")
        with col5: st.metric("Target Balance", f"KD {target_balance:,.0f}")

    allocation_table = pd.DataFrame(index=historical_sales.index.union(current_month_sales.index).unique())
    allocation_table.index.name = "Name"
    allocation_table[f"Last {days_label} Total Sales"] = historical_sales.reindex(allocation_table.index, fill_value=0)
    allocation_table[f"Last {days_label} Average Sales"] = allocation_table[f"Last {days_label} Total Sales"] / months_count
    if total_historical_sales_value > 0:
        allocation_table["This Month Auto-Allocated Target"] = allocation_table[f"Last {days_label} Total Sales"] / total_historical_sales_value * total_target
    else:
        allocation_table["This Month Auto-Allocated Target"] = 0
    allocation_table["Current Month Sales"] = current_month_sales.reindex(allocation_table.index, fill_value=0)
    allocation_table["Target Balance"] = allocation_table["This Month Auto-Allocated Target"] - allocation_table["Current Month Sales"]

    total_row = allocation_table.sum().to_frame().T
    total_row.index = ["Total"]
    total_row["Target Balance"] = total_target - total_current_month_sales
    allocation_table_with_total = pd.concat([allocation_table, total_row])

    def color_target_balance(val):
        if isinstance(val, (int, float)):
            color = 'red' if val > 0 else 'green'
            return f'color: {color}'
        return ''

    st.subheader(f"ğŸ“Š Auto-Allocated Targets Based on {days_label}")
    styled_allocation = (
        allocation_table_with_total.astype(int).style
        .set_table_styles([
            {'selector': 'th', 'props': [('background', '#1E3A8A'), ('color', 'white'), ('font-weight', '800'), ('height', '40px'), ('line-height', '40px'), ('border', '1px solid #E5E7EB')]}
        ])
        .apply(lambda x: ['background-color: #BFDBFE; color: #1E3A8A; font-weight: 900' if x.name == 'Total' else '' for _ in x], axis=1)
        .format("{:,.0f}")
    )
    st.dataframe(styled_allocation, use_container_width=True)

    timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    excel_data = to_excel_bytes(allocation_table, sheet_name="Allocated_Targets")
    if st.download_button(
        "ğŸ’¾ Download Target Allocation Table",
        data=excel_data,
        file_name=f"target_allocation_{allocation_type.replace(' ', '_')}_{timestamp}.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    ):
        st.session_state["audit_log"].append({
            "user": username,
            "action": "download",
            "details": f"target_allocation_{allocation_type.replace(' ', '_')}_{timestamp}.xlsx",
            "timestamp": datetime.now()
        })

# --- AI Insights Page ---
elif choice == "AI Insights":
    st.title("ğŸ¤– AI Insights")

    if "data_loaded" not in st.session_state:
        st.warning("âš ï¸ Please upload the Excel file first.")
    else:
        # Source data (unaltered) - now explicitly using all sheets
        sales_df = st.session_state["sales_df"]
        target_df = st.session_state["target_df"]
        ytd_df = st.session_state["ytd_df"]
        channels_df = st.session_state["channels_df"]

        # Controls for scope of AI narrative (kept separate to avoid changing other pages' logic)
        st.subheader("Scope and filters")
        colf1, colf2 = st.columns(2)
        with colf1:
            # Date range for insights (default full range to capture general view)
            date_range_ai = st.date_input(
                "Select period for insights",
                value=(sales_df["Billing Date"].min(), sales_df["Billing Date"].max())
            )
        with colf2:
            top_n_ai = st.slider("Top-N salesmen spotlight", min_value=3, max_value=20, value=5, step=1)

        # Safety: convert to Timestamps
        if isinstance(date_range_ai, (list, tuple)) and len(date_range_ai) == 2:
            ai_start, ai_end = pd.to_datetime(date_range_ai[0]), pd.to_datetime(date_range_ai[1])
        else:
            ai_start, ai_end = sales_df["Billing Date"].min(), sales_df["Billing Date"].max()

        df_ai = sales_df[(sales_df["Billing Date"] >= ai_start) & (sales_df["Billing Date"] <= ai_end)].copy()

        if df_ai.empty:
            st.info("No data in the selected period. Try expanding the date range.")
            st.stop()

        # --- Reuse same patterns and formulas from Sales Tracking (separate compute, no changes to original) ---
        today = pd.Timestamp.today().normalize()
        billing_start_ai = df_ai["Billing Date"].min().normalize()
        billing_end_ai = df_ai["Billing Date"].max().normalize()
        all_days_ai = pd.date_range(billing_start_ai, billing_end_ai, freq="D")
        days_finish_ai = int(sum(1 for d in all_days_ai if d.weekday() != 4))

        current_month_start_ai = today.replace(day=1)
        current_month_end_ai = current_month_start_ai + pd.offsets.MonthEnd(0)
        month_days_ai = pd.date_range(current_month_start_ai, current_month_end_ai, freq="D")
        working_days_current_month_ai = int(sum(1 for d in month_days_ai if d.weekday() != 4))

        total_sales_by_sm = df_ai.groupby("Driver Name EN")["Net Value"].sum()
        talabat_ai = df_ai[df_ai["PY Name 1"] == "STORES SERVICES KUWAIT CO."].groupby("Driver Name EN")["Net Value"].sum()
        ka_targets_ai = target_df.set_index("Driver Name EN")["KA Target"] if "KA Target" in target_df.columns else pd.Series(dtype=float)
        tal_targets_ai = target_df.set_index("Driver Name EN")["Talabat Target"] if "Talabat Target" in target_df.columns else pd.Series(dtype=float)

        idx_union = total_sales_by_sm.index.union(talabat_ai.index).union(ka_targets_ai.index).union(tal_targets_ai.index)
        total_sales_by_sm = total_sales_by_sm.reindex(idx_union, fill_value=0).astype(float)
        talabat_ai = talabat_ai.reindex(idx_union, fill_value=0).astype(float)
        ka_targets_ai = ka_targets_ai.reindex(idx_union, fill_value=0).astype(float)
        tal_targets_ai = tal_targets_ai.reindex(idx_union, fill_value=0).astype(float)

        ka_gap_ai = (ka_targets_ai - total_sales_by_sm).clip(lower=0)
        tal_gap_ai = (tal_targets_ai - talabat_ai).clip(lower=0)

        total_ka_target_all_ai = float(ka_targets_ai.sum())
        total_tal_target_all_ai = float(tal_targets_ai.sum())
        per_day_ka_target_ai = (total_ka_target_all_ai / working_days_current_month_ai) if working_days_current_month_ai > 0 else 0
        current_sales_per_day_ai = (total_sales_by_sm.sum() / days_finish_ai) if days_finish_ai > 0 else 0
        forecast_month_end_ka_ai = current_sales_per_day_ai * working_days_current_month_ai

        # Channels
        df_py_sales_ai = df_ai.groupby("_py_name_norm")["Net Value"].sum().reset_index()
        df_channels_merged_ai = df_py_sales_ai.merge(
            channels_df[["_py_name_norm", "Channels"]],
            on="_py_name_norm",
            how="left"
        )
        df_channels_merged_ai["Channels"] = df_channels_merged_ai["Channels"].astype(str).str.strip().str.lower().fillna("uncategorized")
        ch_sales = df_channels_merged_ai.groupby("Channels")["Net Value"].sum()
        total_retail_ai = float(ch_sales.get("market", 0.0) + ch_sales.get("uncategorized", 0.0))
        total_ecom_ai = float(ch_sales.get("e-com", 0.0))
        total_channel_ai = total_retail_ai + total_ecom_ai
        retail_pct_ai = (total_retail_ai / total_channel_ai * 100) if total_channel_ai > 0 else 0
        ecom_pct_ai = (total_ecom_ai / total_channel_ai * 100) if total_channel_ai > 0 else 0

        # Spotlight
        top_sm_ai = total_sales_by_sm.sort_values(ascending=False).head(top_n_ai)
        bottom_sm_ai = total_sales_by_sm.sort_values(ascending=True).head(top_n_ai)

        # YTD section (optional if ytd_df available)
        def ytd_quick_compare(ytd_df):
            if ytd_df.empty:
                return None
            # Use the max date in ytd_df as effective "today" to avoid future date issues
            effective_today = ytd_df["Billing Date"].max()
            # Last 30 days vs prior 30 days (rolling window quick pulse)
            p2_end = effective_today
            p2_start = effective_today - pd.Timedelta(days=30)
            p1_end = p2_start
            p1_start = p1_end - pd.Timedelta(days=30)

            df_p1 = ytd_df[(ytd_df["Billing Date"] >= p1_start) & (ytd_df["Billing Date"] < p1_end)]
            df_p2 = ytd_df[(ytd_df["Billing Date"] >= p2_start) & (ytd_df["Billing Date"] <= p2_end)]

            total_p1 = df_p1["Net Value"].sum()
            total_p2 = df_p2["Net Value"].sum()
            diff = total_p2 - total_p1
            pct = (diff / total_p1 * 100) if total_p1 else np.nan

            # Enhanced: YoY if possible (assume data spans years)
            current_year = effective_today.year
            prev_year = current_year - 1
            ytd_current = ytd_df[(ytd_df["Billing Date"].dt.year == current_year)]["Net Value"].sum()
            ytd_prev = ytd_df[(ytd_df["Billing Date"].dt.year == prev_year)]["Net Value"].sum()
            yoy_diff = ytd_current - ytd_prev
            yoy_pct = (yoy_diff / ytd_prev * 100) if ytd_prev else np.nan

            # New: MoM growth using latest available month as "current"
            current_month = effective_today.month
            current_year_mom = effective_today.year
            prev_month = current_month - 1 if current_month > 1 else 12
            prev_month_year = current_year_mom if current_month > 1 else current_year_mom - 1
            mom_current = ytd_df[(ytd_df["Billing Date"].dt.year == current_year_mom) & (ytd_df["Billing Date"].dt.month == current_month)]["Net Value"].sum()
            mom_prev = ytd_df[(ytd_df["Billing Date"].dt.year == prev_month_year) & (ytd_df["Billing Date"].dt.month == prev_month)]["Net Value"].sum()
            mom_diff = mom_current - mom_prev
            mom_pct = (mom_diff / mom_prev * 100) if mom_prev else np.nan

            # NEW: Labels for months and years
            current_month_label = effective_today.strftime("%B %Y")
            prev_month_label = pd.to_datetime(f"{prev_month_year}-{prev_month}-01").strftime("%B %Y")
            current_year_label = str(current_year)
            prev_year_label = str(prev_year)

            return dict(
                p1_start=p1_start.date(), p1_end=p1_end.date(),
                p2_start=p2_start.date(), p2_end=p2_end.date(),
                total_p1=total_p1, total_p2=total_p2,
                diff=diff, pct=pct,
                ytd_current=ytd_current, ytd_prev=ytd_prev,
                yoy_diff=yoy_diff, yoy_pct=yoy_pct,
                mom_current=mom_current, mom_prev=mom_prev,
                mom_diff=mom_diff, mom_pct=mom_pct,
                latest_month_label=current_month_label,
                prev_month_label=prev_month_label,
                current_year_label=current_year_label,
                prev_year_label=prev_year_label
            )

        ytd_pulse = ytd_quick_compare(ytd_df)

        # Target allocation pulse (mirror logic summarization, not changing original)
        def allocation_pulse():
            if ytd_df.empty:
                return None
            # Default pulse uses last 180 days (same default used in allocation manual mode)
            end_date = today
            start_date = today - pd.DateOffset(days=180)
            hist = ytd_df[(ytd_df["Billing Date"] >= start_date) & (ytd_df["Billing Date"] <= end_date)]
            if hist.empty:
                return None
            months_count = (end_date - start_date).days / 30 if (end_date - start_date).days > 0 else 6
            total_hist = hist["Net Value"].sum()
            effective_today = sales_df["Billing Date"].max() if not sales_df.empty else today
            current_month = sales_df[(sales_df["Billing Date"].dt.month == effective_today.month) & (sales_df["Billing Date"].dt.year == effective_today.year)]
            current_month_total = current_month["Net Value"].sum()
            allocated_target_sheet = target_df["KA Target"].sum() if "KA Target" in target_df.columns else 0
            avg_hist = total_hist / months_count if months_count else 0
            inc_needed_pct = ((allocated_target_sheet - avg_hist) / avg_hist * 100) if avg_hist else np.nan

            # Enhanced: Correlation between historical sales and targets
            if not target_df.empty and "Driver Name EN" in target_df.columns and "KA Target" in target_df.columns:
                hist_by_sm = hist.groupby("Driver Name EN")["Net Value"].sum()
                targets_by_sm = target_df.set_index("Driver Name EN")["KA Target"]
                common_idx = hist_by_sm.index.intersection(targets_by_sm.index)
                if len(common_idx) > 1:
                    corr = np.corrcoef(hist_by_sm.loc[common_idx], targets_by_sm.loc[common_idx])[0, 1]
                else:
                    corr = np.nan
            else:
                corr = np.nan

            # New: Suggested target adjustments based on performance
            if not hist.empty and not target_df.empty:
                hist_avg_by_sm = hist.groupby("Driver Name EN")["Net Value"].mean()
                target_adjust = hist_avg_by_sm * 1.1  # Example: suggest 10% increase over avg historical
            else:
                target_adjust = pd.Series()

            return dict(
                hist_period=f"{start_date.date()} to {end_date.date()}",
                total_hist=total_hist,
                avg_hist=avg_hist,
                allocated_target=allocated_target_sheet,
                current_month_total=current_month_total,
                inc_needed_pct=inc_needed_pct,
                target_sales_corr=corr,
                suggested_targets=target_adjust,
                latest_month_label=f"{effective_today.strftime('%B %Y')}"
            )

        alloc_pulse = allocation_pulse()

        # New: Target sheet insights
        def target_insights(target_df):
            if target_df.empty:
                return None
            total_ka = target_df["KA Target"].sum() if "KA Target" in target_df.columns else 0
            total_tal = target_df["Talabat Target"].sum() if "Talabat Target" in target_df.columns else 0
            avg_ka = target_df["KA Target"].mean() if "KA Target" in target_df.columns else 0
            top_target_sm = target_df.sort_values("KA Target", ascending=False).head(1)["Driver Name EN"].iloc[0] if "KA Target" in target_df.columns and "Driver Name EN" in target_df.columns else "N/A"
            target_variance = target_df["KA Target"].std() if "KA Target" in target_df.columns else 0

            # New: Target distribution stats
            if "KA Target" in target_df.columns:
                target_quartiles = target_df["KA Target"].quantile([0.25, 0.5, 0.75])
            else:
                target_quartiles = pd.Series()

            return dict(
                total_ka=total_ka,
                total_tal=total_tal,
                avg_ka=avg_ka,
                top_target_sm=top_target_sm,
                target_variance=target_variance,
                target_quartiles=target_quartiles
            )

        target_pulse = target_insights(target_df)

        # New: Channels sheet insights
        def channels_insights(channels_df):
            if channels_df.empty:
                return None
            channel_counts = channels_df["Channels"].value_counts()
            top_channel = channel_counts.idxmax() if not channel_counts.empty else "N/A"
            num_py = channels_df["PY Name 1"].nunique()

            # New: Channel sales integration if possible
            channel_sales_ai = df_channels_merged_ai.groupby("Channels")["Net Value"].sum()
            return dict(
                channel_dist=channel_counts.to_dict(),
                top_channel=top_channel,
                num_py=num_py,
                channel_sales=channel_sales_ai.to_dict()
            )

        channels_pulse = channels_insights(channels_df)

        # Enhanced: Advanced forecasting using ExponentialSmoothing
        def advanced_forecast(df_time):
            if len(df_time) < 14:  # At least two full cycles for seasonal=7
                return None
            model = ExponentialSmoothing(df_time["y"], trend="add", seasonal="add", seasonal_periods=7, initialization_method='estimated')
            fit = model.fit()
            forecast = fit.forecast(30)
            return forecast

        df_time_ai = df_ai.groupby(pd.Grouper(key="Billing Date", freq="D"))["Net Value"].sum().reset_index()
        df_time_ai.rename(columns={"Billing Date": "ds", "Net Value": "y"}, inplace=True)
        exp_forecast = advanced_forecast(df_time_ai)

        # New: Linear regression for trend analysis
        def linear_trend(df_time):
            if len(df_time) < 2:
                return None
            df_time['day_num'] = (df_time['ds'] - df_time['ds'].min()).dt.days
            model = LinearRegression()
            model.fit(df_time[['day_num']], df_time['y'])
            future_days = np.arange(df_time['day_num'].max() + 1, df_time['day_num'].max() + 31).reshape(-1, 1)
            trend_forecast = model.predict(future_days)
            return trend_forecast

        lin_forecast = linear_trend(df_time_ai)

        # New: Anomaly detection enhancement
        def detect_anomalies(df_time):
            if len(df_time) < 7:
                return pd.DataFrame()
            roll = df_time["y"].rolling(window=7)
            mean = roll.mean()
            std = roll.std()
            df_time['upper'] = mean + 2 * std
            df_time['lower'] = mean - 2 * std
            anomalies = df_time[(df_time['y'] > df_time['upper']) | (df_time['y'] < df_time['lower'])]
            return anomalies

        anomalies_ai = detect_anomalies(df_time_ai)

        # NEW: RFM Integration for Customer Insights
        today = pd.Timestamp.today().normalize()
        rfm_ai = df_ai.groupby("SP Name1").agg({
            "Billing Date": lambda x: (today - x.max()).days,
            "Net Value": ["count", "sum"]
        }).reset_index()
        rfm_ai.columns = ["Customer", "Recency", "Frequency", "Monetary"]
        rfm_ai = rfm_ai[rfm_ai["Monetary"] > 0]

        if not rfm_ai.empty:
            # Safe qcut function (from customer insights)
            def safe_qcut(series, q=4, reverse=False):
                s = series.copy().fillna(series.max() + 1)
                unique_vals = s.unique()
                n_unique = len(unique_vals)
                if n_unique == 1:
                    return pd.Series([1]*len(s), index=s.index)
                if n_unique < q:
                    ranks = s.rank(method='dense', ascending=not reverse)
                    return ranks.astype(int)
                labels = list(range(q, 0, -1)) if reverse else list(range(1, q+1))
                try:
                    return pd.qcut(s, q=q, labels=labels, duplicates='drop')
                except ValueError:
                    ranks = s.rank(method='dense', ascending=not reverse)
                    return ranks.astype(int)

            rfm_ai["R_Score"] = safe_qcut(rfm_ai["Recency"], q=4, reverse=True)
            rfm_ai["F_Score"] = safe_qcut(rfm_ai["Frequency"], q=4)
            rfm_ai["M_Score"] = safe_qcut(rfm_ai["Monetary"], q=4)
            rfm_ai["RFM_Score"] = rfm_ai["R_Score"].astype(str) + rfm_ai["F_Score"].astype(str) + rfm_ai["M_Score"].astype(str)

            def rfm_segment(row):
                if row["RFM_Score"] in ["444", "443", "434", "433"]:
                    return "Champions"
                elif row["R_Score"] >= 3 and row["F_Score"] >= 3:
                    return "Loyal Customers"
                elif row["R_Score"] >= 3 and row["M_Score"] >= 3:
                    return "Potential Loyalists"
                elif row["R_Score"] >= 3:
                    return "New Customers"
                elif row["R_Score"] <= 2 and row["F_Score"] >= 2 and row["M_Score"] >= 2:
                    return "At Risk"
                elif row["R_Score"] <= 1 and row["F_Score"] >= 2 and row["M_Score"] >= 2:
                    return "Hibernating"
                else:
                    return "Others"

            rfm_ai["Segment"] = rfm_ai.apply(rfm_segment, axis=1)
            segment_sales = rfm_ai.groupby("Segment")["Monetary"].sum().sort_values(ascending=False)
        else:
            segment_sales = pd.Series()

        # NEW: Industry Benchmarking (Static for now; can integrate web_search later)
        # Assuming some benchmark data; in production, use web_search tool
        kuwait_retail_yoy_benchmark = 3.8  # Updated average from 3.13% CAGR retail and 4.5% CPG
        if ytd_pulse and pd.notnull(ytd_pulse.get("yoy_pct")):
            your_yoy = ytd_pulse["yoy_pct"]
            benchmark_insight = f"Your YoY growth: {your_yoy:.1f}% vs. Kuwait retail avg ~{kuwait_retail_yoy_benchmark}%."
        else:
            benchmark_insight = "Benchmark data requires YTD comparison."

        # --- AI-style narrative generation (rule-based, data-driven; no change to your formulas) ---
        def fmt_kd(x):
            try:
                return f"KD {x:,.0f}"
            except:
                return "KD 0"

        st.subheader("ğŸ“œ Executive summary")
        summary_lines = []

        # Overall performance
        total_sales_all = total_sales_by_sm.sum()
        ka_ach_pct = (total_sales_all / total_ka_target_all_ai * 100) if total_ka_target_all_ai > 0 else 0
        tal_ach_pct = (talabat_ai.sum() / total_tal_target_all_ai * 100) if total_tal_target_all_ai > 0 else 0
        summary_lines.append(f"- Overall sales in selected period: {fmt_kd(total_sales_all)}.")
        if total_ka_target_all_ai > 0:
            summary_lines.append(f"- KA target achievement: {ka_ach_pct:.0f}% with a remaining gap of {fmt_kd(max(total_ka_target_all_ai - total_sales_all, 0))}.")
        if total_tal_target_all_ai > 0:
            summary_lines.append(f"- Talabat target achievement: {tal_ach_pct:.0f}% with a remaining gap of {fmt_kd(max(total_tal_target_all_ai - talabat_ai.sum(), 0))}. ")

        # Channels
        if total_channel_ai > 0:
            summary_lines.append(f"- Channel mix: Retail {retail_pct_ai:.0f}% ({fmt_kd(total_retail_ai)}), E-com {ecom_pct_ai:.0f}% ({fmt_kd(total_ecom_ai)}).")

        # Productivity and forecast
        if working_days_current_month_ai > 0 and days_finish_ai > 0:
            summary_lines.append(f"- Current sales/day: {fmt_kd(current_sales_per_day_ai)} vs daily KA target {fmt_kd(per_day_ka_target_ai)}.")
            summary_lines.append(f"- Prophet forecast month-end KA sales: {fmt_kd(forecast_month_end_ka_ai)} based on current run-rate.")
            if exp_forecast is not None:
                exp_month_end = exp_forecast.sum()  # Sum of next 30 days forecast
                summary_lines.append(f"- Advanced (Holt-Winters) 30-day forecast: {fmt_kd(exp_month_end)}.")
            else:
                summary_lines.append("- Insufficient data for advanced Holt-Winters forecast (needs at least 14 daily points).")
            if lin_forecast is not None:
                lin_month_end = lin_forecast.sum()
                summary_lines.append(f"- Linear trend 30-day forecast: {fmt_kd(lin_month_end)}.")

        # Top/bottom salesmen insights
        if not top_sm_ai.empty:
            top_name = top_sm_ai.index[0]
            top_val = top_sm_ai.iloc[0]
            summary_lines.append(f"- Top performer: {top_name} with {fmt_kd(top_val)}. Top {top_n_ai} contribute {fmt_kd(top_sm_ai.sum())} ({(top_sm_ai.sum()/total_sales_all*100 if total_sales_all else 0):.0f}% of total).")
        if not bottom_sm_ai.empty:
            bottom_name = bottom_sm_ai.index[0]
            bottom_val = bottom_sm_ai.iloc[0]
            summary_lines.append(f"- Watchlist: {bottom_name} at {fmt_kd(bottom_val)}. Consider targeted coaching, route optimization, or mix improvement.")

        # YTD pulse
        if ytd_pulse:
            p = ytd_pulse
            trend_word = "up" if p["diff"] > 0 else "down" if p["diff"] < 0 else "flat"
            pct_txt = f"{p['pct']:.0f}%" if pd.notnull(p["pct"]) else "N/A"
            summary_lines.append(
                f"- YTD pulse (last 30d vs prior): {trend_word} by {fmt_kd(abs(p['diff']))} ({pct_txt}). "
                f"[{p['p1_start']}â€“{p['p1_end']}] vs [{p['p2_start']}â€“{p['p2_end']}]"
            )
            yoy_trend = "up" if p["yoy_diff"] > 0 else "down" if p["yoy_diff"] < 0 else "flat"
            yoy_pct_txt = f"{p['yoy_pct']:.0f}%" if pd.notnull(p["yoy_pct"]) else "N/A"
            summary_lines.append(
                f"- YoY YTD ({p['current_year_label']} vs {p['prev_year_label']}): {yoy_trend} by {fmt_kd(abs(p['yoy_diff']))} ({yoy_pct_txt}). "
                f"Latest year: {fmt_kd(p['ytd_current'])}, Prev year: {fmt_kd(p['ytd_prev'])}."
            )
            # NEW: Benchmark
            summary_lines.append(f"- {benchmark_insight}")
            mom_trend = "up" if p["mom_diff"] > 0 else "down" if p["mom_diff"] < 0 else "flat"
            mom_pct_txt = f"{p['mom_pct']:.0f}%" if pd.notnull(p["mom_pct"]) else "N/A"
            summary_lines.append(
                f"- MoM ({p['latest_month_label']} vs {p['prev_month_label']}): {mom_trend} by {fmt_kd(abs(p['mom_diff']))} ({mom_pct_txt}). "
                f"Latest month: {fmt_kd(p['mom_current'])}, Prev month: {fmt_kd(p['mom_prev'])}."
            )

        # Allocation pulse
        if alloc_pulse:
            a = alloc_pulse
            inc_txt = f"{a['inc_needed_pct']:.0f}%" if pd.notnull(a['inc_needed_pct']) else "N/A"
            summary_lines.append(
                f"- Allocation pulse: Avg monthly from {a['hist_period']} is {fmt_kd(a['avg_hist'])} vs allocated target {fmt_kd(a['allocated_target'])} "
                f"â†’ lift needed {inc_txt}. Latest month ({a['latest_month_label']}) sales: {fmt_kd(a['current_month_total'])}."
            )
            corr_txt = f"{a['target_sales_corr']:.2f}" if pd.notnull(a["target_sales_corr"]) else "N/A"
            summary_lines.append(f"- Correlation between historical sales and targets: {corr_txt} (higher means targets align well with past performance).")
            if not a['suggested_targets'].empty:
                top_suggest = a['suggested_targets'].sort_values(ascending=False).head(1)
                summary_lines.append(f"- Suggested target adjustment example: {top_suggest.index[0]} to {fmt_kd(top_suggest.iloc[0])} (10% over historical avg).")

        # Target insights
        if target_pulse:
            t = target_pulse
            summary_lines.append(f"- Target sheet: Total KA {fmt_kd(t['total_ka'])}, Total Talabat {fmt_kd(t['total_tal'])}. Avg KA per salesman: {fmt_kd(t['avg_ka'])}.")
            summary_lines.append(f"- Highest target: {t['top_target_sm']} ({fmt_kd(t['total_ka'])}). Target variance (std): {fmt_kd(t['target_variance'])} indicates spread in expectations.")
            if not t['target_quartiles'].empty:
                summary_lines.append(f"- Target quartiles: Q1 {fmt_kd(t['target_quartiles'][0.25])}, Median {fmt_kd(t['target_quartiles'][0.5])}, Q3 {fmt_kd(t['target_quartiles'][0.75])}.")

        # Channels insights
        if channels_pulse:
            c = channels_pulse
            dist_str = ", ".join([f"{k}: {v}" for k, v in c['channel_dist'].items()])
            summary_lines.append(f"- Channels sheet: Distribution - {dist_str}. Top channel: {c['top_channel']}. Unique PY: {c['num_py']}.")
            if c['channel_sales']:
                top_ch_sales = max(c['channel_sales'], key=c['channel_sales'].get)
                summary_lines.append(f"- Highest sales channel: {top_ch_sales} with {fmt_kd(c['channel_sales'][top_ch_sales])}.")

        # NEW: RFM Summary
        if not segment_sales.empty:
            top_segment = segment_sales.index[0]
            top_seg_val = segment_sales.iloc[0]
            summary_lines.append(f"- Top customer segment (RFM): {top_segment} with {fmt_kd(top_seg_val)} ({(top_seg_val/segment_sales.sum()*100):.0f}% of total).")

        st.write("\n".join(summary_lines))

        # New: Prescriptive recommendations
        st.subheader("ğŸ› ï¸ Prescriptive Recommendations")
        rec_lines = []
        if ka_ach_pct < 80:
            rec_lines.append("- KA achievement low: Consider incentivizing high-margin products or expanding e-com partnerships.")
        if len(anomalies_ai) > 3:
            rec_lines.append("- Multiple anomalies detected: Investigate external factors like promotions or market events on affected dates.")
        if alloc_pulse and alloc_pulse['target_sales_corr'] < 0.5 and pd.notnull(alloc_pulse['target_sales_corr']):
            rec_lines.append("- Low target-sales correlation: Realign targets based on recent performance data.")
        if ytd_pulse and ytd_pulse['yoy_pct'] < 0:
            rec_lines.append("- Negative YoY growth: Analyze competitors or internal changes; suggest targeted campaigns.")
        if ytd_pulse and ytd_pulse['mom_current'] == 0:
            rec_lines.append("- No data for latest month: Ensure data is up-to-date or check for upload issues.")
        # NEW: RFM-based rec
        if not segment_sales.empty and "Champions" in segment_sales.index and (segment_sales["Champions"] / segment_sales.sum() < 0.3):
            rec_lines.append("- Champions segment under 30% of sales: Focus retention campaigns.")
        st.write("\n".join(rec_lines) if rec_lines else "- All metrics look stable; maintain current strategies.")

        # New: Visualizations for AI Insights
        st.subheader("ğŸ“Š AI-Generated Visuals")
        if exp_forecast is not None:
            fig_exp = go.Figure()
            fig_exp.add_trace(go.Scatter(x=df_time_ai["ds"], y=df_time_ai["y"], mode='lines+markers', name='Actual', line=dict(color='#1E3A8A'),
                                         hovertemplate='Date: %{x|%Y-%m-%d}<br>Value: %{y:,.0f} KD<extra></extra>'))
            fig_exp.add_trace(go.Scatter(x=pd.date_range(df_time_ai["ds"].max() + pd.Timedelta(days=1), periods=30), y=exp_forecast, mode='lines', name='Holt-Winters Forecast', line=dict(color='#EF4444', dash='dash'),
                                         hovertemplate='Date: %{x|%Y-%m-%d}<br>Forecast: %{y:,.0f} KD<extra></extra>'))
            fig_exp.update_layout(title="Advanced Sales Forecast (Holt-Winters)", xaxis_title="Date", yaxis_title="Net Value (KD)")
            st.plotly_chart(fig_exp, use_container_width=True)
        else:
            st.info("Insufficient daily data points for advanced forecast (requires at least 14 days).")

        if lin_forecast is not None:
            fig_lin = go.Figure()
            fig_lin.add_trace(go.Scatter(x=df_time_ai["ds"], y=df_time_ai["y"], mode='lines+markers', name='Actual', line=dict(color='#1E3A8A'),
                                         hovertemplate='Date: %{x|%Y-%m-%d}<br>Value: %{y:,.0f} KD<extra></extra>'))
            fig_lin.add_trace(go.Scatter(x=pd.date_range(df_time_ai["ds"].max() + pd.Timedelta(days=1), periods=30), y=lin_forecast, mode='lines', name='Linear Trend Forecast', line=dict(color='#10B981', dash='dot'),
                                         hovertemplate='Date: %{x|%Y-%m-%d}<br>Forecast: %{y:,.0f} KD<extra></extra>'))
            fig_lin.update_layout(title="Linear Trend Sales Forecast", xaxis_title="Date", yaxis_title="Net Value (KD)")
            st.plotly_chart(fig_lin, use_container_width=True)

        if ytd_pulse and pd.notnull(ytd_pulse["yoy_pct"]):
            yoy_df = pd.DataFrame({
                "Year": [f"Prev Year ({ytd_pulse['prev_year_label']})", f"Latest Year ({ytd_pulse['current_year_label']})"],
                "YTD Sales": [ytd_pulse["ytd_prev"], ytd_pulse["ytd_current"]]
            })
            yoy_pct = ytd_pulse['yoy_pct'] if pd.notnull(ytd_pulse['yoy_pct']) else 0
            fig_yoy = px.bar(yoy_df, x="Year", y="YTD Sales", title="YoY YTD Sales Comparison")
            fig_yoy.update_traces(
                texttemplate='%{y:,.0f} KD',
                textposition='auto',
                hovertemplate='<b>%{x}</b><br>Sales: %{y:,.0f} KD<br>Change: %{customdata[0]:.1f}%<extra></extra>',
                customdata=[[0], [yoy_pct]]  # Custom data for percentage in hover
            )
            fig_yoy.add_annotation(
                x=1, y=yoy_df['YTD Sales'][1],
                text=f"{yoy_pct:.1f}%",
                showarrow=True,
                arrowhead=1,
                yshift=10 if yoy_pct >= 0 else -10
            )
            st.plotly_chart(fig_yoy, use_container_width=True)

        if ytd_pulse and pd.notnull(ytd_pulse["mom_pct"]):
            mom_df = pd.DataFrame({
                "Month": [f"Prev Month ({ytd_pulse['prev_month_label']})", f"Latest Month ({ytd_pulse['latest_month_label']})"],
                "Sales": [ytd_pulse["mom_prev"], ytd_pulse["mom_current"]]
            })
            mom_pct = ytd_pulse['mom_pct'] if pd.notnull(ytd_pulse['mom_pct']) else 0
            fig_mom = px.bar(mom_df, x="Month", y="Sales", title="MoM Sales Comparison")
            fig_mom.update_traces(
                texttemplate='%{y:,.0f} KD',
                textposition='auto',
                hovertemplate='<b>%{x}</b><br>Sales: %{y:,.0f} KD<br>Change: %{customdata[0]:.1f}%<extra></extra>',
                customdata=[[0], [mom_pct]]  # Custom data for percentage in hover
            )
            fig_mom.add_annotation(
                x=1, y=mom_df['Sales'][1],
                text=f"{mom_pct:.1f}%",
                showarrow=True,
                arrowhead=1,
                yshift=10 if mom_pct >= 0 else -10
            )
            st.plotly_chart(fig_mom, use_container_width=True)

        # NEW: Weekly Visit Tracker Analysis (no table repetition)
        st.subheader("Weekly Visit Tracker Analysis")
        if "ytd_df" not in st.session_state or st.session_state["ytd_df"].empty:
            st.info("YTD sheet is missing or empty in session state.")
        elif "sales_df" not in st.session_state or st.session_state["sales_df"].empty:
            st.info("Sales sheet is missing or empty in session state.")
        else:
            ytd_df = st.session_state["ytd_df"].copy()
            sales_df = st.session_state["sales_df"].copy()

            # Helper to find columns
            def find_col(df, candidates):
                for n in candidates:
                    if n in df.columns:
                        return n
                for c in df.columns:
                    lc = c.lower()
                    for n in candidates:
                        if n.lower() in lc:
                            return c
                return None

            cust_candidates = ["SP Name1", "SP Name 1", "SP_Name1", "Customer", "PY Name1", "PY Name 1"]
            date_candidates = ["Billing Date", "billing date", "Date"]
            amount_candidates = ["Net Value", "NetAmount", "Net Amount", "Amount", "Sales Amount"]

            cust_col_ytd = find_col(ytd_df, cust_candidates)
            cust_col_sales = find_col(sales_df, cust_candidates)
            date_col_ytd = find_col(ytd_df, date_candidates)
            date_col_sales = find_col(sales_df, date_candidates)
            amount_col = find_col(sales_df, amount_candidates)

            if None in [cust_col_ytd, cust_col_sales, date_col_ytd, date_col_sales, amount_col]:
                st.error("Missing required columns for Weekly Visit Tracker.")
            else:
                ytd_df[date_col_ytd] = pd.to_datetime(ytd_df[date_col_ytd], errors="coerce")
                sales_df[date_col_sales] = pd.to_datetime(sales_df[date_col_sales], errors="coerce")

                last_3_months = today - pd.DateOffset(months=3)
                recent_ytd = ytd_df[ytd_df[date_col_ytd] >= last_3_months]
                customer_list = pd.Series(recent_ytd[cust_col_ytd].dropna().unique()).astype(str)

                if customer_list.empty:
                    st.info("No customers in YTD with sales in the last 3 months.")
                else:
                    days_dt = [today - pd.Timedelta(days=i) for i in range(7, 0, -1)]
                    days_str = [d.strftime("%Y-%m-%d") for d in days_dt]

                    sales_window_start = days_dt[0].normalize()
                    sales_window_end = today.normalize()
                    sales_last7 = sales_df[
                        (sales_df[date_col_sales] >= sales_window_start) &
                        (sales_df[date_col_sales] < sales_window_end)
                    ].copy()
                    sales_last7[cust_col_sales] = sales_last7[cust_col_sales].astype(str)
                    sales_last7[amount_col] = pd.to_numeric(sales_last7[amount_col], errors="coerce").fillna(0.0)

                    sales_last7["__date_str"] = sales_last7[date_col_sales].dt.strftime("%Y-%m-%d")
                    pivot = sales_last7.groupby([cust_col_sales, "__date_str"], dropna=False)[amount_col] \
                                     .sum().reset_index().pivot(index=cust_col_sales, columns="__date_str", values=amount_col) \
                                     .reindex(columns=days_str, fill_value=0.0).reset_index()
                    pivot = pivot.rename(columns={cust_col_sales: "Customer"})

                    base = pd.DataFrame({"Customer": customer_list})
                    visit_df = base.merge(pivot, on="Customer", how="left").fillna(0.0)

                    visit_df["Weekly Total"] = visit_df[days_str].sum(axis=1)

                    recent_sales_3m = sales_df[sales_df[date_col_sales] >= last_3_months].copy()
                    recent_sales_3m[amount_col] = pd.to_numeric(recent_sales_3m[amount_col], errors="coerce").fillna(0.0)
                    total_sales = recent_sales_3m.groupby(cust_col_sales)[amount_col].sum().reset_index().rename(
                        columns={cust_col_sales: "Customer", amount_col: "Total Sales"}
                    )
                    visit_df = visit_df.merge(total_sales, on="Customer", how="left").fillna(0.0)

                    def alert_level(row):
                        if row["Weekly Total"] == 0:
                            if row["Total Sales"] >= visit_df["Total Sales"].quantile(0.8):
                                return "ğŸ”´ High"
                            elif row["Total Sales"] >= visit_df["Total Sales"].quantile(0.5):
                                return "ğŸŸ  Medium"
                            else:
                                return "ğŸŸ¢ Low"
                        else:
                            return "âœ… Visited"

                    visit_df["Alert Level"] = visit_df.apply(alert_level, axis=1)
                    visit_df[days_str + ["Weekly Total", "Total Sales"]] = visit_df[days_str + ["Weekly Total", "Total Sales"]].round(0).astype(int)

                    # Analysis
                    high_value_not_visited = visit_df[visit_df["Alert Level"] == "ğŸ”´ High"].shape[0]
                    at_risk_sales = visit_df[visit_df["Alert Level"].str.contains("High|Medium")]["Total Sales"].sum()
                    top_missed = visit_df[visit_df["Alert Level"] == "ğŸ”´ High"].sort_values("Total Sales", ascending=False).head(5)["Customer"].tolist()
                    missed_mask = visit_df["Weekly Total"] == 0
                    total_not_visited = int(missed_mask.sum())
                    total_missed_cells = int((visit_df[days_str] == 0).sum().sum())

                    st.write(f"- High-value customers not visited: {high_value_not_visited}")
                    st.write(f"- Potential sales at risk (High/Medium alerts): {fmt_kd(at_risk_sales)}")
                    if top_missed:
                        st.write(f"- Top 5 missed high-value customers: {', '.join(top_missed)}")
                    st.info(f"- Total missed visit cells: {total_missed_cells:,}")
                    st.warning(f"- Total customers with NO visits in last 7 days: {total_not_visited}")

                    # Pie chart for alert levels
                    fig_alert = px.pie(visit_df, names="Alert Level", title="Customer Alert Levels Distribution", hole=0.3)
                    fig_alert.update_traces(hovertemplate='<b>%{label}</b><br>Count: %{value}<br>Percentage: %{percent}<extra></extra>')
                    st.plotly_chart(fig_alert, use_container_width=True)

        # --- Structured â€œInsights by sectionâ€ mirrors your pages ---
        st.markdown("---")
        st.subheader("ğŸ§­ Section insights")

        with st.expander("Sales Tracking insights"):
            # Sales by PY, returns, cancellations, anomalies hint
            py_sales_ai = df_ai.groupby("PY Name 1")["Net Value"].sum().sort_values(ascending=False)
            top_py_line = f"- Top PY: {py_sales_ai.index[0]} with {fmt_kd(py_sales_ai.iloc[0])}." if not py_sales_ai.empty else "- No PY data available."
            st.write(top_py_line)

            # Returns and cancels share
            billing_wide_ai = df_ai.pivot_table(index="Driver Name EN", columns="Billing Type", values="Net Value", aggfunc="sum", fill_value=0)
            ret = float(billing_wide_ai.get("YKRE", pd.Series()).sum() + billing_wide_ai.get("ZRE", pd.Series()).sum())
            sales_total = float(billing_wide_ai.sum(axis=1).sum())
            ret_pct = (ret / sales_total * 100) if sales_total else 0
            st.write(f"- Total returns: {fmt_kd(ret)} ({ret_pct:.0f}% of sales).")

            canc = float(billing_wide_ai.get("YKS1", pd.Series()).sum() + billing_wide_ai.get("YKS2", pd.Series()).sum() + billing_wide_ai.get("ZCAN", pd.Series()).sum())
            canc_pct = (canc / sales_total * 100) if sales_total else 0
            st.write(f"- Total cancellations: {fmt_kd(canc)} ({canc_pct:.0f}% of sales).")

            # Daily anomalies quick detection
            if len(df_time_ai) > 7:
                st.write(f"- Detected anomalies (7-day band): {len(anomalies_ai)} day(s).")
                if not anomalies_ai.empty:
                    st.dataframe(anomalies_ai[['ds', 'y']])

        with st.expander("YTD Comparison insights"):
            if ytd_pulse:
                p = ytd_pulse
                st.write(f"- Last 30 days vs prior: {fmt_kd(p['total_p2'])} vs {fmt_kd(p['total_p1'])} â†’ Î” {fmt_kd(p['diff'])} ({(p['pct'] if pd.notnull(p['pct']) else 0):.0f}%).")
                st.write(f"- YoY YTD ({p['current_year_label']} vs {p['prev_year_label']}): {fmt_kd(p['ytd_current'])} vs {fmt_kd(p['ytd_prev'])} â†’ Î” {fmt_kd(p['yoy_diff'])} ({(p['yoy_pct'] if pd.notnull(p['yoy_pct']) else 0):.0f}%).")
                st.write(f"- {benchmark_insight}")
                st.write(f"- MoM ({p['latest_month_label']} vs {p['prev_month_label']}): {fmt_kd(p['mom_current'])} vs {fmt_kd(p['mom_prev'])} â†’ Î” {fmt_kd(p['mom_diff'])} ({(p['mom_pct'] if pd.notnull(p['mom_pct']) else 0):.0f}%).")
            else:
                st.write("- YTD data not available for pulse.")

        with st.expander("SP/PY Target Allocation insights"):
            if alloc_pulse:
                a = alloc_pulse
                st.write(f"- Avg monthly ({a['hist_period']}): {fmt_kd(a['avg_hist'])}.")
                st.write(f"- Allocated KA target: {fmt_kd(a['allocated_target'])}; lift needed: {(a['inc_needed_pct'] if pd.notnull(a['inc_needed_pct']) else 0):.0f}%.")
                st.write(f"- Latest month ({a['latest_month_label']}) progress: {fmt_kd(a['current_month_total'])}.")

                # âœ… FIXED: Prevents ValueError when correlation is string or NaN
                if pd.notnull(a.get("target_sales_corr")) and isinstance(a["target_sales_corr"], (int, float)):
                    st.write(f"- Historical sales vs targets correlation: {a['target_sales_corr']:.2f}.")
                else:
                    st.write("- Historical sales vs targets correlation: N/A.")

                if not a['suggested_targets'].empty:
                    st.subheader("Suggested Target Adjustments")
                    st.dataframe(a['suggested_targets'].to_frame(name="Suggested KA Target"))
            else:
                st.write("- Allocation pulse not available.")

        with st.expander("Target Sheet insights"):
            if target_pulse:
                t = target_pulse
                st.write(f"- Total KA Target: {fmt_kd(t['total_ka'])}, Total Talabat Target: {fmt_kd(t['total_tal'])}.")
                st.write(f"- Average KA Target: {fmt_kd(t['avg_ka'])}, Variance: {fmt_kd(t['target_variance'])}.")
                st.write(f"- Top target salesman: {t['top_target_sm']}.")
                if not t['target_quartiles'].empty:
                    st.write(f"- Quartiles: Q1 {fmt_kd(t['target_quartiles'][0.25])}, Median {fmt_kd(t['target_quartiles'][0.5])}, Q3 {fmt_kd(t['target_quartiles'][0.75])}.")
            else:
                st.write("- Target data not available.")

        with st.expander("Sales Channels Sheet insights"):
            if channels_pulse:
                c = channels_pulse
                dist_str = ", ".join([f"{k}: {v}" for k, v in c['channel_dist'].items()])
                st.write(f"- Channel distribution: {dist_str}.")
                st.write(f"- Dominant channel: {c['top_channel']}.")
                st.write(f"- Unique PY Names: {c['num_py']}.")
                if c['channel_sales']:
                    st.subheader("Channel Sales")
                    st.dataframe(pd.Series(c['channel_sales']).to_frame(name="Net Value"))
            else:
                st.write("- Channels data not available.")

        # NEW: Customer Insights Expander
        with st.expander("Customer Insights (RFM)"):
            if not segment_sales.empty:
                st.write(f"- Top segment: {segment_sales.index[0]} with {fmt_kd(segment_sales.iloc[0])} ({(segment_sales.iloc[0]/segment_sales.sum()*100):.0f}% of total).")
                st.dataframe(segment_sales.to_frame(name="Monetary Value"))
            else:
                st.write("- No RFM data available.")

        # --- Downloadable narrative ---
        st.markdown("---")
        st.subheader("ğŸ“¥ Download executive summary")
        exec_summary_text = f"""Executive Summary ({ai_start.date()} to {ai_end.date()})

{chr(10).join(summary_lines)}

Prescriptive Recommendations:
{chr(10).join(rec_lines)}

Sales Tracking Insights:
- {top_py_line}
- Returns: {fmt_kd(ret)} ({ret_pct:.0f}%)
- Cancellations: {fmt_kd(canc)} ({canc_pct:.0f}%)
- Daily anomalies: {len(anomalies_ai) if len(df_ai)>0 and len(df_time_ai)>7 else 0}

YTD Comparison:
{f"- {fmt_kd(ytd_pulse['total_p2'])} vs {fmt_kd(ytd_pulse['total_p1'])} (Î” {fmt_kd(ytd_pulse['diff'])}, {(ytd_pulse['pct'] if ytd_pulse and pd.notnull(ytd_pulse['pct']) else 0):.0f}%)" if ytd_pulse else "- Not available"}
{f"- YoY ({ytd_pulse['current_year_label']} vs {ytd_pulse['prev_year_label']}): {fmt_kd(ytd_pulse['ytd_current'])} vs {fmt_kd(ytd_pulse['ytd_prev'])} (Î” {fmt_kd(ytd_pulse['yoy_diff'])}, {(ytd_pulse['yoy_pct'] if ytd_pulse and pd.notnull(ytd_pulse['yoy_pct']) else 0):.0f}%)" if ytd_pulse else ""}
{f"- {benchmark_insight}" if benchmark_insight else ""}
{f"- MoM ({ytd_pulse['latest_month_label']} vs {ytd_pulse['prev_month_label']}): {fmt_kd(ytd_pulse['mom_current'])} vs {fmt_kd(ytd_pulse['mom_prev'])} (Î” {fmt_kd(ytd_pulse['mom_diff'])}, {(ytd_pulse['mom_pct'] if ytd_pulse and pd.notnull(ytd_pulse['mom_pct']) else 0):.0f}%)" if ytd_pulse else ""}

SP/PY Allocation:
{f"- Avg monthly {fmt_kd(alloc_pulse['avg_hist'])}, target {fmt_kd(alloc_pulse['allocated_target'])}, lift {alloc_pulse['inc_needed_pct']:.0f}%, month-to-date {fmt_kd(alloc_pulse['current_month_total'])}" if alloc_pulse else "- Not available"}
{f"- Sales-Target Corr: {alloc_pulse['target_sales_corr']:.2f}" if alloc_pulse and pd.notnull(alloc_pulse['target_sales_corr']) else ""}

Target Sheet:
{f"- Total KA {fmt_kd(target_pulse['total_ka'])}, Talabat {fmt_kd(target_pulse['total_tal'])}, Avg KA {fmt_kd(target_pulse['avg_ka'])}" if target_pulse else "- Not available"}

Channels Sheet:
{f"- Dist: {', '.join([f'{k}: {v}' for k,v in channels_pulse['channel_dist'].items()])}, Top: {channels_pulse['top_channel']}" if channels_pulse else "- Not available"}

Customer RFM:
{f"- Top segment: {segment_sales.index[0]} with {fmt_kd(segment_sales.iloc[0])}" if not segment_sales.empty else "- Not available"}
"""
        if st.download_button(
            "ğŸ’¾ Download AI executive summary (TXT)",
            data=exec_summary_text.encode("utf-8"),
            file_name=f"AI_Executive_Summary_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}.txt",
            mime="text/plain"
        ):
            st.session_state["audit_log"].append({
                "user": username,
                "action": "download",
                "details": "AI Executive Summary TXT",
                "timestamp": datetime.now()
            })

        # --- Optional: ask a question about the data (enhanced heuristic) ---
        st.markdown("---")
        st.subheader("ğŸ’¬ Ask a question about your data")
        user_q = st.text_input("Type a question (e.g., 'Which salesman is growing fastest?', 'Where are returns highest?', 'Correlation between targets and sales?')")
        if user_q:
            # Enhanced heuristic answers based on keywords
            answer_lines = []
            q = user_q.lower()

            if "top" in q and ("salesman" in q or "driver" in q):
                top_series = total_sales_by_sm.sort_values(ascending=False).head(5)
                for name, val in top_series.items():
                    answer_lines.append(f"- {name}: {fmt_kd(val)}")
                if not answer_lines:
                    answer_lines.append("- No salesman data available.")
            elif "return" in q:
                # Returns by salesman
                ret_by_sm = (df_ai.pivot_table(index="Driver Name EN", columns="Billing Type", values="Net Value", aggfunc="sum", fill_value=0)[["YKRE","ZRE"]].sum(axis=1)
                             if set(["YKRE","ZRE"]).issubset(df_ai["Billing Type"].unique()) else pd.Series(dtype=float))
                if not ret_by_sm.empty:
                    top_ret = ret_by_sm.sort_values(ascending=False).head(5)
                    for name, val in top_ret.items():
                        answer_lines.append(f"- {name}: returns {fmt_kd(val)}")
                else:
                    answer_lines.append("- No return data available in the selected period.")
            elif "e-com" in q or "talabat" in q or "channel" in q:
                answer_lines.append(f"- Retail: {fmt_kd(total_retail_ai)} ({retail_pct_ai:.0f}%)")
                answer_lines.append(f"- E-com: {fmt_kd(total_ecom_ai)} ({ecom_pct_ai:.0f}%)")
            elif "forecast" in q or "run rate" in q:
                answer_lines.append(f"- Current sales/day: {fmt_kd(current_sales_per_day_ai)}")
                answer_lines.append(f"- Prophet forecast month-end KA sales: {fmt_kd(forecast_month_end_ka_ai)}")
                if exp_forecast is not None:
                    answer_lines.append(f"- Holt-Winters 30-day forecast total: {fmt_kd(exp_forecast.sum())}")
                if lin_forecast is not None:
                    answer_lines.append(f"- Linear trend 30-day forecast total: {fmt_kd(lin_forecast.sum())}")
            elif "correlation" in q or "corr" in q:
                if alloc_pulse and pd.notnull(alloc_pulse["target_sales_corr"]):
                    answer_lines.append(f"- Correlation between historical sales and targets: {alloc_pulse['target_sales_corr']:.2f}")
                else:
                    answer_lines.append("- Correlation data not available.")
                # Add sales vs returns corr example
                if not df_ai.empty:
                    df_corr = df_ai[["Net Value"]].copy()
                    df_corr["is_return"] = df_ai["Billing Type"].isin(["YKRE", "ZRE"]).astype(int)
                    corr_sales_ret = df_corr.corr().iloc[0,1]
                    answer_lines.append(f"- Example: Sales vs Returns indicator: {corr_sales_ret:.2f}")
            elif "growth" in q or "fastest" in q:
                if not ytd_df.empty:
                    # Compute growth rates by salesman (last 30d vs prior)
                    p = ytd_quick_compare(ytd_df)
                    if p:
                        df_p1_sm = ytd_df[(ytd_df["Billing Date"] >= pd.to_datetime(p["p1_start"])) & (ytd_df["Billing Date"] < pd.to_datetime(p["p1_end"]))].groupby("Driver Name EN")["Net Value"].sum()
                        df_p2_sm = ytd_df[(ytd_df["Billing Date"] >= pd.to_datetime(p["p2_start"])) & (ytd_df["Billing Date"] <= pd.to_datetime(p["p2_end"]))].groupby("Driver Name EN")["Net Value"].sum()
                        growth = ((df_p2_sm - df_p1_sm) / df_p1_sm * 100).dropna().sort_values(ascending=False).head(5)
                        for name, val in growth.items():
                            answer_lines.append(f"- {name}: {val:.0f}% growth")
                else:
                    answer_lines.append("- Growth data requires YTD sheet.")
            elif "anomaly" in q or "outlier" in q:
                if not anomalies_ai.empty:
                    for idx, row in anomalies_ai.iterrows():
                        answer_lines.append(f"- {row['ds'].date()}: {fmt_kd(row['y'])} (outside band {fmt_kd(row['lower'])} - {fmt_kd(row['upper'])})")
                else:
                    answer_lines.append("- No anomalies detected.")
            elif "recommend" in q or "suggest" in q:
                answer_lines = rec_lines
            elif "segment" in q or "rfm" in q:
                if not segment_sales.empty:
                    for seg, val in segment_sales.head(5).items():
                        answer_lines.append(f"- {seg}: {fmt_kd(val)}")
                else:
                    answer_lines.append("- No RFM segment data available.")
            else:
                # Default: provide quick highlights
                answer_lines.append(f"- Total sales in period: {fmt_kd(total_sales_all)}")
                if total_ka_target_all_ai > 0:
                    answer_lines.append(f"- KA achievement: {ka_ach_pct:.0f}%")
                if total_tal_target_all_ai > 0:
                    answer_lines.append(f"- Talabat achievement: {tal_ach_pct:.0f}%")

            st.write("\n".join(answer_lines))            
            
# --- Customer Insights Page ---
elif choice == texts[lang]["customer_insights"]:
    st.title(texts[lang]["customer_insights_title"])
    
    if "data_loaded" not in st.session_state:
        st.warning(texts[lang]["no_data_warning"])
        st.stop()

    # Use sales_df directly
    df_rfm = st.session_state["sales_df"].copy()
    if df_rfm.empty or "SP Name1" not in df_rfm.columns or "Billing Date" not in df_rfm.columns or "Net Value" not in df_rfm.columns:
        st.warning(texts[lang]["rfm_no_data"])
        st.stop()

    # Apply salesman filter if applicable
    if user_role == "salesman" and salesman_name:
        df_rfm = df_rfm[df_rfm["Driver Name EN"] == salesman_name]

    # --- Basic RFM Calculation ---
    today = pd.Timestamp.today().normalize()
    rfm_df = df_rfm.groupby("SP Name1").agg({
        "Billing Date": lambda x: (today - x.max()).days,  # Recency
        "Net Value": ["count", "sum"]  # Frequency, Monetary
    })
    rfm_df.columns = ["Recency", "Frequency", "Monetary"]
    rfm_df = rfm_df[rfm_df["Monetary"] > 0]  # Filter positive monetary

    if rfm_df.empty:
        st.warning(texts[lang]["rfm_no_data"])
        st.stop()

    # --- Safe RFM Scoring Function ---
    def safe_qcut(series, q=4, reverse=False):
        s = series.copy().fillna(series.max() + 1)
        unique_vals = s.unique()
        n_unique = len(unique_vals)

        # Case 1: All values are the same
        if n_unique == 1:
            return pd.Series([1]*len(s), index=s.index)

        # Case 2: Unique values less than q
        if n_unique < q:
            # Rank values into n_unique bins
            ranks = s.rank(method='dense', ascending=not reverse)
            return ranks.astype(int)

        # Case 3: Enough variation, safe qcut
        labels = list(range(q, 0, -1)) if reverse else list(range(1, q+1))
        try:
            return pd.qcut(s, q=q, labels=labels, duplicates='drop')
        except ValueError:
            # Fallback if qcut fails
            ranks = s.rank(method='dense', ascending=not reverse)
            return ranks.astype(int)

    # Apply safe scoring
    rfm_df["R_Score"] = safe_qcut(rfm_df["Recency"], q=4, reverse=True)
    rfm_df["F_Score"] = safe_qcut(rfm_df["Frequency"], q=4)
    rfm_df["M_Score"] = safe_qcut(rfm_df["Monetary"], q=4)
    rfm_df["RFM_Score"] = rfm_df["R_Score"].astype(str) + rfm_df["F_Score"].astype(str) + rfm_df["M_Score"].astype(str)

    # --- Segments ---
    def rfm_segment(row):
        if row["RFM_Score"] in ["444", "443", "434", "433"]:
            return "Champions"
        elif row["R_Score"] >= 3 and row["F_Score"] >= 3:
            return "Loyal Customers"
        elif row["R_Score"] >= 3 and row["M_Score"] >= 3:
            return "Potential Loyalists"
        elif row["R_Score"] >= 3:
            return "New Customers"
        elif row["R_Score"] <= 2 and row["F_Score"] >= 2 and row["M_Score"] >= 2:
            return "At Risk"
        elif row["R_Score"] <= 1 and row["F_Score"] >= 2 and row["M_Score"] >= 2:
            return "Hibernating"
        else:
            return "Others"

    rfm_df["Segment"] = rfm_df.apply(rfm_segment, axis=1)

    # --- Tabs ---
    tab1, tab2, tab3 = st.tabs([texts[lang]["rfm_analysis_sub"], texts[lang]["rfm_cohort_sub"], "Weekly Visit Tracker"])

    # ---------------- RFM Analysis Tab ----------------
    with tab1:
        st.subheader(texts[lang]["rfm_table_sub"])
        numeric_cols = ["Recency", "Frequency", "Monetary"]
        rfm_display_df = rfm_df.copy()
        rfm_display_df[numeric_cols] = rfm_display_df[numeric_cols].astype(int)

        st.dataframe(
            rfm_display_df.sort_values("Monetary", ascending=False),
            use_container_width=True
        )

        # Download RFM Table
        timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
        excel_data = to_excel_bytes(rfm_df.reset_index(), sheet_name="RFM_Analysis")
        if st.download_button(
            texts[lang]["rfm_download"],
            data=excel_data,
            file_name=f"rfm_analysis_{timestamp}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        ):
            st.session_state["audit_log"].append({
                "user": username,
                "action": "download",
                "details": f"rfm_analysis_{timestamp}.xlsx",
                "timestamp": datetime.now().isoformat()
            })

        # Enhanced: RFM Segment Distribution Pie Chart
        st.subheader("RFM Segment Distribution")
        segment_counts = rfm_df["Segment"].value_counts().reset_index()
        segment_counts.columns = ["Segment", "Count"]
        segment_counts["Percentage"] = (segment_counts["Count"] / segment_counts["Count"].sum() * 100).round(1)
        segment_avg_monetary = rfm_df.groupby("Segment")["Monetary"].mean().round(2).reset_index()
        segment_counts = segment_counts.merge(segment_avg_monetary, on="Segment")

        fig_segment_pie = px.pie(
            segment_counts,
            values="Count",
            names="Segment",
            title="RFM Segment Distribution",
            hole=0.3,
            hover_data=["Percentage", "Monetary"]
        )
        fig_segment_pie.update_traces(
            textposition='inside',
            textinfo='percent+label',
            hovertemplate='<b>%{label}</b><br>Count: %{value}<br>Percentage: %{customdata[0]}%<br>Avg Monetary: %{customdata[1]:,.2f} KD<extra></extra>',
            customdata=segment_counts[["Percentage", "Monetary"]].values
        )
        st.plotly_chart(fig_segment_pie, use_container_width=True)

        # Enhanced: Key Metrics per Segment Table
        st.subheader("Key Metrics per RFM Segment")
        segment_metrics = rfm_df.groupby("Segment").agg(
            mean_recency=("Recency", "mean"),
            mean_frequency=("Frequency", "mean"),
            mean_monetary=("Monetary", "mean"),
            count=("Recency", "count")  # Use existing column for count
        ).round(2).rename(columns={"count": "Count"})
        st.dataframe(segment_metrics, use_container_width=True)

        # Download Segment Metrics
        csv_segment = segment_metrics.to_csv().encode('utf-8')
        st.download_button(
            "Download Segment Metrics (CSV)",
            data=csv_segment,
            file_name=f"rfm_segment_metrics_{timestamp}.csv",
            mime="text/csv"
        )

        # Enhanced: Prescriptive Recommendations per Segment
        st.subheader("Prescriptive Actions per Segment")
        recommendations = {
            "Champions": "Reward with exclusive offers, loyalty programs, and upsell high-value items to maintain engagement.",
            "Loyal Customers": "Encourage referrals and provide personalized recommendations to increase frequency.",
            "Potential Loyalists": "Nurture with targeted campaigns to boost frequency and convert to Loyal Customers.",
            "New Customers": "Onboard effectively with welcome discounts to encourage repeat purchases.",
            "At Risk": "Re-engage with win-back offers, surveys, or limited-time promotions.",
            "Hibernating": "Reactivate with aggressive discounts or reminders of past purchases.",
            "Others": "Analyze further and test general marketing strategies."
        }
        for seg in segment_metrics.index:
            st.write(f"- **{seg}**: {recommendations.get(seg, 'General engagement strategies recommended.')}")

        # RFM Scatter Plot (kept as is)
        st.subheader(texts[lang]["rfm_chart_sub"])
        fig_rfm = px.scatter(
            rfm_df.reset_index(),
            x="Recency",
            y="Monetary",
            size="Frequency",
            color="Segment",
            hover_name="SP Name1",
            title="RFM Scatter Plot (Size = Frequency)",
            color_discrete_sequence=px.colors.qualitative.D3
        )
        st.plotly_chart(fig_rfm, use_container_width=True)


    # ---------------- Cohort Analysis Tab ----------------
    with tab2:
        st.subheader(texts[lang]["rfm_cohort_sub"])
        st.info(texts[lang]["rfm_cohort_info"])

        df_cohort = df_rfm.copy().reset_index().rename(columns={"SP Name1": "Customer"})
        df_cohort["First_Purchase"] = df_cohort.groupby("Customer")["Billing Date"].transform("min")
        df_cohort["Cohort_Month"] = df_cohort["First_Purchase"].dt.to_period("M")
        df_cohort["Period_Month"] = df_cohort["Billing Date"].dt.to_period("M")
        df_cohort["Cohort_Index"] = (df_cohort["Period_Month"] - df_cohort["Cohort_Month"]).apply(lambda x: x.n)

        cohort_data = df_cohort.groupby(["Cohort_Month", "Cohort_Index", "Customer"]).agg({
            "Billing Date": lambda x: (today - x.max()).days,
            "Net Value": ["count", "sum"]
        }).reset_index()
        cohort_data.columns = ["Cohort_Month", "Cohort_Index", "Customer", "Recency", "Frequency", "Monetary"]

        cohort_data = cohort_data.groupby(["Cohort_Month", "Cohort_Index"]).agg({
            "Recency": "mean",
            "Frequency": "mean",
            "Monetary": "mean",
            "Customer": "nunique"
        }).round(1).reset_index()

        cohort_data["Cohort_Month"] = cohort_data["Cohort_Month"].astype(str)
        cohort_data["Cohort_Index"] = cohort_data["Cohort_Index"].astype(int)

        cohort_pivot_m = cohort_data.pivot(index="Cohort_Month", columns="Cohort_Index", values="Monetary")

        fig_cohort_m = px.imshow(
            cohort_pivot_m.fillna(0),
            labels=dict(x="Period (Months After Acquisition)", y="Cohort (First Purchase Month)", color="Avg Monetary (KD)"),
            title="Monetary Value Evolution by Cohort (Heatmap)",
            color_continuous_scale="Viridis"
        )
        st.plotly_chart(fig_cohort_m, use_container_width=True)

        st.subheader(texts[lang]["rfm_cohort_table_sub"])
        st.dataframe(cohort_data.pivot(index="Cohort_Month", columns="Cohort_Index", values="Customer"), use_container_width=True)

        # Cohort Insights
        if not cohort_data.empty:
            latest_cohort = cohort_data[cohort_data["Cohort_Index"] == 0]["Monetary"].mean()
            retention_rate = (cohort_data[cohort_data["Cohort_Index"] == 1]["Customer"].sum() /
                             cohort_data[cohort_data["Cohort_Index"] == 0]["Customer"].sum() * 100) \
                             if len(cohort_data[cohort_data["Cohort_Index"] == 0]) > 0 else 0
            st.metric("Avg Monetary in Latest Cohort", f"KD {int(latest_cohort)}")
            st.metric("1-Month Retention Rate", f"{retention_rate:.0f}%")
            st.info("Higher retention and increasing monetary indicate strong cohorts. Focus retention efforts on declining ones.")
        else:
            st.warning(texts[lang]["rfm_cohort_no_data"])

# ---------------- Weekly Visit Tracker Tab ----------------
        with tab3:
            st.subheader("Weekly Visit Tracker with High-Value Alerts")

            # --- Date selection: Auto or Manual ---
            st.write("ğŸ“… Select how you want to record the visit date:")
            auto_date = st.toggle("Use current date automatically", value=True)

            if auto_date:
                selected_date = datetime.now().date()
                st.info(f"âœ… Auto-selected current date: {selected_date}")
            else:
                selected_date = st.date_input("Select visit date manually", datetime.now().date())

            st.session_state["visit_date"] = selected_date

            if "ytd_df" not in st.session_state or st.session_state["ytd_df"].empty:
                st.info("YTD sheet is missing or empty in session state.")
            elif "sales_df" not in st.session_state or st.session_state["sales_df"].empty:
                st.info("Sales sheet is missing or empty in session state.")
            else:
                ytd_df = st.session_state["ytd_df"].copy()
                sales_df = st.session_state["sales_df"].copy()

                # --- Helper to detect columns dynamically ---
                def find_col(df, candidates):
                    for n in candidates:
                        if n in df.columns:
                            return n
                    for c in df.columns:
                        lc = c.lower()
                        for n in candidates:
                            if n.lower() in lc:
                                return c
                    return None

                cust_candidates = ["SP Name1", "SP Name 1", "SP_Name1", "Customer", "PY Name1", "PY Name 1"]
                date_candidates = ["Billing Date", "billing date", "Date"]
                amount_candidates = ["Net Value", "NetAmount", "Net Amount", "Amount", "Sales Amount"]
                material_candidates = ["Material Description", "Item", "Product", "Material"]

                cust_col_ytd = find_col(ytd_df, cust_candidates)
                cust_col_sales = find_col(sales_df, cust_candidates)
                date_col_ytd = find_col(ytd_df, date_candidates)
                date_col_sales = find_col(sales_df, date_candidates)
                amount_col = find_col(sales_df, amount_candidates)
                material_col = find_col(sales_df, material_candidates)

                if None in [cust_col_ytd, cust_col_sales, date_col_ytd, date_col_sales, amount_col, material_col]:
                    st.error("Missing required columns for Weekly Visit Tracker.")
                else:
                    ytd_df[date_col_ytd] = pd.to_datetime(ytd_df[date_col_ytd], errors="coerce")
                    sales_df[date_col_sales] = pd.to_datetime(sales_df[date_col_sales], errors="coerce")

                    # --- Customer list (last 3 months) ---
                    last_3_months = pd.Timestamp(selected_date) - pd.DateOffset(months=3)
                    recent_ytd = ytd_df[ytd_df[date_col_ytd] >= last_3_months]
                    customer_list = pd.Series(recent_ytd[cust_col_ytd].dropna().unique()).astype(str)

                    if customer_list.empty:
                        st.info("No customers in YTD with sales in the last 3 months.")
                    else:
                        # --- Generate last 7 days dynamically ---
                        days_dt = [pd.Timestamp(selected_date) - pd.Timedelta(days=i) for i in range(6, -1, -1)]
                        days_str = [d.strftime("%Y-%m-%d") for d in days_dt]

                        sales_window_start = days_dt[0]
                        sales_window_end = pd.Timestamp(selected_date) + pd.Timedelta(days=1)

                        sales_last7 = sales_df[
                            (sales_df[date_col_sales] >= sales_window_start)
                            & (sales_df[date_col_sales] < sales_window_end)
                        ].copy()

                        sales_last7[cust_col_sales] = sales_last7[cust_col_sales].astype(str)
                        sales_last7[amount_col] = pd.to_numeric(sales_last7[amount_col], errors="coerce").fillna(0.0)

                        # --- Create pivot for last 7 days ---
                        sales_last7["__date_str"] = sales_last7[date_col_sales].dt.strftime("%Y-%m-%d")
                        pivot = (
                            sales_last7.groupby([cust_col_sales, "__date_str"], dropna=False)[amount_col]
                            .sum()
                            .reset_index()
                            .pivot(index=cust_col_sales, columns="__date_str", values=amount_col)
                            .reindex(columns=days_str, fill_value=0.0)
                            .reset_index()
                        )
                        pivot = pivot.rename(columns={cust_col_sales: "Customer"})

                        base = pd.DataFrame({"Customer": customer_list})
                        visit_df = base.merge(pivot, on="Customer", how="left").fillna(0.0)
                        visit_df.insert(1, "Visit Date", selected_date)

                        # --- Add Weekly Total ---
                        visit_df["Weekly Total"] = visit_df[days_str].sum(axis=1)

                        # --- Compute 4 Weekly Totals (last 4 weeks) ---
                        end_date = pd.Timestamp(selected_date)
                        start_date = end_date - pd.Timedelta(weeks=4)
                        recent_sales = sales_df[
                            (sales_df[date_col_sales] >= start_date)
                            & (sales_df[date_col_sales] <= end_date)
                        ].copy()

                        recent_sales[cust_col_sales] = recent_sales[cust_col_sales].astype(str)
                        recent_sales[amount_col] = pd.to_numeric(recent_sales[amount_col], errors="coerce").fillna(0.0)
                        recent_sales["Week_Number"] = ((recent_sales[date_col_sales] - start_date).dt.days // 7) + 1
                        recent_sales.loc[recent_sales["Week_Number"] > 4, "Week_Number"] = 4

                        week_totals = (
                            recent_sales.groupby([cust_col_sales, "Week_Number"])[amount_col]
                            .sum()
                            .unstack(fill_value=0)
                            .reset_index()
                            .rename(columns={cust_col_sales: "Customer"})
                        )

                        # --- Create dynamic week column names ---
                        week_headers = []
                        for i in range(4):
                            week_start = (start_date + pd.Timedelta(days=i * 7)).strftime("%b %d")
                            week_end = (start_date + pd.Timedelta(days=(i + 1) * 7 - 1)).strftime("%b %d")
                            week_headers.append(f"Week {i+1} ({week_start}-{week_end})")

                        week_totals.columns = ["Customer"] + week_headers
                        visit_df = visit_df.merge(week_totals, on="Customer", how="left").fillna(0.0)

                        # --- Total Sales (3 months) ---
                        total_sales = (
                            sales_df[sales_df[date_col_sales] >= last_3_months]
                            .groupby(cust_col_sales)[amount_col]
                            .sum()
                            .reset_index()
                            .rename(columns={cust_col_sales: "Customer", amount_col: "Total Sales"})
                        )
                        visit_df = visit_df.merge(total_sales, on="Customer", how="left").fillna(0.0)

                        # --- Alert level ---
                        def alert_level(row):
                            if row["Weekly Total"] == 0:
                                if row["Total Sales"] >= visit_df["Total Sales"].quantile(0.8):
                                    return "ğŸ”´ High"
                                elif row["Total Sales"] >= visit_df["Total Sales"].quantile(0.5):
                                    return "ğŸŸ  Medium"
                                else:
                                    return "ğŸŸ¢ Low"
                            else:
                                return "âœ… Visited"

                        visit_df["Alert Level"] = visit_df.apply(alert_level, axis=1)

                        # --- Format numbers ---
                        all_numeric_cols = days_str + ["Weekly Total", "Total Sales"] + week_headers
                        visit_df[all_numeric_cols] = visit_df[all_numeric_cols].round(0).astype(int)

                        # --- Highlight styling ---
                        def _highlight(v):
                            if v in ["ğŸ”´ High"]:
                                return "background-color: #F87171; color: white; font-weight: 700"
                            elif v in ["ğŸŸ  Medium"]:
                                return "background-color: #FACC15; color: black; font-weight: 700"
                            elif v in ["ğŸŸ¢ Low"]:
                                return "background-color: #4ADE80; color: black; font-weight: 700"
                            elif v == "âœ… Visited":
                                return "background-color: #38BDF8; color: white; font-weight: 700"
                            elif isinstance(v, int) and v == 0:
                                return "background-color: #F87171; color: white; font-weight: 700"
                            else:
                                return ""

                        st.dataframe(
                            visit_df.style.applymap(
                                _highlight, subset=all_numeric_cols + ["Alert Level"]
                            ),
                            use_container_width=True,
                        )

                        # --- Summary info ---
                        missed_mask = visit_df["Weekly Total"] == 0
                        total_not_visited = int(missed_mask.sum())
                        st.warning(f"Total customers with NO visits in last 7 days: {total_not_visited}")

                        # --- Download Excel ---
                        try:
                            excel_bytes = to_excel_bytes(visit_df, sheet_name="Weekly_Visit_Tracker", index=False)
                            if st.download_button(
                                "â¬‡ï¸ Download Weekly Visit Tracker (Excel)",
                                data=excel_bytes,
                                file_name=f"weekly_visit_tracker_{selected_date}.xlsx",
                                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                            ):
                                st.session_state["audit_log"].append({
                                    "user": username,
                                    "action": "download",
                                    "details": "Weekly Visit Tracker Excel",
                                    "timestamp": datetime.now().isoformat()
                                })
                        except Exception as e:
                            st.error(f"Could not create download file: {e}")

# ---------------- Improved 15-Day Product-Wise Analysis ----------------
            st.subheader("ğŸ§¾ Customer-wise Product Details (Last 15 Days)")

            # Filter for last 15 days
            product_start_date = pd.Timestamp(selected_date) - pd.Timedelta(days=15)
            product_sales = sales_df[
                (sales_df[date_col_sales] >= product_start_date) &
                (sales_df[date_col_sales] <= pd.Timestamp(selected_date))
            ].copy()

            product_sales[cust_col_sales] = product_sales[cust_col_sales].astype(str)
            product_sales[amount_col] = pd.to_numeric(product_sales[amount_col], errors="coerce").fillna(0.0)

            # Unique product list (full list)
            all_products = sorted(sales_df[material_col].unique())

            # Aggregate by customer and product
            product_summary = (
                product_sales.groupby([cust_col_sales, material_col])[amount_col]
                .sum().reset_index()
                .rename(columns={
                    cust_col_sales: "Customer",
                    material_col: "Product",
                    amount_col: "Sales Amount"
                })
            )

            # --- Customer Selection ---
            customer_list = sorted(product_summary["Customer"].unique())
            selected_customer = st.selectbox("Select a Customer", options=customer_list)

            # --- Get products sold by this customer in last 15 days ---
            customer_products = product_summary[product_summary["Customer"] == selected_customer].copy()
            sold_products = set(customer_products["Product"])

            # --- Get products NOT sold ---
            not_sold_products = [p for p in all_products if p not in sold_products]
            not_sold_df = pd.DataFrame({"Product": not_sold_products})
            not_sold_df["Status"] = "âŒ Not Purchased"

            # --- Display in Expanders ---
            with st.expander(f"ğŸŸ¢ {selected_customer}'s Purchased Products (Last 15 Days)", expanded=True):
                if not customer_products.empty:
                    st.dataframe(
                        customer_products.sort_values("Sales Amount", ascending=False),
                        use_container_width=True
                    )
                else:
                    st.info("No products purchased by this customer in the last 15 days.")

            with st.expander(f"ğŸ”´ {selected_customer}'s Not Purchased Products (Last 15 Days)", expanded=False):
                if not not_sold_df.empty:
                    st.dataframe(not_sold_df, use_container_width=True)
                else:
                    st.success("âœ… This customer purchased all products in the last 15 days!")

            # --- Optional download buttons ---
            col1, col2 = st.columns(2)
            with col1:
                try:
                    excel_bytes_prod = to_excel_bytes(customer_products, sheet_name=f"{selected_customer}_Purchased", index=False)
                    st.download_button(
                        f"â¬‡ï¸ Download Purchased Products ({selected_customer})",
                        data=excel_bytes_prod,
                        file_name=f"{selected_customer}_purchased_15days_{selected_date}.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    )
                except Exception as e:
                    st.error(f"Download failed: {e}")

            with col2:
                try:
                    excel_bytes_not = to_excel_bytes(not_sold_df, sheet_name=f"{selected_customer}_Not_Purchased", index=False)
                    st.download_button(
                        f"â¬‡ï¸ Download Not Purchased Products ({selected_customer})",
                        data=excel_bytes_not,
                        file_name=f"{selected_customer}_not_purchased_15days_{selected_date}.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    )
                except Exception as e:
                    st.error(f"Download failed: {e}")

# --- Material Forecast Page ---
elif choice == texts[lang]["material_forecast"]:
    st.title(texts[lang]["material_forecast_title"])

    if "data_loaded" not in st.session_state:
        st.warning(texts[lang]["no_data_warning"])
        st.stop()

    # Use sales_df directly
    df_sales = st.session_state["sales_df"].copy()
    required_cols = ["Billing Date", "Material", "Quantity", "Material Description"]
    missing_cols = [col for col in required_cols if col not in df_sales.columns]
    if df_sales.empty or missing_cols:
        st.warning(f"âš ï¸ Sales data missing required columns: {', '.join(missing_cols)}.")
        st.stop()

    # Apply role filter if needed
    if user_role == "salesman" and salesman_name:
        if "Driver Name EN" in df_sales.columns:
            df_sales = df_sales[df_sales["Driver Name EN"] == salesman_name]

    # Ensure date column is datetime
    df_sales["Billing Date"] = pd.to_datetime(df_sales["Billing Date"], errors="coerce")
    df_sales = df_sales.dropna(subset=["Billing Date"])

    # Extract Month & Year
    df_sales["Year"] = df_sales["Billing Date"].dt.year
    df_sales["Month"] = df_sales["Billing Date"].dt.month

    # Tabs for Monthly & Yearly Forecast
    tab_month, tab_year = st.tabs(["Monthly Forecast", "Yearly Forecast"])

    # ---------------- Monthly Forecast ----------------
    with tab_month:
        st.subheader("Monthly Material Forecast")
        selected_year = st.selectbox("Select Year:", sorted(df_sales["Year"].unique()))
        df_monthly = df_sales[df_sales["Year"] == selected_year]

        # Group by Month, Material, Material Description
        monthly_forecast = df_monthly.groupby(
            ["Month", "Material", "Material Description"]
        )["Quantity"].sum().reset_index()

        # Fill missing months for all materials
        all_months = pd.DataFrame({"Month": range(1, 13)})
        all_materials = df_sales[["Material", "Material Description"]].drop_duplicates()
        full_index = all_materials.merge(all_months, how="cross")
        monthly_forecast = full_index.merge(
            monthly_forecast, on=["Month", "Material", "Material Description"], how="left"
        ).fillna(0)

        # Aggregate again to ensure unique (Material Description, Month)
        monthly_forecast = monthly_forecast.groupby(
            ["Material Description", "Month"]
        )["Quantity"].sum().reset_index()

        # Combined line chart for all materials
        fig = px.line(
            monthly_forecast,
            x="Month",
            y="Quantity",
            color="Material Description",
            markers=True,
            title=f"Monthly Forecast ({selected_year})"
        )
        st.plotly_chart(fig, use_container_width=True)

        # Pivot table safely
        pivot_table = monthly_forecast.pivot(
            index="Material Description", columns="Month", values="Quantity"
        ).fillna(0).astype(int)
        st.dataframe(pivot_table)

        # Download Excel
        timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
        excel_bytes = to_excel_bytes(monthly_forecast, sheet_name="Monthly_Forecast")
        if st.download_button(
            texts[lang]["download_excel"],
            data=excel_bytes,
            file_name=f"monthly_forecast_{selected_year}_{timestamp}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        ):
            st.session_state["audit_log"].append({
                "user": username,
                "action": "download",
                "details": f"monthly_forecast_{selected_year}_{timestamp}.xlsx",
                "timestamp": datetime.now().isoformat()
            })

    # ---------------- Yearly Forecast ----------------
    with tab_year:
        st.subheader("Yearly Material Forecast")
        yearly_forecast = df_sales.groupby(
            ["Year", "Material", "Material Description"]
        )["Quantity"].sum().reset_index()

        # Aggregate by Year & Material Description to avoid duplicates
        yearly_forecast = yearly_forecast.groupby(
            ["Material Description", "Year"]
        )["Quantity"].sum().reset_index()

        # Combined grouped bar chart
        fig = px.bar(
            yearly_forecast,
            x="Year",
            y="Quantity",
            color="Material Description",
            barmode="group",
            text="Quantity",
            title="Yearly Material Forecast"
        )
        st.plotly_chart(fig, use_container_width=True)

        # Pivot table safely
        pivot_table_year = yearly_forecast.pivot(
            index="Material Description", columns="Year", values="Quantity"
        ).fillna(0).astype(int)
        st.dataframe(pivot_table_year)

        # Download Excel
        excel_bytes_year = to_excel_bytes(yearly_forecast, sheet_name="Yearly_Forecast")
        if st.download_button(
            texts[lang]["download_excel"],
            data=excel_bytes_year,
            file_name=f"yearly_forecast_{timestamp}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        ):
            st.session_state["audit_log"].append({
                "user": username,
                "action": "download",
                "details": f"yearly_forecast_{timestamp}.xlsx",
                "timestamp": datetime.now().isoformat()
            })
                      
# --- Product Availability Checker Page ---
elif choice == "Product Availability Checker":
    st.title("ğŸ›’ Product Availability Checker")

    # --- Upload MTD file ---
    uploaded_file = st.file_uploader("Upload MTD Excel file", type=["xlsx"])
    if not uploaded_file:
        st.stop()

    try:
        mtd_df = pd.read_excel(uploaded_file, sheet_name="items list")
        if "Name" not in mtd_df.columns:
            st.error("âš ï¸ Column 'Name' not found in 'items list' sheet.")
            st.stop()
        product_list = mtd_df["Name"].dropna().astype(str).tolist()
    except Exception as e:
        st.error(f"Error reading 'items list': {e}")
        st.stop()

    # --- Get websites (from sheet or user input) ---
    try:
        websites_df = pd.read_excel(uploaded_file, sheet_name="website")
        if "Website" not in websites_df.columns:
            st.warning("âš ï¸ 'Website' sheet missing or 'Website' column not found.")
            websites_list = []
        else:
            websites_list = websites_df["Website"].dropna().astype(str).tolist()
    except:
        websites_list = []

    websites_input = st.text_area(
        "Enter websites manually (one per line)", 
        placeholder="https://example.com\nhttps://example2.com"
    ).splitlines()

    all_websites = list(set(websites_list + [w.strip() for w in websites_input if w.strip()]))

    if not all_websites:
        st.warning("âš ï¸ No websites provided.")
        st.stop()

    # --- User options ---
    selected_websites = st.multiselect(
        "Pick website(s) to check", all_websites, default=all_websites
    )

    similarity = st.selectbox(
        "Select matching similarity threshold (%)",
        options=[50, 60, 70, 80, 90], index=0
    )

    status_filter = st.radio("Filter by status", ["All", "Available", "Unavailable"])

    # --- Check Availability ---
    if st.button("âœ… Check Availability"):
        report = []
        for product in product_list:
            matched_sites = [
                site for site in selected_websites 
                if fuzz.partial_ratio(product.lower(), site.lower()) >= similarity
            ]
            status = "Available" if matched_sites else "Unavailable"
            matched_sites_str = ", ".join(matched_sites) if matched_sites else "-"
            report.append([product, status, matched_sites_str])

        report_df = pd.DataFrame(report, columns=["Product Name", "Status", "Matched Website"])

        if status_filter != "All":
            report_df = report_df[report_df["Status"] == status_filter]

        st.dataframe(report_df, use_container_width=True)

        # --- Download ---
        def to_excel_bytes(df, sheet_name="Report"):
            output = BytesIO()
            with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
                df.to_excel(writer, index=False, sheet_name=sheet_name)
            return output.getvalue()

        excel_bytes = to_excel_bytes(report_df, sheet_name="Product_Availability")
        st.download_button(
            "ğŸ’¾ Download Report (Excel)",
            data=excel_bytes,
            file_name=f"product_availability_{pd.Timestamp.now().strftime('%Y-%m-%d_%H-%M-%S')}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )

# Admin-only Audit Logs View
if user_role == "admin":
    st.sidebar.markdown("---")
    st.sidebar.subheader("Admin Tools")
    if st.sidebar.button("View Audit Logs"):
        st.title("ğŸ“‹ Audit Logs")
        log_df = pd.DataFrame(st.session_state["audit_log"])
        st.dataframe(log_df)
        timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
        if st.download_button(
            "â¬‡ï¸ Download Audit Logs (Excel)",
            data=to_excel_bytes(log_df, sheet_name="Audit_Logs", index=False),
            file_name=f"audit_logs_{timestamp}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        ):
            st.session_state["audit_log"].append({
                "user": username,
                "action": "download",
                "details": f"audit_logs_{timestamp}.xlsx",
                "timestamp": datetime.now()
            })

if "audit_log" not in st.session_state:
    st.session_state["audit_log"] = []
    
    
